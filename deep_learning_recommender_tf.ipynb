{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "1zKrxVlfnqvM"
   },
   "source": [
    "# Deep Learning Recommenders in TensorFlow\n",
    "\n",
    "Dr. Nick Ball  \n",
    "Data-Scientist-in-Residence, Paperspace\n",
    "\n",
    "Last updated: Aug 09th 2021\n",
    "\n",
    "This self-contained notebook shows the use of Paperspace Gradient to implement a recommender system using TensorFlow. It accompanies the 6-part blog series \"Gradient End-to-End: A Recommender System using Notebooks and Workflows\" on the [Paperspace blog](https://blog.paperspace.com), and the associated [Git Repository](https://github.com/gradient-ai/Deep-Learning-Recommender-TF).\n",
    "\n",
    "The project includes these main highlights:\n",
    "\n",
    "1. Show a real-world-style example of machine learning on Gradient\n",
    "2. End-to-end dataflow incorporating both Gradient Notebooks and Workflows\n",
    "3. Modern data science methodology based on Gradient's integrations with Git\n",
    "4. Use TensorFlow 2 and TensorFlow Recommenders (TFRS) to train a recommender model that includes deep learning\n",
    "5. Use training data that reflects what real-world projects deal with (not just demo data)\n",
    "6. Construct a custom model using the full TensorFlow subclassing API\n",
    "7. Show working hyperparameter tuning that improves the results\n",
    "8. Deploy model using Gradient Deployments and its TensorFlow Serving integrations\n",
    "9. Accompanying material: self-contained working Jupyter notebook, and Git repository\n",
    "10. Aimed at a broad technical audience: data scientists who are not engineers, engineers who are not data scientists, those who span the two disciplines, and others\n",
    "\n",
    "The project is not a complete enterprise-grade recommender system: they would typically take teams of several people months to construct, and result in an amount of code far greater than shown here, but it aims to be more than just a simple demonstration or toy model, by showcasing real data science techniques. In the Appendix we discuss some of the steps one might take to go from the project here to a full system, with a focus on Gradient's capabilities.\n",
    "\n",
    "We assume the reader of this notebook is somewhat technical, but not necessarily an expert in recommender systems, deep learning, TensorFlow, or Paperspace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "## Note: Section 5 is coming soon!\n",
    "\n",
    "Model deployment support in the Gradient product on public clusters is currently pending, expected in Sept. 2021. Therefore section 5 of the Notebook on model deployment is shown but will not yet run.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "### Requirements\n",
    "\n",
    "The notebook is designed to run on Paperspace Gradient\n",
    "\n",
    "In the Gradient GUI, create a Notebook with the following settings:\n",
    "\n",
    " - Name = Deep Learning Recommender (or any allowed name)\n",
    " - Select a runtime = TensorFlow 2.4.1\n",
    " - Select a machine = C5 or P4000\n",
    " - Public/private = set to preferred option\n",
    " - Under Advanced options, change the Workspace URL field from https://github.com/gradient-ai/TF2.4.1.git to https://github.com/gradient-ai/Deep-Learning-Recommender-TF to point to this repository. The other options can remain the same.\n",
    " - Start the Notebook\n",
    "\n",
    "Once the Notebook has started, click `deep_learning_recommender_tf.ipynb` to run in the usual way by clicking Run under each cell in turn.\n",
    "\n",
    "Notebook creation can also be done on the command line if desired, via gradient notebooks create. For more details on Notebooks, see the documentation.\n",
    "\n",
    "Alternatively, you can clone the Git repository and run in your own notebook setup\n",
    "\n",
    " - `git clone https://github.com/gradient-ai/Deep-Learning-Recommender-TF.git` (the repo is public, so Git's ssh command form is not required)\n",
    " - Be able to run Python 3, and import modules as in Section 2 below: Matplotlib, NumPy, TensorFlow 2, TFDS, TFRS\n",
    " - We use some notebook cell magic lines, such as `%matplotlib`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "### Additional requirements to run Gradient Workflows and model deployment (sections 4.3+)\n",
    "\n",
    "In addition to the above, to run the Gradient Workflows in section 4.3 and the model deployment in section 5 requires some more setup.\n",
    "\n",
    "This step is optional:\n",
    "\n",
    " - Use or create a [Gradient Private Cluster](https://docs.paperspace.com/gradient/gradient-private-cloud/about/setup/managed-installation) and [get its ID](https://docs.paperspace.com/gradient/gradient-private-cloud/about/usage#finding-your-cluster-id). If no cluster ID is specified, the Gradient public cluster will be used.\n",
    "\n",
    "These requirements will remain, being associated with Workflows as the enterprise-grade production part of Gradient:\n",
    "\n",
    " - [Create a project](https://docs.paperspace.com/gradient/get-started/managing-projects#create-a-project) and [get its ID](https://docs.paperspace.com/gradient/get-started/managing-projects#get-your-projects-id)\n",
    " - [Generate an API key](https://docs.paperspace.com/gradient/get-started/quick-start/install-the-cli#obtaining-an-api-key) for your project to allow access\n",
    " - [Store the API key](https://docs.paperspace.com/gradient/get-started/managing-projects/storing-an-api-key-as-a-secret) as a secret in your project\n",
    "\n",
    "These steps will go away as the product matures around Workflows:\n",
    "\n",
    " - [Create the two workflows](https://docs.paperspace.com/gradient/explore-train-deploy/workflows/getting-started-with-workflows#creating-gradient-workflows) named `recommender-train-model` and `recommender-deploy-model`, and [get their IDs](https://docs.paperspace.com/gradient/explore-train-deploy/workflows/getting-started-with-workflows#running-your-first-workflow-run)\n",
    " - [Create an output dataset](https://docs.paperspace.com/gradient/data/data-overview/private-datasets-repository#creating-a-dataset-and-dataset-version) for the training workflow, named `recommender`\n",
    " \n",
    "The create workflow step and create output dataset can be done via the GUI, or the [command line interface](https://docs.paperspace.com/gradient/get-started/quick-start/install-the-cli) (CLI). The commands for the latter look like\n",
    "\n",
    "`gradient storageProviders list --apiKey <your API key>` (note the `storage provider ID` for **Gradient Managed** storage)  \n",
    "`gradient datasets create --name recommender --storageProviderId <your storage provider ID> --apiKey <your API key>`  \n",
    "`gradient workflows create --name Recommender-Train-Model --projectId <your project ID> --apiKey <your API key>`  \n",
    "`gradient workflows create --name Recommender-Deploy-Model --projectId <your project ID> --apiKey <your API key>`\n",
    "\n",
    "The usage of `--apiKey` on the command line is optional: you can also store a key in a JSON file, e.g., `~/.paperspace/config.json` to avoid having to add it to each command. Here we leave it present. Another option is the environment variable `PAPERSPACE_API_KEY`. See [connecting your account](https://docs.paperspace.com/gradient/get-started/quick-start/install-the-cli#connecting-your-account) for more details.\n",
    "\n",
    "Note that one thing that is *not* required for this project, even in the current beta state, is any setup on your own machine, unless you choose to use the CLI. This is because the Workflows are invoked from this Notebook, via the SDK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "### Format of notebook text\n",
    "\n",
    "The main text is shown as MarkDown, like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [],
   "source": [
    "# Optional extra information is in cell comments, like this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "### Recommenders\n",
    "\n",
    "Recommender systems are widely used in modern artificial intelligence, most prominently in retail and entertainment content. However, many of these systems in businesses still use classical methods such as matrix factorization that may not capture all of the information now available.\n",
    "\n",
    "The addition of the fully nonlinear mappings allowed by machine learning, for example deep learning neural network layers, can improve the performance of recommender systems by both capturing more of the complex patterns of information that are present, and by making it easier to add new information in the form of further data feature columns, such as detailed text descriptions or reviews, multiple user and item information columns, or timestamps.\n",
    "\n",
    "Here, we use the new TensorFlow Recommenders library to show how the addition of deep learning to a recommender model improves its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "VAsFUrkgyYAu"
   },
   "source": [
    "# Contents\n",
    "\n",
    "1. Introduction: Recommender systems and deep learning\n",
    "2. Setup\n",
    "3. Preparing the dataset\n",
    "4. Build the recommender models\n",
    "5. Deploy the final model\n",
    "6. Conclusions\n",
    "\n",
    "Next Steps  \n",
    "Appendices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "tnDTzpDQ_hUS"
   },
   "source": [
    "## 1: Introduction: Recommender systems and deep learning\n",
    "\n",
    "A good way to describe most recommender systems is:\n",
    "\n",
    "*Present suggested new items to a user that users similar to them already liked.*\n",
    "\n",
    "This is on the assumption that if users similar to them liked something, there is a better-than-random chance that they will like it too.\n",
    "\n",
    "The short sentence above involves several concepts, including information about a user, how to measure if they are similar to another user, what items the other users liked, how to choose candidate items to present from the whole list, and how to rank those choices.\n",
    "\n",
    "(There are further ideas as well, such as whether a user rated an item explicitly or just implicitly liked it by watching or buying it, and using other similarities such as item-item as well as user-user similarity.)\n",
    "\n",
    "Here, we use the well-known MovieLens dataset, containing information about which movies users watched, along with details of the movies, the users, and the times of viewing. The idea is to present to a user suggested movies that they might like to watch next.\n",
    "\n",
    "While not a huge modern dataset with millions of viewings from millions of users, it has been widely used, and is \"real enough\" to show both how deep learning can improve recommender models, and how to set up and end-to-end data science workflow.\n",
    "\n",
    "The content of this notebook is based on the tutorials of the [TensorFlow Recommenders (TFRS) library](https://www.tensorflow.org/recommenders), modified to include more real-world data science steps, and showing a model being deployed into production.\n",
    "\n",
    "As described there, recommender models commonly consist of two parts:\n",
    "\n",
    " - Retrieval, which selects possible candidates from the whole list of items that could be recommended, in this case being movies the user might be interested in\n",
    " - Ranking, which narrows down this list to a refined set of items to recommend\n",
    "\n",
    "We concentrate on the ranking portion, showing how the addition of deep learning layers, data features, and hyperparameter tuning, improves the performance of the model.\n",
    "\n",
    "We then show how the resulting model can be easily deployed with Gradient Deployments.\n",
    "\n",
    "The concentration on just one part of the models to be built is so that we can show more fully realized data science steps, the end-to-end process using both Gradient Notebooks and Workflows, and some of the corresponding functionaity, without the project becoming overly long or repetitive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "3EeRY5DQI5VV"
   },
   "source": [
    "## 2: Setup\n",
    "\n",
    "This project uses [TensorFlow Datasets (TFDS)](https://www.tensorflow.org/datasets) and the TensorFlow Recommenders library (TFRS) in addition to the basic TensorFlow 2 and Python 3.\n",
    "\n",
    "TFRS was created as a separate library because recommender systems typically do not correspond to the simple setup of supervised learning models, but have a more complex arrangement of processing steps associated with them. So rather than using a few layers in the high-level TensorFlow Keras Sequential or [Functional](https://www.tensorflow.org/guide/keras/functional) APIs, they need the custom model and custom layer setup in the lower level representation of writing the model classes and subclasses directly.\n",
    "\n",
    "However, recommenders do contain their own common components, such as the FactorizedTopK performance metric for retrieval, that mean usage of a library is considerably more convenient than writing something from scratch in TensorFlow.\n",
    "\n",
    "We use TensorFlow Datasets as the emphases in this project are recommenders, Gradient functionality, end-to-end, and showing some model tuning, rather than data gathering, cleaning, and preparation. Of course, in a full enterprise system this would be a more prominent aspect of the dataflow.\n",
    "\n",
    "Let's install TFDS, TFRS, and import these and the Python modules that we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": true
    },
    "id": "9gG3jLOGbaUv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/secretstorage/dhcrypto.py:15: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/usr/lib/python3/dist-packages/secretstorage/util.py:19: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Requirement already satisfied: pip in /usr/local/lib/python3.6/dist-packages (21.2.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "/usr/lib/python3/dist-packages/secretstorage/dhcrypto.py:15: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/usr/lib/python3/dist-packages/secretstorage/util.py:19: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gradient-utils 0.3.2 requires numpy==1.18.5, but you have numpy 1.19.5 which is incompatible.\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "/usr/lib/python3/dist-packages/secretstorage/dhcrypto.py:15: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/usr/lib/python3/dist-packages/secretstorage/util.py:19: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Currently the notebook is using pip install, which would not be ideal in a production environment.\n",
    "# This is because the install changes the environment and the versions of libraries being installed are\n",
    "# not necessarily fixed, meaning the environment is not fixed and hence reproducibility is not guaranteed.\n",
    "# One could use requirements.txt, but this also does not necessarily fix things due to secondary dependencies.\n",
    "\n",
    "# Various solutions exist, but for rigorous work, Gradient allows the user to build a custom container\n",
    "# containing the correct dependencies, which removes the need for pip install.\n",
    "\n",
    "# Here, the container we use fixes versions, except for TFDS and TFRS, whose versions we therefore fix.\n",
    "\n",
    "!pip install --upgrade pip\n",
    "!pip install -q tensorflow-recommenders==0.4.0\n",
    "!pip install -q --upgrade tensorflow-datasets==4.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "SZGYDaF-m5wZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "\n",
    "# This is Python's function for more nicely or compactly printing variables or data\n",
    "import pprint\n",
    "\n",
    "# Python 3 allows hints on variable types to be given\n",
    "# Here they are used in the model class definitions\n",
    "from typing import Dict, Text\n",
    "\n",
    "# NumPy is used, e.g., for viewing the data in TensorFlow tensors\n",
    "# TensorFlow tensors are built on NumPy arrays\n",
    "import numpy as np\n",
    "\n",
    "# This allows simple inline plots of, e.g., model training history\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid') # Following TFRS tutorials\n",
    "\n",
    "# TensorFlow, TFDS, TFRS\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "ecPlfiYXJDQe"
   },
   "source": [
    "We can see some basic information about the versions of software that we are using. In principle, the container could be accessed to find out more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false
    },
    "id": "Nc5Um6Y44D-Q",
    "outputId": "df8fe35b-e2e5-4a09-be4a-13c63c757ebe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy version: 1.19.5\n",
      "Python version: 3.6.9\n",
      "TensorFlow version: 2.4.0\n",
      "TensorFlow Datasets version: 4.2.0\n",
      "TensorFlow Recommenders version: v0.4.0\n"
     ]
    }
   ],
   "source": [
    "print('NumPy version: {}'.format(np.__version__))\n",
    "print('Python version: {}'.format(platform.python_version()))\n",
    "print('TensorFlow version: {}'.format(tf.__version__))\n",
    "print('TensorFlow Datasets version: {}'.format(tfds.__version__))\n",
    "print('TensorFlow Recommenders version: {}'.format(tfrs.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "GJORoRytYAGI"
   },
   "source": [
    "We can see if GPUs, etc., are available, or just CPU. Here we do not currently specify devices other than the default, as the processing run is not large enough to require a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false
    },
    "id": "o914Boo2YDYz",
    "outputId": "1c553eac-8a74-4955-990e-6a6245fc14da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 15123098248465724941\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 7810874080\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 13217360528687930248\n",
      "physical_device_desc: \"device: 0, name: Quadro P4000, pci bus id: 0000:00:05.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "5PAqjR4a1RR4"
   },
   "source": [
    "## 3: Preparing the dataset\n",
    "\n",
    "Load the MovieLens data from TensorFlow Datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "aaQhqcLGP0jL"
   },
   "outputs": [],
   "source": [
    "# This loads the data from the official TensorFlow datasets repository\n",
    "# at https://www.tensorflow.org/datasets/catalog/movielens\n",
    "# The -ratings suffix indicates that we are loading the dataset with the\n",
    "# movies data joined to the ratings data\n",
    "\n",
    "ratings_raw = tfds.load('movielens/100k-ratings', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false
    },
    "id": "X_sx4C_Bw4sc",
    "outputId": "aff47275-f87a-482c-eb1f-a8093d449c97"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: {bucketized_user_age: (), movie_genres: (None,), movie_id: (), movie_title: (), raw_user_age: (), timestamp: (), user_gender: (), user_id: (), user_occupation_label: (), user_occupation_text: (), user_rating: (), user_zip_code: ()}, types: {bucketized_user_age: tf.float32, movie_genres: tf.int64, movie_id: tf.string, movie_title: tf.string, raw_user_age: tf.float32, timestamp: tf.int64, user_gender: tf.bool, user_id: tf.string, user_occupation_label: tf.int64, user_occupation_text: tf.string, user_rating: tf.float32, user_zip_code: tf.string}>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It is loaded as a TensorFlow PrefetchDataset\n",
    "ratings_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "9VReDbPf4QRU"
   },
   "source": [
    "Data science workflows, especially in the experimental and model training stage as here, should contain a strong component of viewing the actual data throughout the analysis. This is both for the understanding of the experimenter, other readers, and for sanity checking.\n",
    "\n",
    "Here we see that various columns (features) are available, including information about the user, the movie they watched, and outcomes such as the user's rating of the movie.\n",
    "\n",
    "It is important to distinguish between information that is available before a user watches a movie from that which is only available after, as the latter cannot be used as a feature for training a recommender model. This is because the data to be fed into it when it is deployed must be available before the user has watched the movie that is being recommended to them.\n",
    "\n",
    "In this case, the requirement manifests as the `user_rating` column being a training target and not a feature, and a timestamp column that should be normalized into something that is cyclical like a day of week / month / year, and not an absolute date. Such a date won't come around again in the future when the model has been deployed on unseen data.\n",
    "\n",
    "We also immediately see issues with the data that may manifest further along in the dataflow, such as some of the columns being byte-encoded (strings like `b'357'` instead of just `'357'`). If the setup of TensorFlow Serving plus the RESTful API is to be used for deployment, these will have to be converted to be able to be represented in JSON for passing to the model when it is deployed.\n",
    "\n",
    "The end-to-end mentality of having deployment in scope from the start, enabled by Gradient, has encouraged us to look for and notice these issues right here, rather than spending time training the model and only then noticing them. The latter approach could result in signficant wasted effort if it turns out that the deployment issues are not solvable.\n",
    "\n",
    "The top 2 rows of data are shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false
    },
    "id": "JdNMayvVzhP9",
    "outputId": "2790ba40-5156-4601-aded-36340dc6db31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucketized_user_age': 45.0,\n",
      " 'movie_genres': array([7]),\n",
      " 'movie_id': b'357',\n",
      " 'movie_title': b\"One Flew Over the Cuckoo's Nest (1975)\",\n",
      " 'raw_user_age': 46.0,\n",
      " 'timestamp': 879024327,\n",
      " 'user_gender': True,\n",
      " 'user_id': b'138',\n",
      " 'user_occupation_label': 4,\n",
      " 'user_occupation_text': b'doctor',\n",
      " 'user_rating': 4.0,\n",
      " 'user_zip_code': b'53211'}\n",
      "{'bucketized_user_age': 25.0,\n",
      " 'movie_genres': array([ 4, 14]),\n",
      " 'movie_id': b'709',\n",
      " 'movie_title': b'Strictly Ballroom (1992)',\n",
      " 'raw_user_age': 32.0,\n",
      " 'timestamp': 875654590,\n",
      " 'user_gender': True,\n",
      " 'user_id': b'92',\n",
      " 'user_occupation_label': 5,\n",
      " 'user_occupation_text': b'entertainment',\n",
      " 'user_rating': 2.0,\n",
      " 'user_zip_code': b'80525'}\n"
     ]
    }
   ],
   "source": [
    "# Just saying print(ratings) results in the output <PrefetchDataset shapes: ... as above\n",
    "# So the data is extracted from the TensorFlow tensor format using NumPy\n",
    "\n",
    "for x in ratings_raw.take(2).as_numpy_iterator():\n",
    "    pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "Eo1v4Oac63Te"
   },
   "source": [
    "TensorFlow's `.map()` applies the function in the brackets to each element of a dataset, so with the lambda inline Python function we can reduce the data down to just the columns that we are going to use. Currently these are the movie title, the time of viewing, the user who viewed it, and their rating of the movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "fPH5ffpdw0RR"
   },
   "outputs": [],
   "source": [
    "ratings = ratings_raw.map(lambda x: {\n",
    "    'movie_title': x['movie_title'],\n",
    "    'timestamp': x['timestamp'],\n",
    "    'user_id': x['user_id'],\n",
    "    'user_rating': x['user_rating']\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "Iu4XSa_G1nyN"
   },
   "source": [
    "We perform the canonical 80:20 random split of 80% training data and 20% testing data, with in turn 20% of the training data being used for model validation.\n",
    "\n",
    "As mentioned above, we want to avoid leakage of information from the testing set into the training and validation sets, so we split by timestamp. The testing data comes from later times than the training & validation data. Currently the timestamp used is still absolute rather than cyclic (day of week, month of year, etc.), but that would likely just dampen its utility as a feature, so long as the model is not overfitting to it.\n",
    "\n",
    "TensorFlow allows global and local random seeds to be set, which can ensure, e.g., that we get the same 80:20 split each time here.\n",
    "\n",
    "However, randomness remains in the machine learning models when they are run, which is harder to remove. We have not attempted to do so in this project so results may vary when the notebook is rerun, but they should show the same overall pattern, i.e., they are statistically reproducible even if not exactly reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "jjyIcUVEMmmP"
   },
   "outputs": [],
   "source": [
    "# Get times as a list so we can get the minimum and maximum time values\n",
    "# In the original data they are dictionaries, so a list is needed\n",
    "# Following the TFRS deep model tutorial (https://www.tensorflow.org/recommenders/examples/deep_recommenders)\n",
    "# a quick way to do this is\n",
    "\n",
    "timestamps = np.concatenate(list(ratings.map(lambda x: x['timestamp']).batch(100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false
    },
    "id": "MD5dhCphMm2I",
    "outputId": "3c10d169-d485-44f7-9018-308fc8e68501"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum time value = 874724710\n",
      "Maximum time value = 893286638\n"
     ]
    }
   ],
   "source": [
    "# Get minimum and maximum time values\n",
    "\n",
    "max_time = timestamps.max()\n",
    "min_time = timestamps.min()\n",
    "\n",
    "print('Minimum time value = {}'.format(min_time))\n",
    "print('Maximum time value = {}'.format(max_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false
    },
    "id": "BE16LGI8Mxry",
    "outputId": "0db255df-29ad-428c-8ea3-c5257029b1bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60th percentile time = 885861866.8\n",
      "80th percentile time = 889574252.4\n"
     ]
    }
   ],
   "source": [
    "# Get 60th & 80th percentile times\n",
    "\n",
    "sixtieth_percentile = min_time + 0.6*(max_time - min_time)\n",
    "eightieth_percentile = min_time + 0.8*(max_time - min_time)\n",
    "\n",
    "print('60th percentile time = {}'.format(sixtieth_percentile))\n",
    "print('80th percentile time = {}'.format(eightieth_percentile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "ayX_o1YkMxx6"
   },
   "outputs": [],
   "source": [
    "# Filter original data so that\n",
    "\n",
    "# Training set <= 60th percentile time\n",
    "# 60th < Validation set <= 80th\n",
    "# Testing set > 80th\n",
    "\n",
    "train =      ratings.filter(lambda x: x['timestamp'] <= sixtieth_percentile)\n",
    "validation = ratings.filter(lambda x: x['timestamp'] > sixtieth_percentile and x['timestamp'] <= eightieth_percentile)\n",
    "test =       ratings.filter(lambda x: x['timestamp'] > eightieth_percentile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false
    },
    "id": "Jwlwp7-MMx03",
    "outputId": "2c6df211-27f6-40e6-c891-aac0428ddd96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in training set = 65336\n",
      "Number of rows in validation set = 15778\n",
      "Number of rows in testing set = 18886\n",
      "Total number of rows = 100000\n"
     ]
    }
   ],
   "source": [
    "# We are splitting on time percentiles and not row percentiles,\n",
    "# which means that we have assumed the times are roughly evenly distributed\n",
    "\n",
    "# So check the number of rows in the training, validation, and testing sets is as expected\n",
    "\n",
    "# We could also do row percentiles, which would involve sorting the data by time then shuffling after splitting\n",
    "# As written, the counting is a little slow, but .__len__() doesn't work on the FilterDataset from above\n",
    "\n",
    "# The lengths sum to the number of rows in the original data, currently 100,000, as expected\n",
    "\n",
    "ntimes_tr = 0\n",
    "ntimes_va = 0\n",
    "ntimes_te = 0\n",
    "\n",
    "for x in train.take(-1).as_numpy_iterator():\n",
    "    ntimes_tr += 1\n",
    "\n",
    "for x in validation.take(-1).as_numpy_iterator():\n",
    "    ntimes_va += 1\n",
    "\n",
    "for x in test.take(-1).as_numpy_iterator():\n",
    "    ntimes_te += 1\n",
    "    \n",
    "print('Number of rows in training set = {}'.format(ntimes_tr))\n",
    "print('Number of rows in validation set = {}'.format(ntimes_va))\n",
    "print('Number of rows in testing set = {}'.format(ntimes_te))\n",
    "print('Total number of rows = {}'.format(ntimes_tr + ntimes_va + ntimes_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "rS0eDfkjnjJL"
   },
   "outputs": [],
   "source": [
    "# A validation set is created here because validation_split in model.fit() \n",
    "# is not supported for datasets - its input would have to be tensors\n",
    "# ( [1] ValueError: `validation_split` is only supported for Tensors or NumPy arrays, \n",
    "# found following types in the input: \n",
    "# [<class 'tensorflow.python.data.ops.dataset_ops.CacheDataset'>] )\n",
    "\n",
    "train = train.shuffle(ntimes_tr)\n",
    "validation = validation.shuffle(ntimes_va)\n",
    "test = test.shuffle(ntimes_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "RNIIbzfYDMVt"
   },
   "source": [
    "We also need to extract from the data the list of unique user IDs and unique movie titles.\n",
    "\n",
    "This is because these variables are categorical, and when we use embedding vectors (see below), they map each category onto its own vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "MKROCiPo_5LJ"
   },
   "outputs": [],
   "source": [
    "movie_titles = ratings.batch(1_000_000).map(lambda x: x['movie_title'])\n",
    "user_ids = ratings.batch(1_000_000).map(lambda x: x['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "6NfVEmLiz9jq"
   },
   "outputs": [],
   "source": [
    "unique_movie_titles = np.unique(np.concatenate(list(movie_titles)))\n",
    "unique_user_ids = np.unique(np.concatenate(list(user_ids)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "4-Vj9nHb48pn"
   },
   "source": [
    "## 4: Build the recommender models\n",
    "\n",
    "As mentioned above, recommender systems are often composed of a retrieval model and a ranking model. We will be focusing on the ranking model.\n",
    "\n",
    "We will build two models:\n",
    "\n",
    " - Basic ranking\n",
    " - Tuned ranking\n",
    "\n",
    "and show that the tuned ranking model gives the best performance. This shows the importance of tuning and not just engineering a pipeline using a model off-the-shelf.\n",
    "\n",
    "Recommenders are more complex than basic supervised models, so in the hierarchy of increased flexibility but decreased simplicity or ease of use from the Keras Sequential API, through the Keras functional API, to full definition of model classes and subclasses, the latter approach is used. The classes don't have to be written entirely from scratch, however, as the TFRS library contains various convenience classes and functions, and higher level Keras models and layers can still be used when they fit the purpose.\n",
    "\n",
    "In these models, some of the feature preprocessing can be incorporated as part of the model. This reduces the chance of errors being introduced when it is deployed in production in a different place from where it was trained, because the preprocessing of data from the raw inputs to those correct for the model does not need to be duplicated.\n",
    "\n",
    "The various preprocessing steps and modeling components are combined into a recommender model that can then be trained. The model is described by a Python class that inherits from the TFRS base class.\n",
    "\n",
    "It includes:\n",
    "\n",
    " - Movie embeddings\n",
    " - User ID embeddings\n",
    " - Deep learning layer to compute the rankings\n",
    " - Task layer to compute mean squared error\n",
    " - The `call()` method\n",
    " - The `compute_loss()` method\n",
    "\n",
    "The movie and user ID *embeddings* are using this common method of reducing a column that contains a large number of unique categories to something more manageable. The raw categories get mapped onto integers (known as a vocabulary), which in turn are converted to embeddings. The embedding itself is a vector that represents the mapping from a space with many dimensions (the number of categories) to a continuous vector space with a much lower dimension, e.g., 32.\n",
    "\n",
    "The deep learning layer is a typical set of densely connected layers (every neuron connected to all the others) that allows an arbitrary nonlinear mapping between the inputs and outputs. Deep learning is typically more compute-intensive, but for ranking in a full production system only a small subset of the movies are being used, having been selected by the retrieval model, so this helps.\n",
    "\n",
    "The task layer computes mean squared error between a given ground truth target and the model's prediction. This feeds into `compute_loss()`. `Task` is a TFRS layer that is combining computing the loss, i.e., the measure by which the model training is iterated, and the metric, the measure by which the model performance is reported to the human user. In this case the loss is mean squared error and the metric is root mean squared error, so they are quite similar.\n",
    "\n",
    "The `compute_loss()` method measures how well the model is performing after each iteration of training. This is a built-in method to TFRS and is therefore automatically called during model training with a `tfrs.models.Model` class (the training loop).\n",
    "\n",
    "The `call()` method executes the various steps when the model is run, and is important for the model to be able to be saved for later deployment.\n",
    "\n",
    "The overall result is that for a given user ID and movie title fed to the model, the output is a prediction of what rating that user would give to that movie if they were to watch it. The movies with the highest predicted ratings therefore become the recommendations for that user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "2xiUI74SGklF"
   },
   "source": [
    "### 4.1: Basic ranking model\n",
    "\n",
    "The basic model shows what happens when a model is set up with some default parameters, without attempting to tune any of them.\n",
    "\n",
    "The model is similar to the one in the [TFRS multitask tutorial](https://www.tensorflow.org/recommenders/examples/multitask), here doing a single task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [],
   "source": [
    "class MovielensModelBasicRanking(tfrs.models.Model):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        embedding_dimension = 32\n",
    "\n",
    "        # The embeddings use Keras's preprocessing layers\n",
    "\n",
    "        # Embeddings for movies\n",
    "        self.movie_model: tf.keras.layers.Layer = tf.keras.Sequential([\n",
    "            tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                vocabulary=unique_movie_titles, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(unique_movie_titles) + 1, embedding_dimension)\n",
    "        ])\n",
    "\n",
    "        # Embeddings for users\n",
    "        self.user_model: tf.keras.layers.Layer = tf.keras.Sequential([\n",
    "            tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                vocabulary=unique_user_ids, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "        ])\n",
    "\n",
    "        # Predicted ratings\n",
    "        # This is where deep learning is being used in the recommender system\n",
    "        # The predictions are output by the final layer, hence its size of 1\n",
    "\n",
    "        self.rating_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(256, activation='relu'),\n",
    "            tf.keras.layers.Dense(64, activation='relu'),\n",
    "            tf.keras.layers.Dense(1)\n",
    "        ])\n",
    "\n",
    "        # Ranking is written as a TFRS task\n",
    "        self.task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
    "            loss = tf.keras.losses.MeanSquaredError(),\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    "        )\n",
    "\n",
    "    # The call method allows the model to be run, and saved\n",
    "    # The embeddings are passed into the model\n",
    "    # The embeddings and predicted rating are returned\n",
    "\n",
    "    def call(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:\n",
    "        user_embeddings = self.user_model(features['user_id'])\n",
    "        movie_embeddings = self.movie_model(features['movie_title'])\n",
    "\n",
    "        return (\n",
    "            user_embeddings,\n",
    "            movie_embeddings,\n",
    "            self.rating_model(\n",
    "                tf.concat([user_embeddings, movie_embeddings], axis=1)\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    # This is the TFRS built-in method that computes the model loss function during training\n",
    "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "\n",
    "        ratings = features.pop('user_rating')\n",
    "        user_embeddings, movie_embeddings, rating_predictions = self(features)\n",
    "\n",
    "        rating_loss = self.task(\n",
    "            labels=ratings,\n",
    "            predictions=rating_predictions,\n",
    "        )\n",
    "\n",
    "        return rating_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "SfAqxdgYH1Hl"
   },
   "source": [
    "As at the start of the dataflow, we should view the data at the training stage.\n",
    "\n",
    "The training data is quite similar to the original loaded data, now just movie title, timestamp, user ID, and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false
    },
    "id": "X4wN-Oxqbqxa",
    "outputId": "bc70082f-74d0-4b6a-aeda-084cfbcb4d96"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ShuffleDataset shapes: {movie_title: (), timestamp: (), user_id: (), user_rating: ()}, types: {movie_title: tf.string, timestamp: tf.int64, user_id: tf.string, user_rating: tf.float32}>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Format is now a TensorFlow ShuffleDataset\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false
    },
    "id": "7qByPgKIbjMH",
    "outputId": "1b202622-742c-47bc-a0b7-8115683aa920"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'movie_title': b'Local Hero (1983)',\n",
      " 'timestamp': 883948457,\n",
      " 'user_id': b'846',\n",
      " 'user_rating': 4.0}\n",
      "{'movie_title': b'Sudden Death (1995)',\n",
      " 'timestamp': 880394088,\n",
      " 'user_id': b'374',\n",
      " 'user_rating': 3.0}\n",
      "{'movie_title': b'Beverly Hills Ninja (1997)',\n",
      " 'timestamp': 880696679,\n",
      " 'user_id': b'699',\n",
      " 'user_rating': 1.0}\n"
     ]
    }
   ],
   "source": [
    "for x in train.take(3).as_numpy_iterator():\n",
    "    pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "AdJbchJlqexl"
   },
   "source": [
    "The model performance, especially at scale, can be improved by caching the data into memory.\n",
    "\n",
    "It is also important that the data rows are in a random order. This is because many parts of machine learning algorithms are assuming that each data row is independent of those around it.\n",
    "\n",
    "An example of that is batching the data, which is also done here. Batching causes consecutive elements to be combined into batches, and so if there were, say, some periodicity in the data, it could interact with the batch size and produce highly non-random samples.\n",
    "\n",
    "Note that since a batch size may not divide perfectly into the number of rows in a dataset (or when data is being fed into the system a batch may not be full), its shape may not be known for every batch, and is therefore given as None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "umCAS0aBdtYB"
   },
   "outputs": [],
   "source": [
    "cached_train = train.shuffle(ntimes_tr).batch(8192).cache()\n",
    "cached_validation = validation.shuffle(ntimes_va).batch(8192).cache()\n",
    "cached_test = test.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "YO4SF6-Vqmi5"
   },
   "source": [
    "Since the actual data being fed into the model is the cached and batched set, this should be viewed too. We can see that it is now batched and the batches are formed by arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false
    },
    "id": "aU6QtxRHbs3q",
    "outputId": "93f1e3b3-c4ea-4a63-bf65-246a46f87a90"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<CacheDataset shapes: {movie_title: (None,), timestamp: (None,), user_id: (None,), user_rating: (None,)}, types: {movie_title: tf.string, timestamp: tf.int64, user_id: tf.string, user_rating: tf.float32}>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The shape could be changed, e.g., from None to 8192 by adding drop_remainder=True to the .batch() line above\n",
    "cached_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false
    },
    "id": "dmjmVqnIbzxn",
    "outputId": "a26a618a-0bf8-4f9d-f4c9-e732ad0a55d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'movie_title': array([b'Wizard of Oz, The (1939)', b'1-900 (1994)',\n",
      "       b'Independence Day (ID4) (1996)', ...,\n",
      "       b'Hunt for Red October, The (1990)',\n",
      "       b'Big Blue, The (Grand bleu, Le) (1988)',\n",
      "       b'Speed 2: Cruise Control (1997)'], dtype=object),\n",
      " 'timestamp': array([877196174, 878962200, 879222698, ..., 885062919, 885816915,\n",
      "       882659211]),\n",
      " 'user_id': array([b'331', b'181', b'552', ..., b'513', b'452', b'276'], dtype=object),\n",
      " 'user_rating': array([3., 1., 4., ..., 5., 5., 2.], dtype=float32)}\n",
      "{'movie_title': array([b'Some Kind of Wonderful (1987)', b'Batman Returns (1992)',\n",
      "       b'Scream (1996)', ..., b'To Kill a Mockingbird (1962)',\n",
      "       b'Fear (1996)', b'My Fellow Americans (1996)'], dtype=object),\n",
      " 'timestamp': array([875983023, 878347915, 882818604, ..., 879448475, 878848369,\n",
      "       874953595]),\n",
      " 'user_id': array([b'472', b'44', b'668', ..., b'615', b'749', b'130'], dtype=object),\n",
      " 'user_rating': array([5., 2., 4., ..., 5., 4., 2.], dtype=float32)}\n",
      "{'movie_title': array([b\"It's a Wonderful Life (1946)\", b'Dragonheart (1996)',\n",
      "       b'Bananas (1971)', ..., b'First Wives Club, The (1996)',\n",
      "       b'Top Gun (1986)', b'Primal Fear (1996)'], dtype=object),\n",
      " 'timestamp': array([875727640, 879640502, 880499053, ..., 885713062, 875073048,\n",
      "       884584865]),\n",
      " 'user_id': array([b'694', b'249', b'98', ..., b'885', b'188', b'141'], dtype=object),\n",
      " 'user_rating': array([4., 3., 2., ..., 4., 3., 4.], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "for x in cached_train.take(3).as_numpy_iterator():\n",
    "    pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "LsfOKQ30Iewj"
   },
   "source": [
    "#### 4.1.1: Train and evaluate the basic ranking model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "k_Pe7NpXq_r2"
   },
   "source": [
    "Train the model, outputting the accuracy on the training set and also on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "x7Kirx8U1Cww"
   },
   "outputs": [],
   "source": [
    "model_br = MovielensModelBasicRanking()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "dzDwd1Rp1EbO"
   },
   "outputs": [],
   "source": [
    "model_br.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false
    },
    "id": "SieQYr041H90",
    "outputId": "5851b673-7e8a-4868-8de6-be40cd33efef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "8/8 [==============================] - 15s 1s/step - root_mean_squared_error: 2.1538 - loss: 4.2543 - regularization_loss: 0.0000e+00 - total_loss: 4.2543 - val_root_mean_squared_error: 1.1547 - val_loss: 1.3360 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1.3360\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.1460 - loss: 1.3241 - regularization_loss: 0.0000e+00 - total_loss: 1.3241 - val_root_mean_squared_error: 1.2378 - val_loss: 1.5364 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1.5364\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.1957 - loss: 1.4229 - regularization_loss: 0.0000e+00 - total_loss: 1.4229 - val_root_mean_squared_error: 1.1992 - val_loss: 1.4418 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1.4418\n"
     ]
    }
   ],
   "source": [
    "history_br = model_br.fit(cached_train, epochs=3, validation_data=cached_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "hI7yE0XerkjM"
   },
   "source": [
    "The full model history contains quite a lot of information:\n",
    "\n",
    " - Loss = the value of the loss function\n",
    " - Regularization loss = 0, since we are not applying regularization in the basic model\n",
    " - Root mean squared error = the model performance metric we are recording\n",
    " - Total loss = loss + regularization loss, so the same as loss here\n",
    " - The same four again, but for the validation set instead of the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false
    },
    "id": "aUk4iIRG0Uqf",
    "outputId": "f548679f-70b7-4510-ce02-4168f7778054"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [1.2601068019866943, 1.4078688621520996, 1.3704522848129272],\n",
      " 'regularization_loss': [0, 0, 0],\n",
      " 'root_mean_squared_error': [2.1538093090057373,\n",
      "                             1.1459987163543701,\n",
      "                             1.1956913471221924],\n",
      " 'total_loss': [1.2601068019866943, 1.4078688621520996, 1.3704522848129272],\n",
      " 'val_loss': [1.335972547531128, 1.5363689661026, 1.441826581954956],\n",
      " 'val_regularization_loss': [0, 0, 0],\n",
      " 'val_root_mean_squared_error': [1.1546682119369507,\n",
      "                                 1.237779140472412,\n",
      "                                 1.199165940284729],\n",
      " 'val_total_loss': [1.335972547531128, 1.5363689661026, 1.441826581954956]}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(history_br.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "Zs6U0oW5sVl8"
   },
   "source": [
    "We can report the most relevant numbers from the history, and make a simple plot of the tuning. Here we look at the value of the performance metric.\n",
    "\n",
    "The model has a performance of root mean squared error (RMSE) between predicted and true user ratings of movies of about 1.1, and the value is similar for training and validation, indicating that with the short training duration here the model has not overfit.\n",
    "\n",
    "A more sophisticated option than making these plots would be to load and use TensorBoard, but the overall conclusion drawn would be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false
    },
    "id": "VY8Bt23jJAp1",
    "outputId": "13dbf653-a882-45cf-f0df-b225956c448c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error in user rating from training: 1.20\n",
      "Root mean squared error in user rating from validation: 1.20\n"
     ]
    }
   ],
   "source": [
    "rmse_br = history_br.history['root_mean_squared_error'][-1]\n",
    "print(f'Root mean squared error in user rating from training: {rmse_br:.2f}')\n",
    "\n",
    "val_rmse_br = history_br.history['val_root_mean_squared_error'][-1]\n",
    "print(f'Root mean squared error in user rating from validation: {val_rmse_br:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "bFCCtUTyJnBF"
   },
   "outputs": [],
   "source": [
    "# This sets up the x axis of the plot\n",
    "num_validation_runs = len(history_br.history['root_mean_squared_error']) # Or val_ ; is same here\n",
    "\n",
    "# The TFRS tutorials include values of validation frequency >1 to accommodate training runs where it was set >1 for faster training\n",
    "# Here it is left as 1\n",
    "validation_freq = 1\n",
    "epochs = [(x + 1) * validation_freq for x in range(num_validation_runs)] # E.g., 3,6,9 ... if validation_freq = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 308
    },
    "gradient": {
     "editing": false
    },
    "id": "FOZthVRbJ5iW",
    "outputId": "884a1cdc-52e7-4edb-f04f-523c3fd64fdb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f5ae8409780>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Simple plot with Matplotlib\n",
    "plt.plot(epochs, history_br.history['root_mean_squared_error'], label='Training')\n",
    "plt.plot(epochs, history_br.history['val_root_mean_squared_error'], label='Validation')\n",
    "plt.title('Root mean squared error in user rating vs. training epoch')\n",
    "plt.xlabel('Training epoch')\n",
    "plt.ylabel('Root mean squared error in user rating')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "2n7xDu0C1JCg"
   },
   "source": [
    "We can see the model architecture via `.summary()`, showing the deep learning layers. Even for this small model, the number of parameters is over 100,000, which is greater than the number of movies in the dataset. This shows the importance of setting up the model to not overfit when trained for longer, which we will do in the tuned model below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false
    },
    "id": "v44Elq721cSy",
    "outputId": "a2fb073d-eae5-4c62-954f-b3a17b6d42eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"movielens_model_basic_ranking\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential (Sequential)      (None, 32)                53280     \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 32)                30208     \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, 1)                 33153     \n",
      "_________________________________________________________________\n",
      "ranking (Ranking)            multiple                  2         \n",
      "=================================================================\n",
      "Total params: 116,643\n",
      "Trainable params: 116,641\n",
      "Non-trainable params: 2\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_br.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "XoBOlpc4-_hG"
   },
   "source": [
    "The model's performance can be measured on unseen test data for which what the user did in fact rate the movie (the ground truth) is still available.\n",
    "\n",
    "It is important that the test data is not used as part of the model training or validation, either directly (overlap between training and testing data), or indirectly (performance on testing data being used to influence subsequent training runs).\n",
    "\n",
    "Both of these would produce a result biased high in performance compared to expected performance on new unseen data when the model is deployed in production.\n",
    "\n",
    "As expected following the validation, the RMSE on the unseen testing set is also approximately 1.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false
    },
    "id": "bt8TsSix1cXX",
    "outputId": "0f7c32fe-4a23-472b-db4c-6068fd087cc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 6s 13ms/step - root_mean_squared_error: 1.1413 - loss: 1.3029 - regularization_loss: 0.0000e+00 - total_loss: 1.3029\n"
     ]
    }
   ],
   "source": [
    "eval_br = model_br.evaluate(cached_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false
    },
    "id": "Pp84Btjd3Ovt",
    "outputId": "766d686e-80a5-4211-ee8a-607345432fc3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'root_mean_squared_error': 1.1412544250488281,\n",
       " 'loss': 1.30448579788208,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 1.30448579788208}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_br"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false
    },
    "id": "kHu2-zfTKL34",
    "outputId": "9eb7222a-45ee-42a8-cd06-8172078e06c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error in user rating from evaluation: 1.14\n"
     ]
    }
   ],
   "source": [
    "rmse_eval_br = eval_br['root_mean_squared_error']\n",
    "print(f'Root mean squared error in user rating from evaluation: {rmse_eval_br:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "rWqyrily-JE6"
   },
   "source": [
    "Calling `.predict()` on the model, i.e., sending it data from the testing set in the same manner as new data would be sent to it when deployed, yields the user & movie embeddings for each new data point, and the predicted user ratings for those data points.\n",
    "\n",
    "Here the testing data still has ground truth user ratings that these predictions can be compared to (as in evaluate, above), but of course in production the return will be just the predicted ratings (and embeddings, in this case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false
    },
    "id": "eA7_9Lgi1cav",
    "outputId": "5a39f4c6-50c2-4643-cf8e-082b4e215c8a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.01111712,  0.0342272 , -0.03558037, ...,  0.02093932,\n",
       "          0.0499819 ,  0.03310004],\n",
       "        [ 0.03682995, -0.00292829, -0.01203686, ..., -0.02694032,\n",
       "         -0.04817913, -0.01506655],\n",
       "        [-0.02005151,  0.04311559,  0.02915088, ..., -0.01426794,\n",
       "         -0.02800677,  0.00755465],\n",
       "        ...,\n",
       "        [ 0.00597314, -0.00417596, -0.01312952, ...,  0.04654224,\n",
       "          0.02042881, -0.00455733],\n",
       "        [ 0.01837805,  0.03272862, -0.00753467, ..., -0.00106486,\n",
       "          0.00688084, -0.01778299],\n",
       "        [ 0.01170737, -0.02230951,  0.02672443, ...,  0.04496305,\n",
       "          0.01577738,  0.04709944]], dtype=float32),\n",
       " array([[-0.01685286, -0.0241822 , -0.01624944, ...,  0.02533602,\n",
       "         -0.03852903, -0.00798178],\n",
       "        [ 0.01273345,  0.04116427, -0.01204921, ...,  0.04427261,\n",
       "          0.00770494,  0.04154444],\n",
       "        [-0.02010706,  0.00707144,  0.01014473, ...,  0.0358832 ,\n",
       "         -0.02845538, -0.04785193],\n",
       "        ...,\n",
       "        [ 0.03443922,  0.00560572, -0.02557607, ...,  0.03547254,\n",
       "         -0.03261461, -0.04252266],\n",
       "        [-0.02170203, -0.03458456,  0.04063766, ...,  0.02837485,\n",
       "         -0.04333948, -0.01993461],\n",
       "        [-0.00407333, -0.01227994,  0.02220105, ..., -0.02704033,\n",
       "          0.02687155,  0.01382274]], dtype=float32),\n",
       " array([[3.841122 ],\n",
       "        [3.9126573],\n",
       "        [3.9165623],\n",
       "        ...,\n",
       "        [3.8245552],\n",
       "        [3.7760606],\n",
       "        [3.8328166]], dtype=float32))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As written, the model prediction returns both the embeddings and predicted ratings\n",
    "model_br.predict(cached_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "5CNURtsNIfC2"
   },
   "source": [
    "### 4.2: Tuned ranking model\n",
    "\n",
    "For most machine learning models, a model that has not had its hyperparameters tuned is unlikely to be giving best performance. It would be a bit like choosing random clothes from a store instead of clothes that are your size.\n",
    "\n",
    "The combination of being able to be tuned to higher performance, and the ability to easily add new training set features of many different kinds (categorical, numerical, text, time series, etc.) is what enables deep learning (or other nonlinear ML such as decision trees) to outperform classical non-ML methods on complex data. As written, the deep learning layers component of the model can be whatever arbitrary set of layers, so long as it outputs a single rating at the end.\n",
    "\n",
    "Here we perform some basic tuning on the neural network layer by training it for more epochs and allowing its initial learning rate to vary. We also add regularization to help avoid overfitting that could result from longer training.\n",
    "\n",
    "For more extensive tuning, other parameters can be tuned similarly, including within the network, e.g., size & number of layers, and within the whole model, such as the number of dimensions in the embeddings.\n",
    "\n",
    "If one plans to do more extensive tuning, then for a recommender system like this one, it also makes sense to include more features, such as user age, do more feature engineering, such as cyclic and not absolute times like day of week, and to build more complex models like multitask and deep cross networks as in the TFRS tutorials. To keep this showcase to a manageable length, we do not attempt all of that here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [],
   "source": [
    "# This model is similar to the basic model, but L2 regularization has been added\n",
    "\n",
    "class MovielensModelTunedRanking(tfrs.models.Model):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        embedding_dimension = 32\n",
    "\n",
    "        self.movie_model: tf.keras.layers.Layer = tf.keras.Sequential([\n",
    "            tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                vocabulary=unique_movie_titles, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(unique_movie_titles) + 1, embedding_dimension)\n",
    "        ])\n",
    "\n",
    "        self.user_model: tf.keras.layers.Layer = tf.keras.Sequential([\n",
    "            tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                vocabulary=unique_user_ids, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "        ])\n",
    "\n",
    "        # Regularization is added here\n",
    "        self.rating_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "            tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "            tf.keras.layers.Dense(1)\n",
    "        ])\n",
    "\n",
    "        self.task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
    "            loss = tf.keras.losses.MeanSquaredError(),\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    "        )\n",
    "\n",
    "    def call(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:\n",
    "\n",
    "        user_embeddings = self.user_model(features['user_id'])\n",
    "        movie_embeddings = self.movie_model(features['movie_title'])\n",
    "\n",
    "        return (\n",
    "            user_embeddings,\n",
    "            movie_embeddings,\n",
    "            self.rating_model(\n",
    "                tf.concat([user_embeddings, movie_embeddings], axis=1)\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "\n",
    "        ratings = features.pop('user_rating')\n",
    "        user_embeddings, movie_embeddings, rating_predictions = self(features)\n",
    "\n",
    "        rating_loss = self.task(\n",
    "            labels=ratings,\n",
    "            predictions=rating_predictions,\n",
    "        )\n",
    "\n",
    "        return rating_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "HVp_55ctAF48"
   },
   "source": [
    "When tuning hyperparameters using the grid approach, it is common to test a range of values across a logarithmic scale, then fine-tune by using a linear scale in the range suggested to be best by the logarithmic scale. (For example, try learning rates of 0.01, 0.02, 0.05, 0.1, 0.2, 0.5, and 1, and if the performance is best for 0.1, then try 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13, 0.14, and 0.15.)\n",
    "\n",
    "Here we only show a small number of values to avoid excessive processing time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "0WH4-3S7HOCC"
   },
   "source": [
    "Let's set the values we are tuning so they are not hidden in the calls to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "o2fF4CN5HUj0"
   },
   "outputs": [],
   "source": [
    "learning_rates_logarithmic = [0.001, 0.01, 0.1, 1]\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "jvxCoGSDHxb-"
   },
   "source": [
    "Run the logarithmic grid. As with the basic model, the indicator of performance is the RMSE error, shown in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false
    },
    "id": "IIWlPgqD4Hr6",
    "outputId": "e051920a-cec9-4b54-d688-68dcf6a6c627",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate = 0.001\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 1s 30ms/step - root_mean_squared_error: 3.7003 - loss: 13.6703 - regularization_loss: 2.0611 - total_loss: 15.7314 - val_root_mean_squared_error: 3.5970 - val_loss: 12.9255 - val_regularization_loss: 2.0600 - val_total_loss: 14.9856\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 3.6684 - loss: 13.4396 - regularization_loss: 2.0590 - total_loss: 15.4987 - val_root_mean_squared_error: 3.5708 - val_loss: 12.7386 - val_regularization_loss: 2.0580 - val_total_loss: 14.7966\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s 34ms/step - root_mean_squared_error: 3.6437 - loss: 13.2602 - regularization_loss: 2.0570 - total_loss: 15.3172 - val_root_mean_squared_error: 3.5479 - val_loss: 12.5760 - val_regularization_loss: 2.0560 - val_total_loss: 14.6319\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s 17ms/step - root_mean_squared_error: 3.6215 - loss: 13.0997 - regularization_loss: 2.0550 - total_loss: 15.1547 - val_root_mean_squared_error: 3.5268 - val_loss: 12.4265 - val_regularization_loss: 2.0540 - val_total_loss: 14.4806\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 3.6007 - loss: 12.9501 - regularization_loss: 2.0531 - total_loss: 15.0032 - val_root_mean_squared_error: 3.5066 - val_loss: 12.2849 - val_regularization_loss: 2.0521 - val_total_loss: 14.3370\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 3.5807 - loss: 12.8067 - regularization_loss: 2.0512 - total_loss: 14.8579 - val_root_mean_squared_error: 3.4870 - val_loss: 12.1477 - val_regularization_loss: 2.0503 - val_total_loss: 14.1980\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 3.5611 - loss: 12.6667 - regularization_loss: 2.0494 - total_loss: 14.7160 - val_root_mean_squared_error: 3.4676 - val_loss: 12.0129 - val_regularization_loss: 2.0484 - val_total_loss: 14.0613\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 3.5416 - loss: 12.5282 - regularization_loss: 2.0476 - total_loss: 14.5757 - val_root_mean_squared_error: 3.4482 - val_loss: 11.8790 - val_regularization_loss: 2.0467 - val_total_loss: 13.9256\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 3.5220 - loss: 12.3901 - regularization_loss: 2.0458 - total_loss: 14.4359 - val_root_mean_squared_error: 3.4287 - val_loss: 11.7451 - val_regularization_loss: 2.0449 - val_total_loss: 13.7900\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 3.5023 - loss: 12.2518 - regularization_loss: 2.0441 - total_loss: 14.2958 - val_root_mean_squared_error: 3.4090 - val_loss: 11.6106 - val_regularization_loss: 2.0432 - val_total_loss: 13.6538\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 3.4824 - loss: 12.1126 - regularization_loss: 2.0424 - total_loss: 14.1550 - val_root_mean_squared_error: 3.3891 - val_loss: 11.4751 - val_regularization_loss: 2.0416 - val_total_loss: 13.5166\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 3.4622 - loss: 11.9723 - regularization_loss: 2.0408 - total_loss: 14.0130 - val_root_mean_squared_error: 3.3688 - val_loss: 11.3383 - val_regularization_loss: 2.0399 - val_total_loss: 13.3783\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 3.4417 - loss: 11.8305 - regularization_loss: 2.0392 - total_loss: 13.8696 - val_root_mean_squared_error: 3.3482 - val_loss: 11.2002 - val_regularization_loss: 2.0383 - val_total_loss: 13.2385\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s 17ms/step - root_mean_squared_error: 3.4208 - loss: 11.6870 - regularization_loss: 2.0376 - total_loss: 13.7246 - val_root_mean_squared_error: 3.3273 - val_loss: 11.0603 - val_regularization_loss: 2.0368 - val_total_loss: 13.0971\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 3.3995 - loss: 11.5417 - regularization_loss: 2.0361 - total_loss: 13.5777 - val_root_mean_squared_error: 3.3059 - val_loss: 10.9187 - val_regularization_loss: 2.0353 - val_total_loss: 12.9540\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 3.3777 - loss: 11.3944 - regularization_loss: 2.0346 - total_loss: 13.4290 - val_root_mean_squared_error: 3.2841 - val_loss: 10.7752 - val_regularization_loss: 2.0338 - val_total_loss: 12.8090\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 3.3556 - loss: 11.2451 - regularization_loss: 2.0331 - total_loss: 13.2782 - val_root_mean_squared_error: 3.2619 - val_loss: 10.6298 - val_regularization_loss: 2.0324 - val_total_loss: 12.6622\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 3.3330 - loss: 11.0937 - regularization_loss: 2.0317 - total_loss: 13.1254 - val_root_mean_squared_error: 3.2392 - val_loss: 10.4825 - val_regularization_loss: 2.0310 - val_total_loss: 12.5135\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 3.3099 - loss: 10.9402 - regularization_loss: 2.0303 - total_loss: 12.9705 - val_root_mean_squared_error: 3.2161 - val_loss: 10.3332 - val_regularization_loss: 2.0296 - val_total_loss: 12.3628\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 3.2863 - loss: 10.7846 - regularization_loss: 2.0289 - total_loss: 12.8135 - val_root_mean_squared_error: 3.1925 - val_loss: 10.1821 - val_regularization_loss: 2.0282 - val_total_loss: 12.2103\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s 17ms/step - root_mean_squared_error: 3.2622 - loss: 10.6269 - regularization_loss: 2.0276 - total_loss: 12.6545 - val_root_mean_squared_error: 3.1684 - val_loss: 10.0290 - val_regularization_loss: 2.0269 - val_total_loss: 12.0559\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 3.2376 - loss: 10.4672 - regularization_loss: 2.0263 - total_loss: 12.4935 - val_root_mean_squared_error: 3.1438 - val_loss: 9.8741 - val_regularization_loss: 2.0256 - val_total_loss: 11.8998\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 3.2126 - loss: 10.3056 - regularization_loss: 2.0250 - total_loss: 12.3307 - val_root_mean_squared_error: 3.1188 - val_loss: 9.7176 - val_regularization_loss: 2.0244 - val_total_loss: 11.7420\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 3.1871 - loss: 10.1423 - regularization_loss: 2.0238 - total_loss: 12.1660 - val_root_mean_squared_error: 3.0933 - val_loss: 9.5594 - val_regularization_loss: 2.0232 - val_total_loss: 11.5826\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 3.1611 - loss: 9.9772 - regularization_loss: 2.0226 - total_loss: 11.9997 - val_root_mean_squared_error: 3.0674 - val_loss: 9.3998 - val_regularization_loss: 2.0220 - val_total_loss: 11.4217\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 3.1346 - loss: 9.8105 - regularization_loss: 2.0214 - total_loss: 11.8319 - val_root_mean_squared_error: 3.0410 - val_loss: 9.2388 - val_regularization_loss: 2.0208 - val_total_loss: 11.2596\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 3.1077 - loss: 9.6424 - regularization_loss: 2.0203 - total_loss: 11.6627 - val_root_mean_squared_error: 3.0142 - val_loss: 9.0765 - val_regularization_loss: 2.0197 - val_total_loss: 11.0962\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 3.0803 - loss: 9.4731 - regularization_loss: 2.0191 - total_loss: 11.4922 - val_root_mean_squared_error: 2.9870 - val_loss: 8.9133 - val_regularization_loss: 2.0186 - val_total_loss: 10.9319\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 3.0525 - loss: 9.3027 - regularization_loss: 2.0180 - total_loss: 11.3207 - val_root_mean_squared_error: 2.9594 - val_loss: 8.7492 - val_regularization_loss: 2.0175 - val_total_loss: 10.7666\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 3.0243 - loss: 9.1313 - regularization_loss: 2.0170 - total_loss: 11.1483 - val_root_mean_squared_error: 2.9314 - val_loss: 8.5843 - val_regularization_loss: 2.0164 - val_total_loss: 10.6007\n",
      "Learning rate = 0.01\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 1s 29ms/step - root_mean_squared_error: 3.3446 - loss: 10.8784 - regularization_loss: 2.0212 - total_loss: 12.8996 - val_root_mean_squared_error: 2.7048 - val_loss: 7.3085 - val_regularization_loss: 2.0153 - val_total_loss: 9.3238\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 2.2532 - loss: 4.8129 - regularization_loss: 2.0145 - total_loss: 6.8273 - val_root_mean_squared_error: 1.4972 - val_loss: 2.2398 - val_regularization_loss: 2.0143 - val_total_loss: 4.2541\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.2996 - loss: 1.6457 - regularization_loss: 2.0112 - total_loss: 3.6569 - val_root_mean_squared_error: 1.1413 - val_loss: 1.3041 - val_regularization_loss: 2.0057 - val_total_loss: 3.3098\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1291 - loss: 1.2722 - regularization_loss: 1.9975 - total_loss: 3.2697 - val_root_mean_squared_error: 1.1359 - val_loss: 1.2925 - val_regularization_loss: 1.9881 - val_total_loss: 3.2806\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.1227 - loss: 1.2589 - regularization_loss: 1.9788 - total_loss: 3.2377 - val_root_mean_squared_error: 1.1365 - val_loss: 1.2938 - val_regularization_loss: 1.9689 - val_total_loss: 3.2626\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s 17ms/step - root_mean_squared_error: 1.1212 - loss: 1.2557 - regularization_loss: 1.9595 - total_loss: 3.2152 - val_root_mean_squared_error: 1.1362 - val_loss: 1.2930 - val_regularization_loss: 1.9496 - val_total_loss: 3.2426\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.1199 - loss: 1.2528 - regularization_loss: 1.9403 - total_loss: 3.1931 - val_root_mean_squared_error: 1.1357 - val_loss: 1.2921 - val_regularization_loss: 1.9305 - val_total_loss: 3.2226\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s 18ms/step - root_mean_squared_error: 1.1186 - loss: 1.2499 - regularization_loss: 1.9213 - total_loss: 3.1713 - val_root_mean_squared_error: 1.1353 - val_loss: 1.2911 - val_regularization_loss: 1.9116 - val_total_loss: 3.2027\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.1173 - loss: 1.2471 - regularization_loss: 1.9026 - total_loss: 3.1496 - val_root_mean_squared_error: 1.1349 - val_loss: 1.2901 - val_regularization_loss: 1.8930 - val_total_loss: 3.1831\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1161 - loss: 1.2442 - regularization_loss: 1.8840 - total_loss: 3.1282 - val_root_mean_squared_error: 1.1345 - val_loss: 1.2892 - val_regularization_loss: 1.8745 - val_total_loss: 3.1637\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1148 - loss: 1.2413 - regularization_loss: 1.8656 - total_loss: 3.1070 - val_root_mean_squared_error: 1.1341 - val_loss: 1.2883 - val_regularization_loss: 1.8563 - val_total_loss: 3.1445\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1134 - loss: 1.2384 - regularization_loss: 1.8475 - total_loss: 3.0859 - val_root_mean_squared_error: 1.1337 - val_loss: 1.2873 - val_regularization_loss: 1.8382 - val_total_loss: 3.1255\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s 17ms/step - root_mean_squared_error: 1.1121 - loss: 1.2354 - regularization_loss: 1.8295 - total_loss: 3.0649 - val_root_mean_squared_error: 1.1333 - val_loss: 1.2864 - val_regularization_loss: 1.8204 - val_total_loss: 3.1068\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1107 - loss: 1.2323 - regularization_loss: 1.8118 - total_loss: 3.0441 - val_root_mean_squared_error: 1.1329 - val_loss: 1.2855 - val_regularization_loss: 1.8027 - val_total_loss: 3.0882\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1093 - loss: 1.2291 - regularization_loss: 1.7942 - total_loss: 3.0234 - val_root_mean_squared_error: 1.1324 - val_loss: 1.2845 - val_regularization_loss: 1.7853 - val_total_loss: 3.0698\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.1078 - loss: 1.2258 - regularization_loss: 1.7769 - total_loss: 3.0027 - val_root_mean_squared_error: 1.1320 - val_loss: 1.2836 - val_regularization_loss: 1.7680 - val_total_loss: 3.0516\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.1062 - loss: 1.2224 - regularization_loss: 1.7597 - total_loss: 2.9822 - val_root_mean_squared_error: 1.1316 - val_loss: 1.2826 - val_regularization_loss: 1.7510 - val_total_loss: 3.0336\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 0s 34ms/step - root_mean_squared_error: 1.1046 - loss: 1.2189 - regularization_loss: 1.7428 - total_loss: 2.9617 - val_root_mean_squared_error: 1.1312 - val_loss: 1.2816 - val_regularization_loss: 1.7341 - val_total_loss: 3.0158\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s 17ms/step - root_mean_squared_error: 1.1030 - loss: 1.2152 - regularization_loss: 1.7260 - total_loss: 2.9413 - val_root_mean_squared_error: 1.1307 - val_loss: 1.2806 - val_regularization_loss: 1.7175 - val_total_loss: 2.9981\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1013 - loss: 1.2114 - regularization_loss: 1.7094 - total_loss: 2.9209 - val_root_mean_squared_error: 1.1303 - val_loss: 1.2796 - val_regularization_loss: 1.7010 - val_total_loss: 2.9806\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s 17ms/step - root_mean_squared_error: 1.0995 - loss: 1.2075 - regularization_loss: 1.6931 - total_loss: 2.9006 - val_root_mean_squared_error: 1.1298 - val_loss: 1.2786 - val_regularization_loss: 1.6847 - val_total_loss: 2.9633\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s 17ms/step - root_mean_squared_error: 1.0976 - loss: 1.2034 - regularization_loss: 1.6769 - total_loss: 2.8803 - val_root_mean_squared_error: 1.1294 - val_loss: 1.2775 - val_regularization_loss: 1.6686 - val_total_loss: 2.9461\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.0957 - loss: 1.1992 - regularization_loss: 1.6609 - total_loss: 2.8600 - val_root_mean_squared_error: 1.1289 - val_loss: 1.2764 - val_regularization_loss: 1.6527 - val_total_loss: 2.9291\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.0936 - loss: 1.1947 - regularization_loss: 1.6450 - total_loss: 2.8398 - val_root_mean_squared_error: 1.1284 - val_loss: 1.2753 - val_regularization_loss: 1.6370 - val_total_loss: 2.9123\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.0916 - loss: 1.1902 - regularization_loss: 1.6294 - total_loss: 2.8196 - val_root_mean_squared_error: 1.1279 - val_loss: 1.2742 - val_regularization_loss: 1.6214 - val_total_loss: 2.8956\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.0894 - loss: 1.1855 - regularization_loss: 1.6139 - total_loss: 2.7994 - val_root_mean_squared_error: 1.1274 - val_loss: 1.2730 - val_regularization_loss: 1.6061 - val_total_loss: 2.8791\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.0872 - loss: 1.1806 - regularization_loss: 1.5987 - total_loss: 2.7793 - val_root_mean_squared_error: 1.1268 - val_loss: 1.2718 - val_regularization_loss: 1.5909 - val_total_loss: 2.8627\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.0848 - loss: 1.1756 - regularization_loss: 1.5836 - total_loss: 2.7592 - val_root_mean_squared_error: 1.1263 - val_loss: 1.2705 - val_regularization_loss: 1.5759 - val_total_loss: 2.8464\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s 17ms/step - root_mean_squared_error: 1.0825 - loss: 1.1705 - regularization_loss: 1.5687 - total_loss: 2.7391 - val_root_mean_squared_error: 1.1257 - val_loss: 1.2692 - val_regularization_loss: 1.5610 - val_total_loss: 2.8303\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.0800 - loss: 1.1652 - regularization_loss: 1.5539 - total_loss: 2.7191 - val_root_mean_squared_error: 1.1251 - val_loss: 1.2679 - val_regularization_loss: 1.5464 - val_total_loss: 2.8143\n",
      "Learning rate = 0.1\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 1s 29ms/step - root_mean_squared_error: 2.2890 - loss: 4.8440 - regularization_loss: 1.9580 - total_loss: 6.8020 - val_root_mean_squared_error: 1.2647 - val_loss: 1.6042 - val_regularization_loss: 1.8719 - val_total_loss: 3.4762\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1772 - loss: 1.3735 - regularization_loss: 1.7797 - total_loss: 3.1532 - val_root_mean_squared_error: 1.1611 - val_loss: 1.3514 - val_regularization_loss: 1.6927 - val_total_loss: 3.0440\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1116 - loss: 1.2325 - regularization_loss: 1.6127 - total_loss: 2.8452 - val_root_mean_squared_error: 1.1348 - val_loss: 1.2903 - val_regularization_loss: 1.5327 - val_total_loss: 2.8230\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.0980 - loss: 1.2040 - regularization_loss: 1.4626 - total_loss: 2.6665 - val_root_mean_squared_error: 1.1288 - val_loss: 1.2762 - val_regularization_loss: 1.3897 - val_total_loss: 2.6659\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.0939 - loss: 1.1954 - regularization_loss: 1.3280 - total_loss: 2.5234 - val_root_mean_squared_error: 1.1296 - val_loss: 1.2776 - val_regularization_loss: 1.2616 - val_total_loss: 2.5392\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s 17ms/step - root_mean_squared_error: 1.0907 - loss: 1.1873 - regularization_loss: 1.2071 - total_loss: 2.3944 - val_root_mean_squared_error: 1.1282 - val_loss: 1.2742 - val_regularization_loss: 1.1470 - val_total_loss: 2.4212\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.0778 - loss: 1.1586 - regularization_loss: 1.0984 - total_loss: 2.2570 - val_root_mean_squared_error: 1.1217 - val_loss: 1.2598 - val_regularization_loss: 1.0444 - val_total_loss: 2.3042\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.0611 - loss: 1.1232 - regularization_loss: 1.0006 - total_loss: 2.1238 - val_root_mean_squared_error: 1.1154 - val_loss: 1.2458 - val_regularization_loss: 0.9520 - val_total_loss: 2.1978\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.0468 - loss: 1.0934 - regularization_loss: 0.9124 - total_loss: 2.0059 - val_root_mean_squared_error: 1.1093 - val_loss: 1.2321 - val_regularization_loss: 0.8686 - val_total_loss: 2.1007\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.0346 - loss: 1.0682 - regularization_loss: 0.8330 - total_loss: 1.9012 - val_root_mean_squared_error: 1.1028 - val_loss: 1.2175 - val_regularization_loss: 0.7933 - val_total_loss: 2.0108\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.0236 - loss: 1.0455 - regularization_loss: 0.7614 - total_loss: 1.8069 - val_root_mean_squared_error: 1.0959 - val_loss: 1.2021 - val_regularization_loss: 0.7254 - val_total_loss: 1.9276\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.0131 - loss: 1.0243 - regularization_loss: 0.6967 - total_loss: 1.7211 - val_root_mean_squared_error: 1.0890 - val_loss: 1.1867 - val_regularization_loss: 0.6641 - val_total_loss: 1.8508\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.0034 - loss: 1.0047 - regularization_loss: 0.6383 - total_loss: 1.6430 - val_root_mean_squared_error: 1.0823 - val_loss: 1.1720 - val_regularization_loss: 0.6087 - val_total_loss: 1.7807\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 0.9944 - loss: 0.9867 - regularization_loss: 0.5855 - total_loss: 1.5722 - val_root_mean_squared_error: 1.0762 - val_loss: 1.1586 - val_regularization_loss: 0.5585 - val_total_loss: 1.7171\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 0.9863 - loss: 0.9708 - regularization_loss: 0.5375 - total_loss: 1.5083 - val_root_mean_squared_error: 1.0708 - val_loss: 1.1467 - val_regularization_loss: 0.5129 - val_total_loss: 1.6597\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 0.9792 - loss: 0.9569 - regularization_loss: 0.4939 - total_loss: 1.4508 - val_root_mean_squared_error: 1.0661 - val_loss: 1.1364 - val_regularization_loss: 0.4715 - val_total_loss: 1.6079\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 0.9730 - loss: 0.9448 - regularization_loss: 0.4543 - total_loss: 1.3991 - val_root_mean_squared_error: 1.0620 - val_loss: 1.1276 - val_regularization_loss: 0.4339 - val_total_loss: 1.5615\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 0s 18ms/step - root_mean_squared_error: 0.9676 - loss: 0.9343 - regularization_loss: 0.4184 - total_loss: 1.3527 - val_root_mean_squared_error: 1.0585 - val_loss: 1.1200 - val_regularization_loss: 0.3996 - val_total_loss: 1.5196\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 0.9629 - loss: 0.9252 - regularization_loss: 0.3856 - total_loss: 1.3109 - val_root_mean_squared_error: 1.0555 - val_loss: 1.1135 - val_regularization_loss: 0.3685 - val_total_loss: 1.4820\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s 17ms/step - root_mean_squared_error: 0.9588 - loss: 0.9174 - regularization_loss: 0.3559 - total_loss: 1.2733 - val_root_mean_squared_error: 1.0530 - val_loss: 1.1079 - val_regularization_loss: 0.3403 - val_total_loss: 1.4482\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 0.9552 - loss: 0.9105 - regularization_loss: 0.3289 - total_loss: 1.2394 - val_root_mean_squared_error: 1.0507 - val_loss: 1.1030 - val_regularization_loss: 0.3146 - val_total_loss: 1.4176\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 0.9520 - loss: 0.9045 - regularization_loss: 0.3044 - total_loss: 1.2088 - val_root_mean_squared_error: 1.0488 - val_loss: 1.0987 - val_regularization_loss: 0.2913 - val_total_loss: 1.3901\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 0.9492 - loss: 0.8991 - regularization_loss: 0.2821 - total_loss: 1.1812 - val_root_mean_squared_error: 1.0471 - val_loss: 1.0950 - val_regularization_loss: 0.2702 - val_total_loss: 1.3652\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 0.9466 - loss: 0.8943 - regularization_loss: 0.2619 - total_loss: 1.1562 - val_root_mean_squared_error: 1.0456 - val_loss: 1.0917 - val_regularization_loss: 0.2509 - val_total_loss: 1.3427\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 0.9444 - loss: 0.8901 - regularization_loss: 0.2435 - total_loss: 1.1336 - val_root_mean_squared_error: 1.0443 - val_loss: 1.0888 - val_regularization_loss: 0.2335 - val_total_loss: 1.3223\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 0.9423 - loss: 0.8863 - regularization_loss: 0.2268 - total_loss: 1.1131 - val_root_mean_squared_error: 1.0431 - val_loss: 1.0862 - val_regularization_loss: 0.2176 - val_total_loss: 1.3039\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 0.9405 - loss: 0.8828 - regularization_loss: 0.2116 - total_loss: 1.0944 - val_root_mean_squared_error: 1.0421 - val_loss: 1.0839 - val_regularization_loss: 0.2033 - val_total_loss: 1.2872\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 0.9388 - loss: 0.8796 - regularization_loss: 0.1979 - total_loss: 1.0775 - val_root_mean_squared_error: 1.0411 - val_loss: 1.0818 - val_regularization_loss: 0.1902 - val_total_loss: 1.2720\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 0.9373 - loss: 0.8768 - regularization_loss: 0.1854 - total_loss: 1.0622 - val_root_mean_squared_error: 1.0403 - val_loss: 1.0800 - val_regularization_loss: 0.1783 - val_total_loss: 1.2583\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 0.9359 - loss: 0.8742 - regularization_loss: 0.1740 - total_loss: 1.0482 - val_root_mean_squared_error: 1.0396 - val_loss: 1.0783 - val_regularization_loss: 0.1675 - val_total_loss: 1.2458\n",
      "Learning rate = 1\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 1s 30ms/step - root_mean_squared_error: 261.1108 - loss: 62347.5883 - regularization_loss: 78.2082 - total_loss: 62425.8000 - val_root_mean_squared_error: 6.6873 - val_loss: 44.7779 - val_regularization_loss: 140.2825 - val_total_loss: 185.0604\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s 17ms/step - root_mean_squared_error: 217.2314 - loss: 42385.1809 - regularization_loss: 138.8803 - total_loss: 42524.0623 - val_root_mean_squared_error: 14.8475 - val_loss: 215.7061 - val_regularization_loss: 137.0531 - val_total_loss: 352.7592\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s 17ms/step - root_mean_squared_error: 7.9714 - loss: 60.3700 - regularization_loss: 135.8791 - total_loss: 196.2491 - val_root_mean_squared_error: 5.8840 - val_loss: 34.6001 - val_regularization_loss: 133.8884 - val_total_loss: 168.4885\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 5.9402 - loss: 35.2283 - regularization_loss: 131.7936 - total_loss: 167.0219 - val_root_mean_squared_error: 5.8270 - val_loss: 33.9321 - val_regularization_loss: 129.7231 - val_total_loss: 163.6553\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 5.8634 - loss: 34.3161 - regularization_loss: 128.0028 - total_loss: 162.3189 - val_root_mean_squared_error: 5.7570 - val_loss: 33.1219 - val_regularization_loss: 126.2777 - val_total_loss: 159.3996\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 5.7489 - loss: 32.9284 - regularization_loss: 124.8067 - total_loss: 157.7351 - val_root_mean_squared_error: 5.6863 - val_loss: 32.3179 - val_regularization_loss: 123.3175 - val_total_loss: 155.6354\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s 17ms/step - root_mean_squared_error: 4.9920 - loss: 23.6262 - regularization_loss: 122.0462 - total_loss: 145.6724 - val_root_mean_squared_error: 5.4253 - val_loss: 29.4254 - val_regularization_loss: 120.7793 - val_total_loss: 150.2047\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 3.3424 - loss: 11.0041 - regularization_loss: 119.6054 - total_loss: 130.6096 - val_root_mean_squared_error: 5.3498 - val_loss: 28.6177 - val_regularization_loss: 118.3960 - val_total_loss: 147.0137\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 2.8812 - loss: 8.1469 - regularization_loss: 117.3328 - total_loss: 125.4796 - val_root_mean_squared_error: 5.2618 - val_loss: 27.6909 - val_regularization_loss: 116.2461 - val_total_loss: 143.9370\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 2.4158 - loss: 5.7361 - regularization_loss: 115.2898 - total_loss: 121.0260 - val_root_mean_squared_error: 5.1815 - val_loss: 26.8531 - val_regularization_loss: 114.3086 - val_total_loss: 141.1618\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 2.1029 - loss: 4.3671 - regularization_loss: 113.4359 - total_loss: 117.8030 - val_root_mean_squared_error: 4.9837 - val_loss: 24.8597 - val_regularization_loss: 112.5366 - val_total_loss: 137.3963\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.9503 - loss: 3.7733 - regularization_loss: 111.7258 - total_loss: 115.4990 - val_root_mean_squared_error: 4.9421 - val_loss: 24.4497 - val_regularization_loss: 110.8871 - val_total_loss: 135.3368\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.8735 - loss: 3.4873 - regularization_loss: 110.1275 - total_loss: 113.6148 - val_root_mean_squared_error: 4.9326 - val_loss: 24.3520 - val_regularization_loss: 109.3409 - val_total_loss: 133.6929\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.8235 - loss: 3.3053 - regularization_loss: 108.6284 - total_loss: 111.9338 - val_root_mean_squared_error: 4.9302 - val_loss: 24.3249 - val_regularization_loss: 107.8893 - val_total_loss: 132.2142\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.7857 - loss: 3.1703 - regularization_loss: 107.2190 - total_loss: 110.3892 - val_root_mean_squared_error: 4.9296 - val_loss: 24.3142 - val_regularization_loss: 106.5220 - val_total_loss: 130.8362\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.7544 - loss: 3.0598 - regularization_loss: 105.8893 - total_loss: 108.9491 - val_root_mean_squared_error: 4.9292 - val_loss: 24.3066 - val_regularization_loss: 105.2309 - val_total_loss: 129.5375\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.7257 - loss: 2.9606 - regularization_loss: 104.6327 - total_loss: 107.5932 - val_root_mean_squared_error: 4.9280 - val_loss: 24.2920 - val_regularization_loss: 104.0097 - val_total_loss: 128.3017\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 0s 20ms/step - root_mean_squared_error: 1.6992 - loss: 2.8705 - regularization_loss: 103.4431 - total_loss: 106.3136 - val_root_mean_squared_error: 4.9259 - val_loss: 24.2688 - val_regularization_loss: 102.8530 - val_total_loss: 127.1218\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s 18ms/step - root_mean_squared_error: 1.6748 - loss: 2.7887 - regularization_loss: 102.3158 - total_loss: 105.1045 - val_root_mean_squared_error: 4.9238 - val_loss: 24.2457 - val_regularization_loss: 101.7554 - val_total_loss: 126.0011\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.6518 - loss: 2.7136 - regularization_loss: 101.2452 - total_loss: 103.9587 - val_root_mean_squared_error: 4.9215 - val_loss: 24.2216 - val_regularization_loss: 100.7118 - val_total_loss: 124.9333\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.6313 - loss: 2.6475 - regularization_loss: 100.2261 - total_loss: 102.8736 - val_root_mean_squared_error: 4.9191 - val_loss: 24.1965 - val_regularization_loss: 99.7175 - val_total_loss: 123.9140\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.6130 - loss: 2.5891 - regularization_loss: 99.2545 - total_loss: 101.8437 - val_root_mean_squared_error: 4.9163 - val_loss: 24.1691 - val_regularization_loss: 98.7688 - val_total_loss: 122.9379\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s 17ms/step - root_mean_squared_error: 1.5965 - loss: 2.5374 - regularization_loss: 98.3266 - total_loss: 100.8640 - val_root_mean_squared_error: 4.9135 - val_loss: 24.1406 - val_regularization_loss: 97.8619 - val_total_loss: 122.0025\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.5800 - loss: 2.4864 - regularization_loss: 97.4406 - total_loss: 99.9269 - val_root_mean_squared_error: 4.9107 - val_loss: 24.1139 - val_regularization_loss: 96.9963 - val_total_loss: 121.1103\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s 18ms/step - root_mean_squared_error: 1.5583 - loss: 2.4209 - regularization_loss: 96.5966 - total_loss: 99.0175 - val_root_mean_squared_error: 4.9066 - val_loss: 24.0823 - val_regularization_loss: 96.1718 - val_total_loss: 120.2542\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s 19ms/step - root_mean_squared_error: 1.5221 - loss: 2.3100 - regularization_loss: 95.7925 - total_loss: 98.1025 - val_root_mean_squared_error: 4.9000 - val_loss: 24.0226 - val_regularization_loss: 95.3829 - val_total_loss: 119.4055\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.4839 - loss: 2.1981 - regularization_loss: 95.0033 - total_loss: 97.2014 - val_root_mean_squared_error: 4.8930 - val_loss: 23.9495 - val_regularization_loss: 94.6031 - val_total_loss: 118.5526\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.4556 - loss: 2.1141 - regularization_loss: 94.2352 - total_loss: 96.3492 - val_root_mean_squared_error: 4.8865 - val_loss: 23.8887 - val_regularization_loss: 93.8514 - val_total_loss: 117.7401\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s 17ms/step - root_mean_squared_error: 1.4298 - loss: 2.0382 - regularization_loss: 93.4992 - total_loss: 95.5374 - val_root_mean_squared_error: 4.8808 - val_loss: 23.8399 - val_regularization_loss: 93.1297 - val_total_loss: 116.9696\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.4039 - loss: 1.9652 - regularization_loss: 92.7933 - total_loss: 94.7585 - val_root_mean_squared_error: 4.8745 - val_loss: 23.7831 - val_regularization_loss: 92.4383 - val_total_loss: 116.2214\n"
     ]
    }
   ],
   "source": [
    "# Store the training histories in a dictionary\n",
    "# This can probably be done better or more securely than here, because we are creating \n",
    "# variable names from values, but it serves the purpose here of plotting the tuning\n",
    "\n",
    "histories_tr = {}\n",
    "\n",
    "# For each learning rate:\n",
    "\n",
    "# - Create an instance of the model class that can be used as the model\n",
    "# - Compile the model to set its initial parameters\n",
    "# - Train the model using .fit, minimizing the loss on the neural network predictions of the user ratings\n",
    "\n",
    "for val in learning_rates_logarithmic:\n",
    "    print('Learning rate = {}'.format(val))\n",
    "    model_tr = MovielensModelTunedRanking()\n",
    "    model_tr.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=val))\n",
    "\n",
    "    lr = str(val)\n",
    "    histories_tr[lr] = model_tr.fit(cached_train, epochs=epochs, validation_data=cached_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "w_mymY1K_Dlz"
   },
   "source": [
    "As above, we can view and plot the tuning history, now for multiple hyperparameter tuning grid points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false
    },
    "id": "yWoxGpqX99tl",
    "outputId": "0ef9d914-47d8-4593-d9f1-5d18c0e18972"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0.001': <tensorflow.python.keras.callbacks.History at 0x7f5ae843d630>,\n",
       " '0.01': <tensorflow.python.keras.callbacks.History at 0x7f5ae83b0a58>,\n",
       " '0.1': <tensorflow.python.keras.callbacks.History at 0x7f5afc087ac8>,\n",
       " '1': <tensorflow.python.keras.callbacks.History at 0x7f5ae872bac8>}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All 4 histories\n",
    "histories_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false
    },
    "id": "XgssZ1Tm-JDv",
    "outputId": "83900cad-51a5-4642-89ba-c0754ab8c1a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [1.762627124786377, 1.27882719039917, 1.2089080810546875,\n",
      "          1.1910356283187866, 1.1852569580078125, 1.1688036918640137,\n",
      "          1.1348143815994263, 1.1025407314300537, 1.0754719972610474,\n",
      "          1.0513532161712646, 1.028888463973999, 1.0077794790267944,\n",
      "          0.9882305264472961, 0.9706097841262817, 0.9550227522850037,\n",
      "          0.9414154887199402, 0.9296673536300659, 0.9195032119750977,\n",
      "          0.9106879234313965, 0.9030314683914185, 0.8963359594345093,\n",
      "          0.8904510140419006, 0.8852168321609497, 0.8805525302886963,\n",
      "          0.8763761520385742, 0.8726167678833008, 0.8692119121551514,\n",
      "          0.8661321997642517, 0.8633233904838562, 0.8607590198516846],\n",
      " 'regularization_loss': [1.8833727836608887, 1.709684133529663,\n",
      "                         1.5512652397155762, 1.4084283113479614,\n",
      "                         1.2802670001983643, 1.1646971702575684,\n",
      "                         1.0602525472640991, 0.9661356806755066,\n",
      "                         0.8814136385917664, 0.8051096796989441,\n",
      "                         0.7363383173942566, 0.6742603182792664,\n",
      "                         0.6181073784828186, 0.5672097206115723,\n",
      "                         0.5210040211677551, 0.4790118634700775,\n",
      "                         0.44083353877067566, 0.4061235785484314,\n",
      "                         0.37457412481307983, 0.3459088206291199,\n",
      "                         0.31986862421035767, 0.2962194085121155,\n",
      "                         0.27474555373191833, 0.25524279475212097,\n",
      "                         0.23753470182418823, 0.22145286202430725,\n",
      "                         0.20684660971164703, 0.1935809850692749,\n",
      "                         0.18152524530887604, 0.1705697625875473],\n",
      " 'root_mean_squared_error': [2.289046049118042, 1.1771577596664429,\n",
      "                             1.1115610599517822, 1.0980154275894165,\n",
      "                             1.093927264213562, 1.0907137393951416,\n",
      "                             1.077783226966858, 1.0610603094100952,\n",
      "                             1.046777606010437, 1.0346107482910156,\n",
      "                             1.0235512256622314, 1.0131421089172363,\n",
      "                             1.0033774375915527, 0.9943932294845581,\n",
      "                             0.9863340854644775, 0.9792006611824036,\n",
      "                             0.9729844927787781, 0.9675800800323486,\n",
      "                             0.9628666043281555, 0.958757758140564,\n",
      "                             0.9551514983177185, 0.9519810676574707,\n",
      "                             0.9491576552391052, 0.9466348886489868,\n",
      "                             0.9443740248680115, 0.9423385262489319,\n",
      "                             0.9404929280281067, 0.9388144612312317,\n",
      "                             0.9372864961624146, 0.9358880519866943],\n",
      " 'total_loss': [3.6459999084472656, 2.988511323928833, 2.7601733207702637,\n",
      "                2.599463939666748, 2.4655239582061768, 2.333500862121582,\n",
      "                2.1950669288635254, 2.068676471710205, 1.956885576248169,\n",
      "                1.8564629554748535, 1.7652268409729004, 1.682039737701416,\n",
      "                1.6063379049301147, 1.537819504737854, 1.4760267734527588,\n",
      "                1.4204273223876953, 1.370500922203064, 1.3256268501281738,\n",
      "                1.285262107849121, 1.2489402294158936, 1.2162046432495117,\n",
      "                1.1866704225540161, 1.1599624156951904, 1.1357953548431396,\n",
      "                1.1139109134674072, 1.0940696001052856, 1.0760585069656372,\n",
      "                1.0597131252288818, 1.0448486804962158, 1.031328797340393],\n",
      " 'val_loss': [1.6042264699935913, 1.3513578176498413, 1.2903485298156738,\n",
      "              1.2762088775634766, 1.2776464223861694, 1.27419912815094,\n",
      "              1.259826421737671, 1.2458175420761108, 1.232138752937317,\n",
      "              1.2175116539001465, 1.2021178007125854, 1.1866992712020874,\n",
      "              1.1720060110092163, 1.1586028337478638, 1.1467399597167969,\n",
      "              1.1364425420761108, 1.1275955438613892, 1.1200101375579834,\n",
      "              1.1134916543960571, 1.1078695058822632, 1.1029906272888184,\n",
      "              1.09873628616333, 1.0950082540512085, 1.091720461845398,\n",
      "              1.0888092517852783, 1.0862199068069458, 1.0839091539382935,\n",
      "              1.0818350315093994, 1.0799734592437744, 1.0782928466796875],\n",
      " 'val_regularization_loss': [1.8719346523284912, 1.6926913261413574,\n",
      "                             1.5326679944992065, 1.38970148563385,\n",
      "                             1.2615903615951538, 1.1470091342926025,\n",
      "                             1.0444021224975586, 0.9519760012626648,\n",
      "                             0.8685702085494995, 0.7933182120323181,\n",
      "                             0.7254354953765869, 0.6641483306884766,\n",
      "                             0.6087190508842468, 0.5584917664527893,\n",
      "                             0.5129101276397705, 0.4714999198913574,\n",
      "                             0.4338560402393341, 0.3996390402317047,\n",
      "                             0.3685440123081207, 0.34029173851013184,\n",
      "                             0.31462952494621277, 0.2913235127925873,\n",
      "                             0.27016207575798035, 0.2509452700614929,\n",
      "                             0.23349589109420776, 0.2176496833562851,\n",
      "                             0.20325830578804016, 0.19018563628196716,\n",
      "                             0.17830677330493927, 0.16751188039779663],\n",
      " 'val_root_mean_squared_error': [1.2646777629852295, 1.1610608100891113,\n",
      "                                 1.1348239183425903, 1.1287872791290283,\n",
      "                                 1.1296191215515137, 1.1281509399414062,\n",
      "                                 1.121716022491455, 1.1154413223266602,\n",
      "                                 1.109337568283081, 1.1028119325637817,\n",
      "                                 1.0959229469299316, 1.0889877080917358,\n",
      "                                 1.0823380947113037, 1.0762399435043335,\n",
      "                                 1.0708181858062744, 1.066096544265747,\n",
      "                                 1.0620325803756714, 1.0585448741912842,\n",
      "                                 1.0555487871170044, 1.0529675483703613,\n",
      "                                 1.050732135772705, 1.0487874746322632,\n",
      "                                 1.0470881462097168, 1.0455944538116455,\n",
      "                                 1.0442761182785034, 1.043107509613037,\n",
      "                                 1.0420681238174438, 1.0411385297775269,\n",
      "                                 1.0403069257736206, 1.0395591259002686],\n",
      " 'val_total_loss': [3.476161003112793, 3.0440492630004883, 2.82301664352417,\n",
      "                    2.665910243988037, 2.5392367839813232, 2.421208381652832,\n",
      "                    2.3042285442352295, 2.197793483734131, 2.1007089614868164,\n",
      "                    2.0108299255371094, 1.9275532960891724, 1.850847601890564,\n",
      "                    1.7807250022888184, 1.7170946598052979, 1.6596500873565674,\n",
      "                    1.6079424619674683, 1.5614515542984009, 1.5196491479873657,\n",
      "                    1.4820356369018555, 1.448161244392395, 1.4176201820373535,\n",
      "                    1.3900598287582397, 1.3651703596115112, 1.342665672302246,\n",
      "                    1.3223052024841309, 1.303869605064392, 1.2871674299240112,\n",
      "                    1.272020697593689, 1.2582802772521973, 1.245804786682129]}\n"
     ]
    }
   ],
   "source": [
    "# History for learning rate 0.1\n",
    "pprint.pprint(histories_tr['0.1'].history, compact=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false
    },
    "id": "03HKT4aLKr4i",
    "outputId": "03f7636d-4e71-40f2-a382-0c90e6750c03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error in user rating from training   for learning rate 0.001 = 3.02431321144104\n",
      "Root mean squared error in user rating from validation for learning rate 0.001 = 2.9313621520996094\n",
      "Root mean squared error in user rating from training   for learning rate 0.01 = 1.0800449848175049\n",
      "Root mean squared error in user rating from validation for learning rate 0.01 = 1.1250864267349243\n",
      "Root mean squared error in user rating from training   for learning rate 0.1 = 0.9358880519866943\n",
      "Root mean squared error in user rating from validation for learning rate 0.1 = 1.0395591259002686\n",
      "Root mean squared error in user rating from training   for learning rate 1 = 1.4039241075515747\n",
      "Root mean squared error in user rating from validation for learning rate 1 = 4.874517440795898\n"
     ]
    }
   ],
   "source": [
    "for val in learning_rates_logarithmic:\n",
    "    lr = str(val)\n",
    "\n",
    "    rmse_tr = histories_tr[lr].history['root_mean_squared_error'][-1]\n",
    "    print('Root mean squared error in user rating from training   for learning rate {} = {}'.format(lr, rmse_tr))\n",
    "\n",
    "    val_rmse_tr = histories_tr[lr].history['val_root_mean_squared_error'][-1]\n",
    "    print('Root mean squared error in user rating from validation for learning rate {} = {}'.format(lr, val_rmse_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "NT6elfwzLa67"
   },
   "outputs": [],
   "source": [
    "num_validation_runs = len(histories_tr['0.1'].history['root_mean_squared_error']) # Or any of the learning rates; they are all the same\n",
    "validation_freq = 1\n",
    "epochs_x = [(x + 1) * validation_freq for x in range(num_validation_runs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 308
    },
    "gradient": {
     "editing": false
    },
    "id": "M0tpT1fJLqO0",
    "outputId": "1576e6e6-bc69-4b15-8337-decb7bd6cd68"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f5ae87b7f60>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for val in learning_rates_logarithmic:\n",
    "    lr = str(val)\n",
    "    plt.plot(epochs_x, histories_tr[lr].history['root_mean_squared_error'], label=lr)\n",
    "    plt.plot(epochs_x, histories_tr[lr].history['val_root_mean_squared_error'], label=lr, linestyle='dotted')\n",
    "\n",
    "plt.title('Root mean squared error in user rating vs. training epoch')\n",
    "plt.xlabel('Training epoch')\n",
    "plt.ylabel('Root mean squared error in user rating')\n",
    "plt.yscale('log')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "WegveKxPIAaV"
   },
   "source": [
    "It looks like learning rates closer in magnitude to 0.1 than 0.01 or 1 are best, so we zoom in on those.\n",
    "\n",
    "Again a production system would test more values so the results are less noisy, but this shows the idea.\n",
    "\n",
    "The RMSE has improved from about 1.1 in the basic model to about 0.9 here, although a little higher on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false
    },
    "id": "ZaSvBMAWEXxf",
    "outputId": "245286e0-0f53-4216-f735-2e5a56b72292",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate = 0.05\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 1s 30ms/step - root_mean_squared_error: 2.1155 - loss: 4.1128 - regularization_loss: 2.0002 - total_loss: 6.1129 - val_root_mean_squared_error: 1.1633 - val_loss: 1.3542 - val_regularization_loss: 1.9563 - val_total_loss: 3.3105\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.1256 - loss: 1.2646 - regularization_loss: 1.9082 - total_loss: 3.1728 - val_root_mean_squared_error: 1.1419 - val_loss: 1.3045 - val_regularization_loss: 1.8598 - val_total_loss: 3.1643\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.1172 - loss: 1.2469 - regularization_loss: 1.8152 - total_loss: 3.0621 - val_root_mean_squared_error: 1.1341 - val_loss: 1.2862 - val_regularization_loss: 1.7684 - val_total_loss: 3.0546\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.1181 - loss: 1.2494 - regularization_loss: 1.7271 - total_loss: 2.9764 - val_root_mean_squared_error: 1.1342 - val_loss: 1.2861 - val_regularization_loss: 1.6821 - val_total_loss: 2.9682\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s 17ms/step - root_mean_squared_error: 1.1184 - loss: 1.2492 - regularization_loss: 1.6436 - total_loss: 2.8928 - val_root_mean_squared_error: 1.1337 - val_loss: 1.2848 - val_regularization_loss: 1.6010 - val_total_loss: 2.8858\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.1109 - loss: 1.2320 - regularization_loss: 1.5648 - total_loss: 2.7967 - val_root_mean_squared_error: 1.1314 - val_loss: 1.2793 - val_regularization_loss: 1.5246 - val_total_loss: 2.8040\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.1004 - loss: 1.2088 - regularization_loss: 1.4903 - total_loss: 2.6991 - val_root_mean_squared_error: 1.1296 - val_loss: 1.2750 - val_regularization_loss: 1.4525 - val_total_loss: 2.7274\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.0904 - loss: 1.1873 - regularization_loss: 1.4200 - total_loss: 2.6072 - val_root_mean_squared_error: 1.1280 - val_loss: 1.2711 - val_regularization_loss: 1.3842 - val_total_loss: 2.6553\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.0815 - loss: 1.1680 - regularization_loss: 1.3535 - total_loss: 2.5215 - val_root_mean_squared_error: 1.1262 - val_loss: 1.2667 - val_regularization_loss: 1.3196 - val_total_loss: 2.5862\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.0730 - loss: 1.1498 - regularization_loss: 1.2906 - total_loss: 2.4404 - val_root_mean_squared_error: 1.1240 - val_loss: 1.2613 - val_regularization_loss: 1.2584 - val_total_loss: 2.5197\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.0647 - loss: 1.1320 - regularization_loss: 1.2310 - total_loss: 2.3630 - val_root_mean_squared_error: 1.1213 - val_loss: 1.2550 - val_regularization_loss: 1.2004 - val_total_loss: 2.4554\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.0564 - loss: 1.1145 - regularization_loss: 1.1745 - total_loss: 2.2889 - val_root_mean_squared_error: 1.1182 - val_loss: 1.2477 - val_regularization_loss: 1.1454 - val_total_loss: 2.3931\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.0482 - loss: 1.0970 - regularization_loss: 1.1209 - total_loss: 2.2179 - val_root_mean_squared_error: 1.1148 - val_loss: 1.2397 - val_regularization_loss: 1.0932 - val_total_loss: 2.3329\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.0399 - loss: 1.0798 - regularization_loss: 1.0700 - total_loss: 2.1498 - val_root_mean_squared_error: 1.1110 - val_loss: 1.2310 - val_regularization_loss: 1.0437 - val_total_loss: 2.2747\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.0317 - loss: 1.0628 - regularization_loss: 1.0217 - total_loss: 2.0845 - val_root_mean_squared_error: 1.1069 - val_loss: 1.2217 - val_regularization_loss: 0.9967 - val_total_loss: 2.2184\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.0237 - loss: 1.0463 - regularization_loss: 0.9759 - total_loss: 2.0223 - val_root_mean_squared_error: 1.1027 - val_loss: 1.2122 - val_regularization_loss: 0.9521 - val_total_loss: 2.1643\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.0160 - loss: 1.0307 - regularization_loss: 0.9324 - total_loss: 1.9630 - val_root_mean_squared_error: 1.0985 - val_loss: 1.2026 - val_regularization_loss: 0.9097 - val_total_loss: 2.1123\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.0088 - loss: 1.0159 - regularization_loss: 0.8910 - total_loss: 1.9069 - val_root_mean_squared_error: 1.0943 - val_loss: 1.1932 - val_regularization_loss: 0.8694 - val_total_loss: 2.0626\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.0020 - loss: 1.0023 - regularization_loss: 0.8516 - total_loss: 1.8540 - val_root_mean_squared_error: 1.0902 - val_loss: 1.1842 - val_regularization_loss: 0.8310 - val_total_loss: 2.0152\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 0.9958 - loss: 0.9899 - regularization_loss: 0.8141 - total_loss: 1.8040 - val_root_mean_squared_error: 1.0864 - val_loss: 1.1757 - val_regularization_loss: 0.7945 - val_total_loss: 1.9702\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 0.9900 - loss: 0.9784 - regularization_loss: 0.7784 - total_loss: 1.7568 - val_root_mean_squared_error: 1.0828 - val_loss: 1.1678 - val_regularization_loss: 0.7596 - val_total_loss: 1.9275\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 0.9846 - loss: 0.9679 - regularization_loss: 0.7444 - total_loss: 1.7122 - val_root_mean_squared_error: 1.0795 - val_loss: 1.1607 - val_regularization_loss: 0.7264 - val_total_loss: 1.8871\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 0.9797 - loss: 0.9582 - regularization_loss: 0.7119 - total_loss: 1.6701 - val_root_mean_squared_error: 1.0765 - val_loss: 1.1541 - val_regularization_loss: 0.6947 - val_total_loss: 1.8489\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 0.9753 - loss: 0.9495 - regularization_loss: 0.6809 - total_loss: 1.6304 - val_root_mean_squared_error: 1.0738 - val_loss: 1.1482 - val_regularization_loss: 0.6645 - val_total_loss: 1.8127\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 0.9712 - loss: 0.9417 - regularization_loss: 0.6513 - total_loss: 1.5930 - val_root_mean_squared_error: 1.0713 - val_loss: 1.1428 - val_regularization_loss: 0.6357 - val_total_loss: 1.7785\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s 17ms/step - root_mean_squared_error: 0.9676 - loss: 0.9346 - regularization_loss: 0.6231 - total_loss: 1.5577 - val_root_mean_squared_error: 1.0690 - val_loss: 1.1379 - val_regularization_loss: 0.6082 - val_total_loss: 1.7461\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 0.9643 - loss: 0.9282 - regularization_loss: 0.5962 - total_loss: 1.5244 - val_root_mean_squared_error: 1.0670 - val_loss: 1.1335 - val_regularization_loss: 0.5820 - val_total_loss: 1.7154\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 0.9612 - loss: 0.9224 - regularization_loss: 0.5706 - total_loss: 1.4930 - val_root_mean_squared_error: 1.0651 - val_loss: 1.1294 - val_regularization_loss: 0.5570 - val_total_loss: 1.6864\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 0.9585 - loss: 0.9171 - regularization_loss: 0.5462 - total_loss: 1.4632 - val_root_mean_squared_error: 1.0634 - val_loss: 1.1257 - val_regularization_loss: 0.5332 - val_total_loss: 1.6589\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 0.9560 - loss: 0.9123 - regularization_loss: 0.5229 - total_loss: 1.4351 - val_root_mean_squared_error: 1.0618 - val_loss: 1.1223 - val_regularization_loss: 0.5105 - val_total_loss: 1.6328\n",
      "Learning rate = 0.1\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 1s 32ms/step - root_mean_squared_error: 2.3914 - loss: 5.5133 - regularization_loss: 1.9663 - total_loss: 7.4796 - val_root_mean_squared_error: 1.1728 - val_loss: 1.3759 - val_regularization_loss: 1.8751 - val_total_loss: 3.2510\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1379 - loss: 1.2900 - regularization_loss: 1.7909 - total_loss: 3.0809 - val_root_mean_squared_error: 1.1323 - val_loss: 1.2837 - val_regularization_loss: 1.7006 - val_total_loss: 2.9843\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1202 - loss: 1.2532 - regularization_loss: 1.6219 - total_loss: 2.8751 - val_root_mean_squared_error: 1.1313 - val_loss: 1.2815 - val_regularization_loss: 1.5403 - val_total_loss: 2.8219\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1149 - loss: 1.2414 - regularization_loss: 1.4694 - total_loss: 2.7109 - val_root_mean_squared_error: 1.1299 - val_loss: 1.2782 - val_regularization_loss: 1.3960 - val_total_loss: 2.6742\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s 17ms/step - root_mean_squared_error: 1.1078 - loss: 1.2254 - regularization_loss: 1.3324 - total_loss: 2.5578 - val_root_mean_squared_error: 1.1281 - val_loss: 1.2740 - val_regularization_loss: 1.2664 - val_total_loss: 2.5404\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.0980 - loss: 1.2036 - regularization_loss: 1.2095 - total_loss: 2.4131 - val_root_mean_squared_error: 1.1257 - val_loss: 1.2685 - val_regularization_loss: 1.1503 - val_total_loss: 2.4189\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.0856 - loss: 1.1764 - regularization_loss: 1.0995 - total_loss: 2.2759 - val_root_mean_squared_error: 1.1225 - val_loss: 1.2613 - val_regularization_loss: 1.0466 - val_total_loss: 2.3079\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s 18ms/step - root_mean_squared_error: 1.0716 - loss: 1.1463 - regularization_loss: 1.0012 - total_loss: 2.1474 - val_root_mean_squared_error: 1.1183 - val_loss: 1.2517 - val_regularization_loss: 0.9537 - val_total_loss: 2.2054\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 0s 37ms/step - root_mean_squared_error: 1.0574 - loss: 1.1161 - regularization_loss: 0.9131 - total_loss: 2.0292 - val_root_mean_squared_error: 1.1130 - val_loss: 1.2398 - val_regularization_loss: 0.8703 - val_total_loss: 2.1101\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.0438 - loss: 1.0875 - regularization_loss: 0.8340 - total_loss: 1.9215 - val_root_mean_squared_error: 1.1066 - val_loss: 1.2253 - val_regularization_loss: 0.7954 - val_total_loss: 2.0207\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.0310 - loss: 1.0612 - regularization_loss: 0.7628 - total_loss: 1.8240 - val_root_mean_squared_error: 1.0994 - val_loss: 1.2091 - val_regularization_loss: 0.7279 - val_total_loss: 1.9370\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.0193 - loss: 1.0371 - regularization_loss: 0.6988 - total_loss: 1.7359 - val_root_mean_squared_error: 1.0919 - val_loss: 1.1921 - val_regularization_loss: 0.6671 - val_total_loss: 1.8592\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.0089 - loss: 1.0161 - regularization_loss: 0.6409 - total_loss: 1.6571 - val_root_mean_squared_error: 1.0846 - val_loss: 1.1759 - val_regularization_loss: 0.6120 - val_total_loss: 1.7879\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.0001 - loss: 0.9985 - regularization_loss: 0.5885 - total_loss: 1.5870 - val_root_mean_squared_error: 1.0781 - val_loss: 1.1614 - val_regularization_loss: 0.5620 - val_total_loss: 1.7234\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 0.9925 - loss: 0.9834 - regularization_loss: 0.5409 - total_loss: 1.5243 - val_root_mean_squared_error: 1.0724 - val_loss: 1.1487 - val_regularization_loss: 0.5165 - val_total_loss: 1.6653\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 0.9856 - loss: 0.9696 - regularization_loss: 0.4975 - total_loss: 1.4671 - val_root_mean_squared_error: 1.0674 - val_loss: 1.1377 - val_regularization_loss: 0.4751 - val_total_loss: 1.6129\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 0.9789 - loss: 0.9565 - regularization_loss: 0.4579 - total_loss: 1.4144 - val_root_mean_squared_error: 1.0629 - val_loss: 1.1281 - val_regularization_loss: 0.4375 - val_total_loss: 1.5656\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 0.9728 - loss: 0.9446 - regularization_loss: 0.4219 - total_loss: 1.3665 - val_root_mean_squared_error: 1.0591 - val_loss: 1.1199 - val_regularization_loss: 0.4032 - val_total_loss: 1.5231\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 0.9674 - loss: 0.9341 - regularization_loss: 0.3891 - total_loss: 1.3232 - val_root_mean_squared_error: 1.0558 - val_loss: 1.1128 - val_regularization_loss: 0.3720 - val_total_loss: 1.4849\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 0.9627 - loss: 0.9252 - regularization_loss: 0.3593 - total_loss: 1.2845 - val_root_mean_squared_error: 1.0530 - val_loss: 1.1068 - val_regularization_loss: 0.3437 - val_total_loss: 1.4504\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 0.9587 - loss: 0.9176 - regularization_loss: 0.3322 - total_loss: 1.2498 - val_root_mean_squared_error: 1.0505 - val_loss: 1.1015 - val_regularization_loss: 0.3179 - val_total_loss: 1.4194\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 0.9553 - loss: 0.9110 - regularization_loss: 0.3075 - total_loss: 1.2185 - val_root_mean_squared_error: 1.0483 - val_loss: 1.0969 - val_regularization_loss: 0.2944 - val_total_loss: 1.3913\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s 17ms/step - root_mean_squared_error: 0.9523 - loss: 0.9052 - regularization_loss: 0.2851 - total_loss: 1.1903 - val_root_mean_squared_error: 1.0464 - val_loss: 1.0929 - val_regularization_loss: 0.2731 - val_total_loss: 1.3660\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 0.9495 - loss: 0.9001 - regularization_loss: 0.2647 - total_loss: 1.1648 - val_root_mean_squared_error: 1.0448 - val_loss: 1.0893 - val_regularization_loss: 0.2538 - val_total_loss: 1.3431\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 0.9471 - loss: 0.8955 - regularization_loss: 0.2462 - total_loss: 1.1417 - val_root_mean_squared_error: 1.0433 - val_loss: 1.0862 - val_regularization_loss: 0.2362 - val_total_loss: 1.3224\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 0.9449 - loss: 0.8914 - regularization_loss: 0.2294 - total_loss: 1.1208 - val_root_mean_squared_error: 1.0420 - val_loss: 1.0834 - val_regularization_loss: 0.2202 - val_total_loss: 1.3036\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 0.9429 - loss: 0.8876 - regularization_loss: 0.2142 - total_loss: 1.1018 - val_root_mean_squared_error: 1.0408 - val_loss: 1.0809 - val_regularization_loss: 0.2057 - val_total_loss: 1.2866\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s 17ms/step - root_mean_squared_error: 0.9411 - loss: 0.8842 - regularization_loss: 0.2003 - total_loss: 1.0845 - val_root_mean_squared_error: 1.0397 - val_loss: 1.0786 - val_regularization_loss: 0.1925 - val_total_loss: 1.2711\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 0.9395 - loss: 0.8812 - regularization_loss: 0.1877 - total_loss: 1.0688 - val_root_mean_squared_error: 1.0388 - val_loss: 1.0766 - val_regularization_loss: 0.1805 - val_total_loss: 1.2571\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 0s 17ms/step - root_mean_squared_error: 0.9380 - loss: 0.8784 - regularization_loss: 0.1762 - total_loss: 1.0545 - val_root_mean_squared_error: 1.0380 - val_loss: 1.0748 - val_regularization_loss: 0.1696 - val_total_loss: 1.2444\n",
      "Learning rate = 0.15\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 1s 30ms/step - root_mean_squared_error: 3.4389 - loss: 10.8493 - regularization_loss: 2.0222 - total_loss: 12.8715 - val_root_mean_squared_error: 1.1389 - val_loss: 1.2983 - val_regularization_loss: 1.9445 - val_total_loss: 3.2428\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1299 - loss: 1.2732 - regularization_loss: 1.8204 - total_loss: 3.0937 - val_root_mean_squared_error: 1.1328 - val_loss: 1.2851 - val_regularization_loss: 1.6919 - val_total_loss: 2.9770\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1155 - loss: 1.2419 - regularization_loss: 1.5846 - total_loss: 2.8265 - val_root_mean_squared_error: 1.1322 - val_loss: 1.2840 - val_regularization_loss: 1.4745 - val_total_loss: 2.7585\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.1027 - loss: 1.2132 - regularization_loss: 1.3826 - total_loss: 2.5959 - val_root_mean_squared_error: 1.1311 - val_loss: 1.2815 - val_regularization_loss: 1.2885 - val_total_loss: 2.5701\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.0859 - loss: 1.1763 - regularization_loss: 1.2103 - total_loss: 2.3866 - val_root_mean_squared_error: 1.1290 - val_loss: 1.2770 - val_regularization_loss: 1.1299 - val_total_loss: 2.4069\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.0674 - loss: 1.1367 - regularization_loss: 1.0631 - total_loss: 2.1998 - val_root_mean_squared_error: 1.1254 - val_loss: 1.2689 - val_regularization_loss: 0.9942 - val_total_loss: 2.2631\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.0496 - loss: 1.0992 - regularization_loss: 0.9369 - total_loss: 2.0361 - val_root_mean_squared_error: 1.1198 - val_loss: 1.2561 - val_regularization_loss: 0.8775 - val_total_loss: 2.1337\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s 17ms/step - root_mean_squared_error: 1.0327 - loss: 1.0641 - regularization_loss: 0.8283 - total_loss: 1.8924 - val_root_mean_squared_error: 1.1123 - val_loss: 1.2390 - val_regularization_loss: 0.7771 - val_total_loss: 2.0160\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.0166 - loss: 1.0312 - regularization_loss: 0.7347 - total_loss: 1.7660 - val_root_mean_squared_error: 1.1036 - val_loss: 1.2190 - val_regularization_loss: 0.6904 - val_total_loss: 1.9094\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.0020 - loss: 1.0019 - regularization_loss: 0.6538 - total_loss: 1.6556 - val_root_mean_squared_error: 1.0946 - val_loss: 1.1986 - val_regularization_loss: 0.6151 - val_total_loss: 1.8138\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 0.9895 - loss: 0.9770 - regularization_loss: 0.5834 - total_loss: 1.5604 - val_root_mean_squared_error: 1.0862 - val_loss: 1.1799 - val_regularization_loss: 0.5496 - val_total_loss: 1.7295\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 0.9791 - loss: 0.9568 - regularization_loss: 0.5220 - total_loss: 1.4788 - val_root_mean_squared_error: 1.0791 - val_loss: 1.1639 - val_regularization_loss: 0.4923 - val_total_loss: 1.6562\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 0.9708 - loss: 0.9406 - regularization_loss: 0.4683 - total_loss: 1.4089 - val_root_mean_squared_error: 1.0731 - val_loss: 1.1507 - val_regularization_loss: 0.4421 - val_total_loss: 1.5929\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 0.9640 - loss: 0.9275 - regularization_loss: 0.4212 - total_loss: 1.3488 - val_root_mean_squared_error: 1.0682 - val_loss: 1.1400 - val_regularization_loss: 0.3982 - val_total_loss: 1.5382\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 0.9585 - loss: 0.9169 - regularization_loss: 0.3800 - total_loss: 1.2968 - val_root_mean_squared_error: 1.0642 - val_loss: 1.1313 - val_regularization_loss: 0.3596 - val_total_loss: 1.4909\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 0.9538 - loss: 0.9080 - regularization_loss: 0.3438 - total_loss: 1.2519 - val_root_mean_squared_error: 1.0609 - val_loss: 1.1241 - val_regularization_loss: 0.3259 - val_total_loss: 1.4500\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s 17ms/step - root_mean_squared_error: 0.9499 - loss: 0.9006 - regularization_loss: 0.3121 - total_loss: 1.2127 - val_root_mean_squared_error: 1.0581 - val_loss: 1.1181 - val_regularization_loss: 0.2962 - val_total_loss: 1.4144\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 0.9466 - loss: 0.8943 - regularization_loss: 0.2843 - total_loss: 1.1786 - val_root_mean_squared_error: 1.0558 - val_loss: 1.1131 - val_regularization_loss: 0.2703 - val_total_loss: 1.3834\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 0.9437 - loss: 0.8889 - regularization_loss: 0.2599 - total_loss: 1.1488 - val_root_mean_squared_error: 1.0539 - val_loss: 1.1089 - val_regularization_loss: 0.2475 - val_total_loss: 1.3564\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 0.9412 - loss: 0.8842 - regularization_loss: 0.2385 - total_loss: 1.1227 - val_root_mean_squared_error: 1.0522 - val_loss: 1.1052 - val_regularization_loss: 0.2274 - val_total_loss: 1.3327\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 0.9390 - loss: 0.8801 - regularization_loss: 0.2196 - total_loss: 1.0997 - val_root_mean_squared_error: 1.0507 - val_loss: 1.1021 - val_regularization_loss: 0.2098 - val_total_loss: 1.3119\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 0.9371 - loss: 0.8765 - regularization_loss: 0.2030 - total_loss: 1.0795 - val_root_mean_squared_error: 1.0494 - val_loss: 1.0994 - val_regularization_loss: 0.1942 - val_total_loss: 1.2936\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s 37ms/step - root_mean_squared_error: 0.9354 - loss: 0.8733 - regularization_loss: 0.1884 - total_loss: 1.0616 - val_root_mean_squared_error: 1.0483 - val_loss: 1.0970 - val_regularization_loss: 0.1805 - val_total_loss: 1.2774\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s 18ms/step - root_mean_squared_error: 0.9338 - loss: 0.8704 - regularization_loss: 0.1754 - total_loss: 1.0458 - val_root_mean_squared_error: 1.0473 - val_loss: 1.0949 - val_regularization_loss: 0.1683 - val_total_loss: 1.2632\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 0.9325 - loss: 0.8678 - regularization_loss: 0.1640 - total_loss: 1.0318 - val_root_mean_squared_error: 1.0465 - val_loss: 1.0930 - val_regularization_loss: 0.1575 - val_total_loss: 1.2506\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 0.9312 - loss: 0.8655 - regularization_loss: 0.1538 - total_loss: 1.0193 - val_root_mean_squared_error: 1.0457 - val_loss: 1.0913 - val_regularization_loss: 0.1480 - val_total_loss: 1.2393\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 0.9301 - loss: 0.8635 - regularization_loss: 0.1448 - total_loss: 1.0082 - val_root_mean_squared_error: 1.0450 - val_loss: 1.0898 - val_regularization_loss: 0.1395 - val_total_loss: 1.2293\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 0.9291 - loss: 0.8616 - regularization_loss: 0.1367 - total_loss: 0.9983 - val_root_mean_squared_error: 1.0444 - val_loss: 1.0885 - val_regularization_loss: 0.1319 - val_total_loss: 1.2204\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 0.9281 - loss: 0.8598 - regularization_loss: 0.1295 - total_loss: 0.9894 - val_root_mean_squared_error: 1.0438 - val_loss: 1.0873 - val_regularization_loss: 0.1251 - val_total_loss: 1.2125\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 0.9273 - loss: 0.8582 - regularization_loss: 0.1231 - total_loss: 0.9814 - val_root_mean_squared_error: 1.0433 - val_loss: 1.0862 - val_regularization_loss: 0.1191 - val_total_loss: 1.2053\n"
     ]
    }
   ],
   "source": [
    "# Here we start a new dictionary of training histories, but these could also be appended to the above one\n",
    "histories_tr_li = {}\n",
    "\n",
    "# Learning rate linear grid\n",
    "learning_rates_linear = [0.05, 0.1, 0.15]\n",
    "\n",
    "for val in learning_rates_linear:\n",
    "    print('Learning rate = {}'.format(val))\n",
    "    model_tr = MovielensModelTunedRanking()\n",
    "    model_tr.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=val))\n",
    "\n",
    "    lr = str(val)\n",
    "    histories_tr_li[lr] = model_tr.fit(cached_train, epochs=epochs, validation_data=cached_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false
    },
    "id": "d2ojspFOEpb-",
    "outputId": "89d73d93-96b7-4336-f5f7-ecd8266477e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0.05': <tensorflow.python.keras.callbacks.History at 0x7f5afc093828>,\n",
       " '0.1': <tensorflow.python.keras.callbacks.History at 0x7f5a784bf898>,\n",
       " '0.15': <tensorflow.python.keras.callbacks.History at 0x7f5a785fd160>}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "histories_tr_li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false
    },
    "id": "ujCXSvC6MLa4",
    "outputId": "f3a5dcd8-0a59-4a46-9498-ea81f6b7413e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error in user rating from training   for learning rate 0.05 = 0.9559524655342102\n",
      "Root mean squared error in user rating from validation for learning rate 0.05 = 1.0618358850479126\n",
      "Root mean squared error in user rating from training   for learning rate 0.1 = 0.9380072951316833\n",
      "Root mean squared error in user rating from validation for learning rate 0.1 = 1.0379561185836792\n",
      "Root mean squared error in user rating from training   for learning rate 0.15 = 0.9272826910018921\n",
      "Root mean squared error in user rating from validation for learning rate 0.15 = 1.0433213710784912\n"
     ]
    }
   ],
   "source": [
    "for val in learning_rates_linear:\n",
    "    lr = str(val)\n",
    "\n",
    "    rmse_tr = histories_tr_li[lr].history['root_mean_squared_error'][-1]\n",
    "    print('Root mean squared error in user rating from training   for learning rate {} = {}'.format(lr, rmse_tr))\n",
    "\n",
    "    val_rmse_tr = histories_tr_li[lr].history['val_root_mean_squared_error'][-1]\n",
    "    print('Root mean squared error in user rating from validation for learning rate {} = {}'.format(lr, val_rmse_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "SJmfaxQ1MeTl"
   },
   "outputs": [],
   "source": [
    "num_validation_runs = len(histories_tr_li['0.1'].history['root_mean_squared_error'])\n",
    "validation_freq = 1\n",
    "epochs_x = [(x + 1) * validation_freq for x in range(num_validation_runs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 308
    },
    "gradient": {
     "editing": false
    },
    "id": "31udS6_AMniY",
    "outputId": "fdc30bc0-ae31-4d06-cc1b-2ddd83ebf1e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f5a782680f0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZoAAAETCAYAAAAPucBzAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAABphUlEQVR4nO3dd3wU1drA8d/2lt4LofceukiR0KRDAMUCWBEviIhXBQsqqFhQUdBrw/pyVVSKAiKCFK8oTYr0DgnpvW3fef+YZJOFhA0lCYHz5bOfnTM7O/vM7rJPzpkz5ygkSZIQBEEQhCqirOkABEEQhOubSDSCIAhClRKJRhAEQahSItEIgiAIVUokGkEQBKFKiUQjCIIgVCmRaIRaY9myZdxxxx01HUaFkpKSiI2Nxel01nQo1e6BBx5g+fLlNR1GtRoyZAjbtm276tte62bOnMnbb799Sc9RV1Es15S4uDgyMjJQqVQYjUZ69uzJc889h8lkuqL9zpw5k/DwcB577LGrFKlQm0VFRbF79+6aDqPKLVy4kDNnzjB//nz3uk8++aQGI7o0iYmJ9O3blwMHDqBWX/5P4OrVq6tk2+vRDVOj+eCDD9i9ezcrVqzg4MGDfPTRRzUd0g1NkiRcLtc189oOh+OS9nGp218LKhNzbTyuqiDeh6vrhkk0JUJDQ+nRoweHDh1yr9uwYQNDhgyhU6dOjB8/nhMnTrgfO3HiBOPHj6dTp04MGTKEDRs2APDtt9/y008/sXjxYmJjY5k8eXK5r9esWTOWLFnCgAEDiI2NZcGCBZw9e5Zx48bRoUMHHn30UWw2m3v7jRs3MmLECDp16sS4ceM4fPiw+7GPPvqIfv36ERsby+DBg/n111/dj5U0K7322mt07tyZuLg4Nm/eXOH78NFHH9GzZ09iY2MZOHAgf/75JwAWi4WZM2fSuXNnBg8ezCeffEKvXr08jufMmTPuctlqdG5uLg899BDdunWjc+fOPPTQQ6SkpLi3HT9+PG+//Tbjxo2jXbt2JCQkcOLECe699166dOnCwIEDWbNmjXv77OxsJk+eTIcOHRgzZgxnz56t8HgA9uzZw7hx4+jUqRPDhw/3aKoo77XLfjYDBgwAYOnSpfTv358uXbowefJkUlNTy/0sS7YvKzExkWbNmrl/pMaPH8+CBQsYN24csbGx3HfffWRlZZUbe3nNgmXf682bNzN48GBiY2Pp2bMnixcvdm93se9MXFwcH330EcOGDaN9+/bl/oCWd1wvvfQSvXv3pkOHDsTHx7Nz504AtmzZwocffsjPP/9MbGwsw4cPdx/rd99953EsFX0XExISuOuuu4iNjeWee+7hxRdf5N///ne578ugQYPYuHGju+xwOOjWrRsHDhzAarXy73//m65du9KpUydGjx5NRkZGufsp6+677wagc+fOxMbGsnv3bpYtW8a4ceN45ZVX6Nq1KwsXLuTs2bNMmDCBrl270rVrVx5//HHy8vI83tutW7cCci3v0Ucf5cknnyQ2NpYhQ4bwzz//XNa2Bw4cYOTIkcTGxjJt2jSmT59+0aaq77//nkGDBtG5c2fuv/9+zp07536sWbNmfPnll/Tt25euXbvy2muvuf/IcrlcvP/++/Tp04ebbrqJJ598kvz8fPdzd+7c6f7/1Lt3b5YtW+Z+LC8vj0mTJhEbG8vYsWO9/t9EugH06dNH+uOPPyRJkqTk5GRp6NCh0ty5cyVJkqSTJ09K7dq1k/73v/9JNptN+uijj6R+/fpJVqtVstlsUr9+/aT//Oc/ktVqlbZu3Sq1b99eOnHihCRJkvTUU09Jb7311kVfu2nTptLkyZOl/Px86ejRo1KrVq2kCRMmSGfPnpXy8vKkQYMGScuWLZMkSZIOHDggdevWTdqzZ4/kcDikZcuWSX369JGsVqskSZK0Zs0aKSUlRXI6ndLq1auldu3aSampqZIkSdIPP/wgtWzZUvr2228lh8MhLVmyRLr55psll8t1QUwnTpyQevXqJaWkpEiSJEkJCQnSmTNnJEmSpDfeeEO64447pOzsbCkpKUkaMmSI1LNnT4/jOX36tLtc9j3IysqS1q5dKxUVFUn5+fnSI488Ij388MPube+++26pd+/e0tGjRyW73S7l5eVJvXr1kr7//nvJbrdLBw4ckLp06SIdO3ZMkiRJmj59ujRt2jSpsLBQOnLkiNSjRw9p3Lhx5b7PKSkpUpcuXaRNmzZJTqdT+t///id16dJFyszMLPe1bTab1LRpU+mee+6RsrOzJbPZLG3dulXq0qWLtH//fslqtUpz5syR7rzzTo9jL7v9+RISEqSmTZtKdrvd/Zp9+/aVTp48KZnNZunuu++W3njjjXLj/+GHHy44trLv9c033yzt2LFDkiRJysnJkfbv3y9JkvfvTJ8+faThw4dLSUlJ5cZc0XGtWLFCysrKkux2u7R48WKpe/fuksVikSRJkt59913p8ccf99jH3XffLS1dutR9LBf7Lt52223Sq6++KlmtVmnHjh1SbGzsBfsrsXDhQmnGjBnu8saNG6Vbb71VkiRJ+vrrr6WHHnpIKioqkhwOh/TPP/9I+fn55e6nrPM/p5KYW7RoIX355ZeS3W6XzGazdPr0ael///ufZLVapczMTOnOO++UXnrpJfdzyv6uvPvuu1Lr1q2lTZs2SQ6HQ5o/f740duzYS97WarVKt9xyi/T5559LNptN+uWXX6RWrVpV+Dvz66+/Sv369ZOOHz8u2e126b333pNuv/129+NNmzaV7r77bik7O1s6d+6cNGDAAPfn9N1330n9+vWTzp49KxUUFEhTpkyR/v3vf0uSJEmJiYlS+/btpZ9++kmy2WxSVlaWdPDgQUmS5P/zXbp0kfbu3SvZ7XZpxowZ0vTp0y/6nt8wNZopU6YQGxtL7969CQoKYtq0aQCsWbOG3r17c/PNN6PRaLj//vuxWCzs3r2bvXv3UlRUxKRJk9Bqtdx000306dPnkttbH3jgAXx8fGjSpAlNmzbl5ptvJiYmBl9fX3r16sXBgwcBuZZ0++23065dO1QqFaNGjUKj0bBnzx5A/usuPDwcpVLJ4MGDqVevHvv27XO/TlRUFLfddpv7uenp6eX+hadSqbDZbJw4cQK73U6dOnWoW7cuAD///DOTJ08mICCAyMhIxo8fX+njDAwMZODAgRgMBnx8fHj44YfZsWOHxzajRo2iSZMmqNVqfv/9d6Kjoxk9ejRqtZqWLVsycOBA1q5di9PpZN26dUybNg2j0UjTpk0ZNWpUha+9cuVKevXqRe/evVEqldx88820bt3a4y/psq+t0WgAmDRpEgEBAej1en766SdGjx5Nq1at0Gq1zJgxgz179pCYmOjeR9ntKyM+Pp4GDRqg1+u59dZbPWrSl0KtVnP8+HEKCgrw9/enVatWgPfvDMi1jcjIyIvGfP5xjRgxgsDAQNRqNffddx82m41Tp05VOt6KvotJSUn8888/TJs2Da1WS6dOnYiLi6twP8OGDeO3337DbDYD8NNPPzFkyBD3e5KTk8OZM2dQqVS0bt0aHx+fSsd4vrCwMMaPH49arUav11OvXj1uvvlmtFotQUFB3HvvvRd8n8vq2LEjvXv3RqVSMWLECI+aZWW33bt3Lw6HgwkTJqDRaBgwYABt2rSpcD/ffPMNkyZNolGjRqjVaiZPnsyhQ4c8ajUPPvggAQEBREVFMWHCBFatWgXI7+U999xDTEwMJpOJGTNmsGbNGhwOB6tWraJ79+4MHToUjUZDYGAgLVq0cO+zX79+tG3bFrVazfDhw71+r2+IzgAA7733Ht27d2f79u08/vjjZGdn4+fnR1paGlFRUe7tlEolkZGRpKamolariYiIQKkszcdRUVEezSmVERIS4l7W6XQXlEuSQVJSEitWrOD//u//3I/b7XbS0tIAWLFiBZ999pn7S1RUVER2dna5r2MwGNzbnK9evXo8/fTTLFy4kOPHj9OjRw93x4a0tDQiIyM9jreyzGYz8+bN4/fffyc3NxeAwsJCnE4nKpUKwGPf586dY9++fXTq1Mm9zul0Mnz4cLKysnA4HJWOJSkpibVr117QzNK1a1d3uey+yluXlpbm/gEHMJlMBAQEkJqaSp06dSrcx8WEhoa6lw0GQ7mfR2W8++67/Oc//+HNN9+kWbNmPP7448TGxnr9zlQ25vO3Wbx4Md9//z1paWkoFAoKCgo8vmveVPRdzM7Oxt/f372u5LWTk5PL3U+9evVo1KgRGzdupE+fPvz222+sWLECkJNhSkoKM2bMIC8vj+HDh/PYY4+5/4i4VBERER7ljIwMXn75ZXbu3ElhYSGSJOHn51epY9br9VitVhwOR7kdDiraNi0tjfDwcBQKhfvxi31+SUlJvPLKK7z22mvudZIkkZqaSnR09AXPj46Odn830tLS3NuUPOZwOMjMzCQ5Odn9x2dljtXb9/qGSTQlunTpQnx8PK+99hrvv/8+YWFhHD161P24JEkkJycTHh6OSqUiJSUFl8vlTjbJycnUr18fwOPLcDVERkYyefJkHn744QseO3fuHM8++yyff/45sbGx7r+ELtewYcMYNmwYBQUFzJ49m/nz5/PGG28QGhpKcnIyTZo0AbjgB8BgMLj/ugRIT08nPDwcgE8//ZRTp06xdOlSQkNDOXToECNHjkQqM0D4+f+BOnfuzGeffXZBfE6nE7VaTXJyMo0aNSo3lrIiIyMZMWIEL730UoXblPd5lV0XFhbm8ZdgUVEROTk57uOraB9Xg8FgwGKxuMvp6ekej7dt25b//Oc/2O12lixZwvTp09m8efNFvzOXEnPZbXbu3Mknn3zC559/TpMmTVAqlXTu3Nn9OV7JexAaGkpubi5ms9mdbC72uQIMHTqUVatW4XK5aNy4MfXq1QNAo9EwdepUpk6dSmJiIpMmTaJBgwaMHTu20sd6sfVvvfUWCoWCn376iYCAANavX8+cOXMqe6iXJTQ0lNTUVCRJcseTnJxMTExMuduXfP4l58rKU/b/c1JSEmFhYcCF3/ekpCTUajXBwcFERkZ6tJZcqRum6aysiRMnsnXrVg4fPsygQYPYvHkzf/75J3a7nU8//RStVktsbCxt27ZFr9fzySefYLfb2bZtG7/99huDBw8GIDg42KNZ5UqNHTuWb775hr179yJJEkVFRWzatImCggLMZjMKhYKgoCAAfvjhB44dO3ZZr3Py5En+/PNPbDYbWq0WnU7nTqSDBg3io48+Ijc3l5SUFL766iuP5zZv3pxVq1bhdDrZsmWLR1NCYWEhOp0OPz8/cnJyWLRo0UXjuOWWWzh9+jQrVqzAbrdjt9vZt28fJ06cQKVS0b9/fxYtWoTZbOb48eMXvU5j+PDhbNy4kd9//x2n04nVamXbtm0enRG8GTp0KMuWLePQoUPYbDbeeust2rZt667NVKXmzZtz7NgxDh06hNVqZeHChe7HbDYbP/74I/n5+Wg0Gkwmk/vzuth35nIVFhaiUqkICgrC4XCwaNEij/0FBwdz7ty5y+o1GB0dTevWrVm4cCE2m43du3d71ELLM3jwYP744w++/vprhg4d6l7/119/ceTIEZxOJz4+PqjVao/Wh4oEBQWhVCpJSEi46HaFhYUYjUZ8fX1JTU2tli7c7du3R6VS8X//9384HA7Wr1/v0VHgfOPGjeOjjz5y/xbk5+fz888/e2yzePFicnNzSU5O5ssvv3T/fg0dOpQvvviChIQECgsLefvttxk0aBBqtZphw4axdetWd1Nadnb2ZTf7wg2aaIKCghgxYgTvvfceDRs25I033mDu3Ll069aNjRs38sEHH6DVatFqtXzwwQds2bKFbt268eKLL/L666+7/8IeM2YMx48fp1OnTvzrX/+64rjatGnD3LlzmTNnDp07d2bAgAHunh6NGzfmvvvuY9y4cXTv3p2jR4/SoUOHy3odm83Gm2++SdeuXenRowdZWVnMmDEDgKlTpxIVFUXfvn257777Lqg1PfPMM2zcuJFOnTrx008/0a9fP/djEydOxGq10q1bN26//XZ69ux50Th8fHxYvHgxa9asoWfPnvTo0YP58+e7e+HNnj2boqIibr75ZmbOnEl8fHyF+4qMjOT999/nww8/5KabbqJ3794sXrz4kn4Mu3fvzqOPPsojjzxCjx49SEhIuOQL0y5XgwYNmDJlCvfccw8DBgygY8eOHo+vXLmSuLg4OnTowDfffMMbb7wBXPw7c7l69OhBz549GThwIHFxceh0Oo/ml1tvvRWArl27XvS8WUXmz5/Pnj176Nq1KwsWLGDw4MFotdoKtw8LC6N9+/bs3r3b/SMJctPWtGnT6NixI4MHD6ZLly7u7+vs2bOZPXt2ufszGAxMnjyZO+64g06dOnmczypr6tSpHDx4kE6dOjFp0qRyexpebVqtloULF/L999/TuXNnfvzxR2655ZYK35/+/fvzwAMPMGPGDDp06MDQoUPZsmWLxzZ9+/YlPj6ekSNHcssttzBmzBgARo8ezfDhw7n77rvp27cvWq2W5557DpCbqT/++GM+++wzunTpwsiRIy96zskbhSSJic+Eim3bto0nnnjigi+vIFwt06dPp2HDhu4OOoKnsWPHMm7cOEaPHn3Jz23WrBnr1q1zNzfWlBuyRiMIQs3Zt28fZ8+exeVysWXLFjZs2OBRM77Rbd++nfT0dBwOB8uXL+fIkSNeWweudTdcZwBBEGpWRkYGjzzyCDk5OURERPDCCy/QsmXLmg7rmnHq1CmmT5+O2WymTp06vPvuu+4T+LWVaDoTBEEQqpRoOhMEQRCqlEg0giAIQpW6Yc/R7Nq1q6ZDEARBqJXO737vzQ2baODCN+vQoUMe4/nUdtfb8cD1d0zX2/HA9XdM19vxwJUd0+X8kS6azgRBEIQqJRKNIAiCUKVEohEEQRCqlEg0giAIQpUSiUYQBEGoUiLRCIIgCFVKJBpBEAShSolEc4lO7cvgm5e243Je+qRPgiAIV8uWLVsYOHAg/fv356OPPrrgcZvNxvTp0+nfvz9jx451T9KYmJjIbbfdxogRIxgxYkSF8/ZcTTf0BZuXIz/TQmZiAdYiBwbfiidrEgRBqCpOp5M5c+bw2WefER4ezpgxY4iLi6Nx48bubb777jv8/Pz49ddfWb16NfPnz2fBggUAREREsHLlymqLV9RoLpHOKOdma5GjhiMRBOFGtW/fPurVq0dMTAxarZYhQ4awYcMGj21+++039wyoAwcO5M8//6SmBusXNZpLpDMUJxqzSDSCIMAPuxJZujPhqu7ztk4xjO5Yp8LHU1NTiYiIcJfDw8PZt2/fBduUTMGtVqvx9fUlOzvb/djIkSPx8fFh+vTpdOrU6arGfz6viWbYsGEXrPP19aV169Y8/PDDBAYGVklg1yptcY3GJmo0giDUQmFhYXz88cd07dqV/fv3M2XKFFavXo2Pj0+VvabXRNOzZ09UKhVDhw4FYM2aNZjNZkJCQpg1axYffPBBlQV3LRI1GkEQyhrdsc5Fax9VITw8nJSUFHc5NTWV8PDwC7ZJTk4mIiICh8NBfn4+gYGBKBQK/Pz8AGjdujV169bl1KlTtGnTpsri9Zpo/vzzT5YvX+4uN2vWjFGjRrF8+fJyazvXu9JzNPYajkQQhBtVmzZtOH36NAkJCYSHh7N69WrefPNNj23i4uJYvnw5sbGx/PLLL3Tr1g2FQkFWVhZOpxOAhIQETp8+TUxMTJXG6zXROJ1O9u3bR9u2bQH5JFRJkCqVqkqDuxZpRY1GEIQaplarmT17Ng888ABOp5PRo0fTpEkT3nnnHVq3bk3fvn0ZM2YMTzzxBP3798ff35+3334bgB07dvDGG29gMplQKpW8+OKLBAQEVG283jZ46aWXeOaZZygsLATAZDLx8ssvU1RUxKRJk6o0uGuRRqdCoVSIczSCINSo3r1707t3b491jz76qHtZp9Px7rvvXvC8gQMHUrdu3WqdY8dromnbti0//fQT+fn5gNwRoMTgwYOrLrJrlEKhQGdQixqNIAhCJXlNNDabjV9++YVz587hcJT+uE6dOrVKA7uWaY1qcR2NIAhCJXlNNA8//DC+vr60atUKrVZcCQ9yzzObqNEIgiBUitdEk5qayuLFi6sjllpDJ2o0giAIleZ1CJrY2FiOHDlSHbHUGuIcjSAIQuV5rdHs2rWL5cuXEx0d7dF09tNPP1VpYNcyrVGNTVxHIwiCUCleE83HH39cHXHUKqJGIwhCTduyZQsvv/wyLpeLsWPHXnC5ic1m48knn+TAgQMEBATw9ttvU6dOHfc0AQ0bNgSgXbt2zJkzp0pjrTDRFBQU4OPjg8lkqtIAaiOdUY3D5sLpcKFSiwGwBUGoXrVtmoAKE83jjz/Ohx9+SHx8PAqFwmN4aYVCccGQ1DcSrUEDgM0s5qQRBKH6lZ0mAHBPE1A20fz222/uy1AGDhzInDlzrr1pAj788ENADra2KSoq4sUXX0Sj0dClSxeGDx9+Vfdfdk4akWgEQeCzIdD+Toi9C5x2+HIkdJgA7W4HWxEsGQud74PWo8GSC1/fCV0fgpbDoTATlk6A7lOh2SDITwXf8Iu+XG2bJsBru8/EiRMrte58VquVMWPGMHz4cIYMGVLuUAiVNWvWLG666Sb3CNJllTed6bp16xg4cCAvvfRSlSRKMYKzIAi1Vck0AStWrGDmzJk8/vjjFBQUVOlrVlijsVqtmM1msrOzyc3NdVe5CgoKSE1N9bpjrVbLF198gclkwm63c+edd9KrVy/at2/v3iYzMxOdTucxD8KZM2eoV6+ex77i4+O5++67eeqppzzWV9ROmZqaSrNmzYCqGfhTzEkjCIKHe1eXLqs0nmWt0bOs9/csm4I9y15qM1D7pgmosEbzzTffEB8fz8mTJ4mPj3ff/vWvf3H33Xd73bFCoXB3JHA4HDgcDhQKhcc227dvZ8qUKdhsNgCWLl3K3LlzL9hX586d8ff3v2B9RdOZlv0QXC6X11gvlajRCIJQk8pOE2Cz2Vi9ejVxcXEe25RMEwBcu9METJw4kYkTJ/LVV18xfvz4y9q50+kkPj6es2fPcuedd9KuXTuPxwcNGkRiYiLTp0/n1ltv5YcffuDTTz+t9P4raqccP348c+fOZdOmTfTp0+eyYr8YMSeNIAg16bqbJmD8+PEcPXqU48ePu2seACNHjvS6c5VKxcqVK8nLy2PKlCkcPXqUpk2bemzz4IMP8thjj/HCCy+wfv36q9Kd2mg0Mm/evCveT0XEnDSCINS02jRNgNfOAIsWLWLu3Lm89NJLbNu2jTfeeOOST7D7+fnRtWtXfv/99wse27lzJ8eOHaN///4sWrTokvZbmXbKqiDmpBEEQag8r4nml19+4YsvviAkJIR58+axcuVK99w0F5OVlUVeXh4AFouFrVu3uq9ELXHw4EGee+453n//febNm0dOTo67elcZlWmnrApiThpBEITK89p0ptPpUCqVqNVqCgoKCA4OJjk52euO09LSmDlzJk6nE0mSuPXWWy84X2I2m1mwYAF169YF4LXXXnOfvCprxowZbN++nezsbHr16sUjjzzC2LFjK2ynrA5iThpBEITK8ZpoWrduTV5eHmPHjiU+Ph6j0UhsbKzXHTdv3pwVK1ZcdJuOHTt6lDUaDbfddtsF27311lsV7qO8dsrqIOakEQRBqJyLJhpJknjooYfw8/PjjjvuoGfPnhQUFNC8efPqiu+aJeakEQRBqJyLnqNRKBQeI4LWqVNHJJli4hyNIAhC5XjtDNCyZcsLxtARxJw0giDUrPKG3yprx44djBo1ipYtW7J27doaiLCU13M0e/fu5aeffiIqKgqDweBefyNPfAaiRiMIQs2pzDQBkZGRzJs375Iugq8qXhPN4sWLqyOOWkfMSSMIQk2pzDQBderUAUCprPnfJ6+JJjo6ujriqHXEnDSCIAD8eOJHlh+78LKMKzGqySiGN6p4epPKTBNwLan5VFdLlZ2TRhAEQaiY1xqNUD4xgrMgCADDGw2/aO2jKtTU8FuX66I1GqfTedkjN1/vxJw0giDUlJoafutyXTTRqFQqlEplpcY2u9GIGo0gCDWl7PBbgwcPZtCgQe5pAjZs2ADIHQZ69erF2rVref755xkyZEjNxettA6PRyLBhw+jevTtGo9G9/tlnn63SwK51Yk4aQRBqkrdpAtq2bcuWLVuqO6xyeU00AwYMYMCAAdURS60i5qQRBEGoHK+JZtSoUVgsFpKSki4Y5v9GJuakEQRBqByv3Zt/++03RowYwQMPPADAoUOHmDx5cpUHdq0Tc9IIgiBUTqVm2Pz+++/x8/MDoEWLFiQmJlZ5YLWBmJNGEATBO6+JRq1W4+vr67FOoVBUWUC1iZiTRhAEwTuv52gaN27MTz/9hNPp5PTp03z11VeVmvjsRiDmpBEEQfDOa43mueee4/jx42i1WmbMmIGPjw/PPPNMdcR2zRPnaARBqCnX1TQBBoOBxx57jMceewyn04nZbEan01VHbNc8MSeNIAg1obZNE+C1RvP4449TUFBAUVERw4YNY/DgwXzyySfVEds1T9RoBEGoCWWnCdBqte5pAsoqmRH5WpgmwGsEx48fx8fHh/Xr19OrVy82bNjAypUrqyO2a17ZOWkEQbhxnRk/gZxl8lQBkt3OmfETyP3xRwBcZjNnxk8gb80aAJz5+XJ53ToAHNnZnBk/gfzfNsrl9HSvr1feNAGpqalX9ZiuJq+JxuFwYLfbWb9+PXFxcWg0GtHrrFjZOWkEQRCE8nk9R3P77bcTFxdH8+bN6dy5M+fOncPHx6c6YrvmlZ2TRkx+Jgg3rnpffeleVmg0HmWlweBRVvn6epTVgYGe5dBQr69X26YJ8JpoJkyYwIQJE9zl6Ohovvzyy4s848YhRnAWBKEmlJ0mIDw8nNWrV/Pmm2/WdFgV8ppoFi1aVO76qVOnXvVgahsxJ40gCDWh7DQBTqeT0aNHu6cJaN26NX379mXfvn1MnTqVvLw8Nm7cyMKFC1m9enXNxOttg7JTA1itVjZt2iQG1ywmajSCINSU62qagPvuu8+jfP/993P//fdXWUDXOofLQZ4tjyB9kJiTRhAEoRIuuYO12Wz2OAl1o1l1chVDlw3F6rSKOWkEQRAqwWuNZtiwYe5ll8tFVlYWU6ZMqdKgrmWSJJFvzyfDnEGUKQqFUiHGOxMEQbgIr4nmgw8+KN1YrSY4OBi12uvTrlshhhAAMswZRPtEyyM4i0QjCIJQIa8ZIzo6ujriqDXKJhoonpNGNJ0JgiBUqOYHwallShJNpjkTKB7vTNRoBEEQKiQSzSUK1AeiQOGu0eiMamxm0etMEITqdSXTBMTHxzNixAhGjBjB5MmTqzzWG/dky2VSK9UE6gNLE41BTWGOtYajEgThRnKl0wRotdpqHRzZa6JZt24d8+fPJzMzE0mSkCQJhULB33//XR3xXZNCDCHiHI0gCDWm7DQBgHuagLKJpk6dOgDXxDQBXhPNG2+8wQcffECjRo2qI55aIcQQ4nGORvQ6E4Qb1+G/kjn0R/JV3WeLmyNp3i2ywsfLmyZg3759ld6/zWYjPj4etVrNpEmT6Nev3xXF643XRBMcHCySzHlCDCGczj0NFM9JY3fhtLtQaWr+LwdBEARvPv74Y3r06EFCQgITJ06kadOm1K1bt8pez2uiad26NdOnT6dfv35otaVD4Q8YMKDKgrrWBRuCyTBnIEmSe04aq9mBUSOmChCEG03zbhevfVSFK50mIDg4GICYmBi6dOnCwYMHqzTReP0TvLCwEIPBwB9//MHGjRvdtxtZiD4Em8tGvj3fPd6ZmPxMEITqUnaaAJvNxurVq4mLi6vUc3Nzc7Hb5Z6yWVlZ/P333x7ndqqC1xrNvHnzqjSA2qjsRZs6gx+AuJZGEIRqcyXTBJw4cYKnnnoKg8GAJEk8+OCDNZdoPv74Yx588EHmzp1b7tTNzz77bJUGdi0re9FmtDEIAKu4lkYQhGp0udMEdOjQgXfffZcWLVpUeYwlKkw0JR0AWrduXW3B1BZlazQNDfKHJWo0giAI5asw0ZS0940aNaragqktgg3yibQMcwa6AHGORhAE4WJEf9zL4Kf1Q6PUkGHOKJ2TRtRoBEEQyiUSzWVQKBTu0QE0OpU8J42o0QiCIJTroonG6XTy+eefV1MotcORlHzm/XyIYEMwmeZMFAqFGB1AEAThIi6aaFQqFatWraquWGqFbacy+XDzSfw0QWK8M0EQhErw2nTWoUMH5syZw86dOzlw4ID7dqOK8NMDoFcEeIzgLM7RCIJQna6raQIOHToEwDvvvONep1Ao+PLLL6suqmtYpL8BAJXkR7Y1G6fLKeakEQShWl130wR89dVX1RFHrRHhL9doJIcvLslFtjVbzEkjCEK1qm3TBHiNID8/n3nz5hEfH098fDyvvvoq+fn51RHbNSnYpEWrUmKzmQD5WhpxjkYQbmzfvjiT/ZvWA+B0OPj2xZkc/F0eE9JutfDtizM5vFW+St9aVMi3L87k2LatABTl5fLtizM5sWsbAIU52V5fr7xpAlJTUysdb8k0Abfddhvr16+v9PMul9cazdNPP+0eQwdg5cqVzJo1i0WLFlV5cJerqKiIF198EY1GQ5cuXRg+fPhV27dSqSDcX0dhkdyEJo93Fi56nQmCUGtcc9MEnD17loULF7rLU6dOZcSIEV53nJyczJNPPklmptwF+LbbbmPixImXFeSsWbPYtGkTwcHBF/SC27JlCy+//DIul4uxY8cyadIk1q1bx8CBA4mLi2P69OlXNdEARPoZyCkwgE5ONHWM0WJOGkG4gd3+/KvuZZVa7VHW6PQeZZ3R5FE2+vl7lE0BgV5f77qbJkCv17Nz5053edeuXej1eq87VqlUzJw5kzVr1vDtt9/y3//+l+PHj3tsk5mZSUFBgce6M2fOXLCv+Ph4PvnkkwvWl5wQ++STT1i9ejWrVq3i+PHjpKamEhkZ6Y7jaovw15OZI889I48OUDonjSAIQlW77qYJePHFF3nyySfdCcHPz49XX33Vy7MgLCyMsLAwAHx8fGjYsCGpqakeB7R9+3a++eYbPv74Y7RaLUuXLmXdunUXJJXOnTuTmJh4wWtUdEKsJNu3aNECl8vlNdZLFRmgZ+1+F8F1fMg0Z3rMSWP0E5OfCYJQta6baQJArjGsXLmSH3/80Z1ofHx8LvlFEhMTOXToEO3atfNYP2jQIBITE5k+fTq33norP/zwQ7ld8SpS0bzZ48ePZ+7cuWzatIk+ffpccrzeRPrpsTldBOrkizZ1gWK8M0EQqtd1MU0AyM1Ou3btAi4vwYA8Q+e0adN4+umny93Hgw8+yGOPPcYLL7zA+vXrMZlMl/U6ZRmNxiqdsC2i+Foak1pONNro4kQjrqURBEG4gNemsxYtWjB58mRuvfVWjEaje/2AAQO87txutzNt2jSGDRtW4fY7d+7k2LFj9O/fn0WLFjF79uxKB3+lJ8QuV6R/yegA/mSYz6ATIzgLgiBUyGtnAJvNRmBgINu2bWPjxo3umzeSJPHMM8/QsGFD7r333nK3OXjwIM899xzvv/8+8+bNIycnh7fffrvSwV/JCbErUZJoVJLfBedoBEEQBE9ez9EEBATw1FNPXfKOd+3axcqVK2natKm7O/SMGTM82hTNZjMLFixwd6t77bXXWL58+QX7mjFjBtu3byc7O5tevXrxyCOPMHbs2ApPiFW1EB8daqUCp8OXfHs+ktYJiBqNIAhCebyeo/n7778va8edOnXiyJEjF92mY8eOHmWNRsNtt912wXZvvfVWhfso74RYVVMqFYT76bFZ5PNJua5sMSeNIAhCBbyeo2nevPlln6O5nkX66ykw60EDmZZMMSeNIAhCBbwmmrLnaMq60RNNhL+ePal6CCoZ78woajSCIAjl8JpoqrKbcG0WFWDg1yM6tEHIHQIMfuIcjSAIQjm89jo7deoUEydOZOjQoQAcPnyY999/v8oDu9ZF+OmxWg0oUMgXbYo5aQRBEMrlNdE899xzPP7446jVcuWnefPmrFmzpsoDu9bJXZxV+GkDikdwFrNsCoIglMdrojGbzbRt29ZjXVUMVFnblEyAZlIFijlpBEEQLsJrogkMDOTs2bMoFAoA1q5dS2hoaJUHdq2LCpCHodEq/IvP0YheZ4IgCOXx2hng+eef57nnnuPkyZP07NmTOnXqMH/+/OqI7ZoW4qNDpVSgdPmRYT6GzqgWc9IIgiCUw2uiiYmJ4fPPP6eoqAiXy3XZg2teb1RKBeG+OlwOHzJsGWiDSwbWdGDUiKkCBEEQSlT6T2+j0SiSzHki/PVYLSZsLhsurdxsJsY7EwRB8CTaeK5AZICBgiL5XI1FVQiI8c4EQRDOJxLNFYj005OdrwOgSJEPiDlpBEEQzlfhOZp169Zd9Ik3+hA0UNJ05oMayFfkAlpRoxEEQThPhYmmZM6ZzMxMdu/eTbdu3QDYtm0bsbGxItEAkf4GXA75vFWOlAlEinM0giAI56kw0ZSMcXbfffexevVqwsLCAEhLS2PWrFnVE901LsJfDy4DKoWGLCkDLZGiRiMIgnAer+dokpOT3UkGICQkhKSkpCoNqraICtADCkyqADLsaWJOGkEQhHJ4vY7mpptu4v7772fIkCEArFmzhu7du1d5YLVBqI8OpaJ4dABLJg3F6ACCIAgX8JpoZs+eza+//sqOHTsAuP322+nfv3+VB1YbqFVKwnz1KFy+7hGcRY1GEATBk9dEA9CyZUtMJhPdu3fHbDZTUFAgLt4sFuGvJ9vuS4b5rJxoRI1GEATBg9dzNEuXLmXatGnMnj0bgNTUVKZMmVLlgdUWUQF6LBYj2dZsNAaVmJNGEAThPF4TzZIlS/j666/dNZj69euTlZVV5YHVFhF+BgoKDbgkFwqdJGo0giAI5/GaaLRaLVpt6SCRDof4IS0r0l+P1WoCwKWxi3M0giAI5/F6jqZz58588MEHWCwW/vjjD/773/8SFxdXHbHVChH+elwOXwDsGgu2ohoOSBAE4RrjtUbzxBNPEBQURNOmTfn222/p3bs306dPr4bQaoeoAD1S8egAVlWRe04aQRAEQXbRGo3T6WTIkCGsXbuW2267rbpiqlUi/A1IxTWaImUBoBdz0giCIJRx0RqNSqWiQYMGYiSAiwjz1aFAi0ZhoECRC4g5aQRBEMryeo4mLy+PIUOG0LZtWwwGg3v9Bx98UKWB1RYalZJQHx0K/MmVstEj5qQRBEEoy2uiefTRR6sjjlotMsBAqsuXbCmDcMScNIIgCGV5TTRdunSpjjhqtUg/PefMPmSo0gBRoxEEQSjLa6LZs2cPc+fO5eTJk9jtdpxOJwaDgb///rs64qsVIvz1WLJNpGlOAuIcjSAIQlleuzfPmTOHt956i3r16rF3715eeukl7rrrruqIrdaI9Ndjs5rIkjIAUaMRBEEoy2uiAahXrx5OpxOVSsXo0aP5/fffqzquWkW+aNMHh9KGQokYHUAQBKEMr01nBoMBm81GixYteP311wkLC8PlEhcklhUVUHwtjQJUeoWYk0YQBKEMrzWa119/HZfLxezZszEajSQnJ7Nw4cLqiK3WiPDTIznlizYVOpeo0QiCIJThtUYTHR3tXp46dWqVBlNbhfvp3aMDSFqHOEcjCIJQhtdEExcXh0KhuGD9hg0bqiSg2kirVhKkD8KGAofaJuakEQRBKMNrovnhhx/cyzabjZ9//pnc3NwqDao2ig4wkSD5YFWbRY1GEAShDK/naAIDA9238PBw7rnnHjZv3lwdsdUqEX56cPpiVhaIczSCIAhleK3RHDhwwL3scrnYv3+/mPysHJH+ehzJPhQq80SvM0EQhDK8JppXX321dGO1mujoaBYsWFCVMdVKEf4G7KdN5ErZ7jlpVJpKXaYkCIJwXfOaaL766qvqiKPWiwqQuzjnkAUg5qQRBEEo5jXRfPbZZxd9/N57771qwdRmEX7ylM5mZQogj3dm9BOJRhAEwWui2b9/P//88w9xcXEAbNy4kTZt2lC/fv2qjq1WiSyeadNqPAWI8c4EQRBKeE00KSkpLFu2DB8fH0C+aPOhhx5i/vz5VR5cbRLur0Ny+GBTmQExJ40gCEIJr2erMzIy0GpLm4C0Wi0ZGRlVGlRtpFOr8NcGYVUXJxpRoxEEQQAqUaMZOXIkY8aMoX///gCsX7+e+Pj4Kg+sNgo3hZJdXKMRc9IIgiDIvCaahx9+mF69erFz504A5s2bR8uWLas8sNooyi+YFIcNEDUaQRCEEl6bzs6ePUuTJk2YOHEizZo1Y+fOneTl5VVHbLVOlL8Bh6RDUogRnAVBEEp4TTSPPPIISqWSM2fO8Pzzz5OcnMzjjz9eHbHVOhH+epwOH5wamxgdQBAEoZjXRKNUKlGr1axbt467776bp556ivT09OqIrdaJCpCnC7CqLaJGIwiCUMxrolGr1axatYqVK1dyyy23AIixzioQ4WfA5fDFoiwU52gEQRCKeU008+bNY8+ePUyePJmYmBgSEhIYPnx4dcRW60T665EcPphVBViLxHU0giAIUIleZ40bN+bZZ591l2NiYpg0aVKVBlVbRfjL451ZVUWYi6w1HY4gCMI1QQwvfBXpNSpMqkBsajMWUaMRBEEARKK56oL1wVhVZuxmV02HIgiCcE0QieYqi/AJxaY2IznAaRfJRhAEwes5mlOnTrF48WKSkpI8ept9+eWXVRpYbVXHL4wzqSUDa4o5aQRBELwmmkcffZRx48Zx2223oVSKCpA3dQMDOaqQE7KYk0YQBKESiUatVnPnnXdWRyzXhQg/PVaFvCyupREEQajEOZo+ffqwZMkS0tLSyMnJcd+E8kX66zEr5LdVzEkjCIJQiRrN8uXLAVi8eLF7nUKhYMOGDVUXVS0W4a/HKqkAUaMRBEGASiSa3377rTriuG5E+huwSPJ5GTEnjSAIQiUSDcDRo0c5fvw4NpvNvW7kyJFVFVOtZtCqQG0AoLDQUsPRCIIg1DyviWbRokVs27aNEydO0Lt3b7Zs2ULHjh1ForkIk84fp8JJbl5BTYciCIJQ47x2Bvjll1/44osvCAkJYd68eaxcuZL8/PzqiK3WCjGGYFOZyS8orOlQBEEQapzXRKPT6dxz0hQUFBAcHExycnJ1xFZrRfqEYVObKSwQTWeCIAhem85at25NXl4eY8eOJT4+HqPRSGxsbHXEVmvV9Q/HrDpEUaEYwVkQBMFronnhhRcAuOOOO+jZsycFBQU0b968quOq1eoHhrFH/TcW0b1ZEATBe9OZJEmsXLmSRYsWUadOHfz8/Ni3b191xFZr1Qnwxaq04RQtZ4IgCN4TzQsvvMCePXtYvXo1ACaTiRdffLHKA6vNIvz1WJVOsImx4QRBELz+Eu7bt4/nn38enU4HgL+/P3a7GFrlYiL99VgVLlT2Sl2mJAiCcF3zmmjUajVOpxOFQh4pMisrS4zi7IVJp8ahVKB2acScNIIg3PC8Zozx48czZcoUMjMzefvtt7njjjt46KGHqiO2Wk3SyLUZMaWzIAg3Oq9tO8OHD6dVq1b89ddfSJLE+++/T6NGjaojtmtW3s8/ow4Lw9ixY4XbaPRyU2NOfh4m/9DqCk0QBOGaU6k2sJCQEDp27EhsbCwWi4UDBw5UdVzXLEmSyFjwBhkLXr/odiajEYC0nMzqCEsQBOGa5bVGs2DBApYvX07dunXd6xQKxQ07lbNCoaD+CAmnXU4gjuxskqc/RNjUh9B17uvezt/PH4DULJFoBEG4sXlNND///DO//vorWq2YkriE8t5lKAvSAbAdO4p57z7Y/RV07ovkdKI4sooYkwo7kJSRU6OxCoIg1DSvTWdNmzYVg2ieJ/lcGsk5EgDGLl1p/MtP6MY8D0DqC8+SOO1R2hftASAzMwPWPAFJchm7GVIPgE0MuCkIwo3Ba41m0qRJjBw5kqZNm6LRaNzrP/jggyoN7Fr2x7f/h62oiDtffhOAHz76HBQKxj77Epq6jdiT2RtnUSAA9r//ZtaBbRhPJtK6z0hab9hHzv7lBNz6MI0GP0j+d59yYt8yAgY8QP0eIyj8+WtO7V1J0K2TiYrtg3XzMs7u/IaAIY8T2vImHDtXk/TH5/gPf46ARu1xHd1E9paPMA57CWN0Uzi1BcsfH6EZNl8O9sxW+Od76DsbDAFwbhec2gJdHgKtEdIOQ+p+aDkCVBrIPg05Z6FeD1AqoSANzNkQ0hQUCrAWgNMGxiB5/y6XvL64+7sgCML5vCaamTNn8uCDD9K0aVNx/UyxvvdNxlFmErhm3Xu6l4MffADHgkxUkoQdFwGuoejTsijK17A6809Cf0lga/16FG3fRP1AG11f/oTtHRpQf98h6jS/mcSn3+B/sfVpHLSD0PBmnH50LhvaN6BFwJ/cbIjg1H1Ps659Q9r5b6arTc/psY+wtl1DOmrX0im2kDMTp7KmRV26sZIgUzhHF7zOr1F+3OT4mRYNW5H8wkx2mMzESq2pGxxN2puzOK5IoNljjQnR+5Lz8WwKirYS/vx2dDYH5m+ex5T5PaqXsnDm5eH86Xk0J/6LYnaqfMC/PA17/wszz8rldc/C0XUwdbtc3jAXErfDxJ/k8pb5kHEM4j+Uy3/9B/KSYMBcubx7CVjzodtkuXx4NTjt0GokAIb0veCTDzFd5MezToJSAwExctlulssqcbGsIFwrvP5v1Ov1TJgwoTpiqTUCI6M9ym373upRHjr9KQC+f/13nAl5BAWOJ9SlJDZZyd62YJRcKPILOfLzOfaMiifd5xxrTSd477d/EzOpDRafAP70LWDpti+pf88g8n2DOR4Uyrpdf1P/9gkUBoSzydSIP/dkU2/IBGxBAWxQNOJ/f2fRpOutOMKDWVsUjSKpgF512qBtEMZZVSia5FxU6iAc4SG4lFocmZnknsxlf3Q9QpJT8DEnkrh6H5tatmLgvj3UyS7g+Gd/sqVldwb/sZnwc6mcevVXzg4aTNdjR9Dv3kvSmxvQ3j+WOvl52P/4k5wv/qHOXf1RAkU7d1K06SzBHRugAOxJSThOp6E32HDXf7JOQtap0jfv6Fo58ZQkmu0fga3InWhC//kATpjgXnlIJJZNAq0PTFghlz8dCD4RcNdSufzFcAhuBEPflssr/gUhTaDHY3J54ytyba3NGLm891sIrA91u8rlxF3gGw7+deSyrQg0BlGDE4RL4DXRdOrUiTfffJO4uDiPDgGtWrWq0sCuB4uf7InN4SI1z0JqnoXE1EJSz+aRm1yELVOPX54PkflNaZKthARw4SJXl02WIYVsYzIZppMc80sl15CG01Y8EnTD4p3bVeD0hWa+KJy+ULQLhdMPZSsfcKpQ5p7DajHxZcxgcKjhDytghYYTUCogaKOdMF8dYRNeJ8xXx2+SgfrRRqK/WcUgSyZ1G9bHoFDSIOpjLCcPExxTD1Od+gQ8PoO9+7bjsNvQ1q+P45berN1wmDE3nSTAaiHFpmTNj2cZ0fwI6q1/cvrH7RyPnUWbnGwKv/6GtC/W0mznTjRA2ptvkfvjDpps3gRAzrLlWI41J+LZrwAw/7MfV/1HMXVqD4DkcpHceRaNGzYsfZPjngOlqrTcZRJoTaXlOp3BN6K0bCsAR5npGw6uhAa9ShPN2qeg9ZjSRPPlCOgwAW59RS6/Vh+6PiTXwCQJ3usiv2aXB8HlhGUPQpux0GyQXBPb9oG8/8h2cjlxBwQ3Bp8wcLlQOEtrxoJwvfKaaA4ePAjAnj173Otu5O7Nl0qrVhITZCQmyEin+kHQ1fNxp9NFVnIR507nkpdWRG5KKLkpdchLMSOVjF6jAEOQEk2IBEE27IF55AamkKFIIdOSSaY5kwzzCbIsWTik0iFvFIC/QkmwPpQgbTg+6nB0hKB0BuG0BlJU5E9GvsTBpDzS8j3nzvHVpVM32Ei9YCN1g7qRkKKkXpCRuiPGMWHCvaiU8l/0Ldq2IfTsGYLrxKBr054Gse3I+flHTAGB+D4ylfQ2zfn5g3do2q0n/vGjSPTV8+74eO575yMM7dqSmpfNxs8/4qaxd2I7c4bcvXvwzcnG6B9A1hdfYN67l8a/rgMg6d//xn74MKxZA0DWl1/iMlsIeWgSAJZDh1D43YSu7AXFfZ/zfMNvO+97O2WbZ/lf2+RzVSVu/xJ8o+RlSYK4ZyCqg1x2OSC8NZiKL8h1WCB5L9TvIZcteXJT4qDX5URTlAmfDYIhb0LnByDvHM2/7wW2RdBhPOQkwDd3QN8XoEk/yEuGLa9Dx3shsi0UZsKxX6DhLeAXJdeu8pLAP1quZQnCNcprovnqq6+qI44blkqlJLSOD6F1fDzWO+0uctKKyEoqJCu5kOxk+T7nGEiuYLQE0zSoAxEN/Ylo4E94az+Coozku/LIMGeQaclkz/E9SH4S5/LPca7gHIkF+0grSkNC7jGHAtT+aiKiIoj1rUeILgajIhqXLZyi/ACScxQcTs7n14Op2J2SOza1UkF0oIGYQGNxEjUQY86lbpCdmOAo+k96xD02Xss+/WlyU09UWg1KpYqYgYPoHhSIT1Awmn79cEl29i/5lB53TCDssemcqh/FqofGM+2L7wl7fAaH/reJte8vYMDkR/DpE0dKoD+ZiWcJrlMX875/cObnueNKeellFCoV9b78AoCEqVNRB4cQ+eILAGQvXYo6NBTfPn0AcGRlofL1RVGmkwu+4Z4fUKO40mWFAm5+tMyHp4Gxn5WWtSZ4ZFdp2RgEMxNAWfzfTB8A41fINZri7dPaTCYsqmQiQQn8Y0prZEWZcPBHaDZELmcehxUPw90/yIkm6W/4fAhM+BEa9oaTm+G7iXDXD1CnIyTskBPVra/KzYdph+DQKuh4D/iEykkq/QjEdJU7htjNcvLU+oimQeGqEmdMr1EqjZLgaB+Coy9MQOkJ+aSeyiPlZC4pJ3M5vjMNAKVaQWiMLxEN/Qlv0Iib9H7Etm/t8Xyb00ZKYQqJBYmcKzhHUkESifmJnM47za60nVidpTWbUFMoDaMb0s+vEUHaGHRSBE5LOJn5GhKyikjINvPLgRSyCj2bf0xaFTFBRuoEGogKMBAdIN/Ly5F0jR+HsrhG1K7/INr2u9WdmBp26IzB1w+NXg+RkVh1WlJPHUepVOE/bCgnD+/lrxdmMuWT/xI9/w3+WvYtexe8xrDpTxH+9CyST5/g7P691G3dDl3DRqj8/dxxZX70MYYOse5Ec2rMGEydOxP12msAnHviSYxdOhM4diwA+Rs2oG3QEF3DBpf3ISoUoC99fTR6aNSntGwMIrPlPYRFtJDLAXXhjq9LH49oDU+eKC1HtYdpe+RmN4DgJhD/MYS1lMs+YXKznU9JDcss9xoskbIfNr4ErePlbU78BiunwKP7QFsP9n4Dq6bDjENyItvzNfzvLbjvFzlpHlkLB5bDsAVyDSphO5z7W66dqdRyj8X8VJB85dezFcnvgaht3fBEoqllVBqlXItp6E+7vnJPq8IcKymnckk5mUfqqVz2bznH3g0JAOz/cStRTQOJbhJAVJMA/EIM1PWrS12/uhfs2+lyklSQxMnck5zIPcGJnBOcyj3FyhMrKHIUubcLM4TRLKwZfZs3p1lQM2JMzcERTGKWhYRss5yEsopIzDaz/VQWeRbPmUY1KgUR/nqi/EuTUGSAXI4MCKZe975IkoRCoaDz8NF0Hj7a/dx6XbrTsd8Ad1mhVLp7QxpatWLvqu/J3/wrE15fSNiMx1g5/yUcr8xm9NNzaLT2Z3atWkHGr2to138woVOmkK9Vk5eRjl9IKPakJFy5uYB8Pihx2qME338/YTMeQ3I6Odq1GyH/+hfB992L5HCQ/MIL+A8Zgummm5AcDop27EDXuDHq0Coa206tg6AySc83HNreVloOawGD3ygtN+gFD20uLbcdK3djL6lhNRkI9/5ceg6rTmcY8BIY5K75GIPlJKaRh1MiPwnObi19/rFfYcsb8jkrgF2fw5/vwZgtcnnjy7DzM3gmqbj8ivycSRvl8vaPIeUfGP6uXD6wAvKTodvDcvnsNvmcWuPiETeyz8j3gfXke6ddjkXUvq55XhONzWa7YFSA8tYJNccUoKNRbBiNYuW/dJ0OF5nnCtjzx1EcuVpO7U3n8NZkAHyCdEQ3CSSqaQDRTeXEU1KbUClVxPjFEOMXQ++Y3u79S5JEalEqJ3NOciznGEeyjnA4+zBbk7bilJwAGNQGmgY2pVlgM1o2a0Z8UHOaBLbGoDaQb7GTlGMhKcfMuRwzSe6bhW2nskjJs+B0SR7HZNSqiPTXy0nIX0+kv4GoAD12ux+BUU0psDrw0anpOnKsx/P6PzgVa1FpUqzXJhanQx5BW6FWc2r/HjQ6He36DyZg9Gh+fPIR/A7vY+QTz1F/yf+xdM7ThHz+IX0mPEiD5cvY+ccmsv/8nSaxnQkYPZpMow5l8jl89UYKN29B17IVpptuwpGZxdl77yPihecJHDcOe3IyJ0eMJPKF5/EbPBh7Whrpb75F4F13YmjbFmdeHoV//QW+8l//kt2OZLOhMBrdn0eVUJf5f+sTWlr7AbkGFVGmBtx0gHwr0ek++Vai95NyUiiJt8NE+fxRSaW46UC5KbBEQD1wNxMi17ZyzpSWD6+CpN2liWbru3KvxJJE8/NTkHcOJv8ul/97m9wV/oH1cvmHB0ChKu06/8szcjNkn6fl8h/vykm0w3i5vO87MAZC435y+dTv8uMl70HmCdD5lsZnN4NK69n5RKgUr4nm9ttvZ/ny5V7XCdcOlVpJWD0/YopMtGjRAsklkZVcyLmjOSQdy+bswUyObEsB5CQV1UROOlFNAggIv/CHTqFQEGGKIMIUQffo7u71VqeVEzknOJJ1hCPZRzicdZg1p9aw9KjctVipUFLfrz7Ng5rTMrglzYOaM6xBc/x19Tz273RJpOVbSMqxkJxrJjnHQlLxfXKumcMp+WQUWJFKctF6OXZfvdojCUX4ldaMItIKiArQ037gEI/XGvvsS0hSaVK7ZcKDqMqcowlv2Bj/0HAUSiX6pk05+v6bWFxOmt3Uk/BZM/n+vnE0L8ql730P0+T3LSy85zbausz0HHsXdb/8gtU/fUfLjcE0b90ev6FD2XXsII0PxhCm0VOwYzuZLZoQEx6GLjmFxGmPYv33DBwdO2L75x/O3HU3MYs/wefmmzHv20fqK/OIePEF9M2aYT15krxVqwi4fRya8DAc6elYjh7F2L49SpMJyWZDkiSUxRMUVguVpvTCXZBrW0EN4NAhudygl3wrEXuXfCsR94zn/kZ/IvfcKzHodfnHvUSP6Z4jarQdJ188XCK4MSjKXOtXlCXXekocWQN+0aWJZvOrENG2NNGs/BfU7V6aqD4fIj/WdIpcfrsVtBwJQ9+Sy++0l2uUJYls8UC592KXB+XyN3fJzZStR8vHtXam3BuxURw4bPDXe/L7E91R7gm5fxnU6SR3v3dY5YutQ5uDX6S8feZxuUnTEABOB1hy5USovvb/6K8w0aSnp5OamorFYuHgwYPu/5wFBQWYzeaKniZcgxRKhft8T9s+dZAkiezkIpKOZXPuWA7njmRzbId8AabBV0Nk4wCiGsuJJ7iOj/t8yvl0Kh0tg1vSMrile50kSSQVJnE48zCHsw9zKPMQO1N3subUGvc2UaYomgc1p3lwc1oEtaBFUAsi/MKI9DcAgeW+Vkk38b/2HUYbEE5yroXkHDNJuRZSci0cSMolo+DCrsL+Bk1xMtITGWAg0k++j/LXy813zVqh15T+hdr77vs8nn/fgg89EtOomS+g9/F1H2vn4aOJaNQEpU6HoWNH+Hk5kiShDg0lZOaT7Lnndkz16xMzYgz1Vv3Eontvp3dIEB363krk/33Fp2+8gBQdQZu2HTBN/RdfLF5InMtGff9grHotKz7/gG53TCAoNYNzH3/MbkcR7UaNRX/gMKeeehLbrH/TbMAgpK1/cfbpZzC+8ybR3bpj/2MrKR9+SOArLxHQqDG2nbvIWfMzYU88gcbfD8vBg5j37ydg5EgUWq18jVN6Ovo2bVAolbgsFvm7o9NVbQ3rfGVrC/6e16tRt5tnud3tnuVbZnqWR/3Hs3zfWs/yAxs8y+P+W9pMCDB4vtysWDICV68n5CRQoumtpefHQE4AJc93OeVzVuZsuey0wT/fyddoNYqTz5+tfwEGviInGkserJgsv2ZIEyjMgK9GwrB35M4beefgPzfByP9A+zvlmt57nWH0Yjm5peyHD3vCbV9Bi6GQvA+WjIH4j+RaZvJe+RqyoQsgpjPVTSGV/V9UxvLly1m2bBn79++ndevS6rTJZCI+Pp4BAwaU97RaY9euXXQ8bz6ZQ4cO0aJFixqK6Oqr7PFIkkRumpmk4zkkHcsh+XgOeRnyD41WryKiUQBRTfyJahJIWD1fVOpLHyEiy5LF4czDHMo6xOGswxzOOsyZvDPuHnCBukCaBjWleaB83qd5UHPq+9dHo9R47Odix2SxO0nLs8q1oVxzcTKSa0VJORZS8iwXdFwACDRq3LWiSP8y54uKm+7C/fRoL+OYS0gul/zj7XSSfvY0poBAfAKDsFnM/Lb0azrdEkdI3fqY8/P4Y+kSWvS4hehmLchLT2PNovl0ix9H/XYdSD9zmqVzZjHw4enUb9SUxD9+54evPmLkk7OJ9vHn5Mrl/Lzrf4x+eg4huQUc+fJzNuWncdvsV/A5cJgDH/2HbcEmxs15A93GzRz85CMOdmrN6Fkvwo+rOfzFp5wdcAtDpj2B7etvOfrfr8i8PZ6+903G8u1STq1dTd6IIXQfexfmlT+R+Of/KIzrRcfBIzBv2EjqP3uxdOmAMjSK+nn5ZJw8hr15Uxp17Ir10GHyUpOxR0UQ3awljtRUinJzcPj4EFwnBpfFgs1qwQUY/QMAcDrkc3sqdc2eSq6S3wVJkrvDK1RyjcTpgNyzYAiSE5bdIjcjBjWQk521AI6vl5seA+vJtbV/voNGfSGksdwVfscncmeQsObyRdD/exu6TobwlvJQU7/NhVtmQUTrKzqm8n47vakw0ZT45ZdfGDhw4GUFdC0Tiebi8rMsJBcnnqTjuWQny00WKo2S8Pp+RDbyJ7JxABEN/dAZNV72Vr5CeyFHs49yKPMQR7OPcjjrMMeyj2FzyclAo9TQOKAxzYPk5NMssBmkQ6c2nS7r9UBORsm5pU10ybmltaKkHDk55Zo9Z0VVKCDER0eU/3mJqDgxRQcYCPXVua8tuhRX8hm5nE4shQVo9QbUWi3WoiIyzp4muE5d9D4+FOZkc+afPdRr0x5TQCDZKUkc+WMLrfr0w2Qwkbx/H/t3beOmMXegLzJzeuvv/HPyCP0nPYL61GmO/vYre9PPMWrmC0h/buPAb7+wOz+Tia8vxLp8BXs3b2C3NY+HP15C3jsL2bvrL/broP/MOQT/33/Ze+wAhwwqpn31A6n/fpK9CSc4rIUZX/9I4pSp7E1P5KhGLp99cBJ7ctM5pVPy6Fc/kPCvKewuyOSsWmLqp9+SNHMWu3JTSVEpeHDRYlJefoW/M5PI0qm5e94C0he9x+6UM+Qb9Yx+eg5ZX37J32dPYPE1MfTRJ8lZsYLdJw/j8PWh/4NTyd+4kT2H9yH5+dHrrnsp+vtvdu/dicrfn27xt2M9cYI9O7ai8ffHUL8JTUJD2fvHJrR+frTpMwDJ4WDPhrUYfP1o3l1uHvznt3UY/f1p1FG+WO7A5g34BAZTr217AA7/sRnf4FCim8u1oGPbtuIXGkZ4Q7m7+4ld2/EPDSOkbn0ATu/9G7/QcIKi5JpdwoF9+IWG4x8WLl+8fPwoviEh+AaF4HI5yTh7Bp/AIIz+AbhcTrKTkjAGBGDw8cXldJKXkY7B1w+d0Vjticbrnwo33XQT8+bNY8eOHQB06dKFKVOm4Ovr6+WZQm3mG6THt0sETbvIPZLM+TaSj+eSdDyH5BO57F53ll1rz4ACgqN8ihOPnHx8g/SVeg2TxkRsWCyxYaUniB0uB6dzT3Mk+4jc6SDrMJsSNrH8eOk5wfDD4TQJbEKTwCY0DWxKk4AmNPRviEblPeHpNSoahJhoEGKqcJtCq+O8ZFSakE6kF/D7sXQKbU6P56iVCsL9SpvoovzLLstJKdikvarNUEqVCmPxvEcAOqPR/SMGYAoIpGXP0u7UgRFRdBs9zl2O7tyV6M6lVxA3rXsXTUsKIaG079yZ9iXlYUPpPmwoJWfofO6/n7j77+cWlxOFQonxuWcJtljoXlhAQkoqkXPn4JueRifJhVqtIezfj9P5XAKtTSYUSiXB999Hm4QzNImQO7AExI+i+bkE6jeQz9+ZunWlQVoyUc3kpipVcBCRWiUhbeXWFWdODgFKNT5t5AiLduxA66sjsPhi3ez/fo2rbgS6TvIPYvo772JuWg9lu3YAJD/7HFmtGqNpI+8vYfLDJLdvjr6l/P6dGjOWk51aY2rRnCb1m3Cs9y0cuKkd/s1b0rp3Pw63bsPfN7UjtHVbmnbsyrHuN/NXu8ZEtutA/WatOTV8OP+rF0K9zt2oU68BZybew8YADY1u6kF4WATnHp3OL0ozLXrHEezrT/LzL7A6L5m2AwZz88DhpL/1JssTDtNp6Ci69R1ExgcfsvTgdm4acwede/Yl46v/4+udm+gxbgIduvUkY9ly/rtlDb3uvo/2nW4ifc0avl63nD73PESb2M6kr1/P1z99Q78HptCu/6BL+6JdBV5rNI888ghNmjRh1KhRAKxcuZLDhw+zaNGiagmwqogazZWxW52kns4juTjxpJzMxW6Rf3x9AnVENvInopFc4wmu44NKdQVNT5JEujmdw1mH+ePIH+RqczmWfYyTuSdxuOTmFbVCTX3/+jQJaOJOQo38GxHtG41ScfmvXVE8eRbHBR0XknLMxc12cnKyOVwez9Oqle7zRSXJR2HOJbZZfXfTnb9BU73nRKrAtfL/qKSLPMgTFCpUKlR+8nVN1hMnUJpMaCLkP6SKdu5EFRTsvmYq75d1aOvGoG/RgkOHDhGxZw/6Fi0wtG+P5HKR+eGHGDt1wtCxI5LDQfqbb6Hv0R1T124oHQ5S5sxF2zcO35tvRu1wkDTraTSDb8WvZ0+0Njvnpj+GavQoAvv0QWu2kPDwv1DefQfBcXHo8go4+8CD8MA9hPXtjzYrhzMTJsC0fxHRfwDa1HRO3XkXPDmDqP4D0SYkcmr8BKRnniS63wC0p85w6v77cT0zkzpx/dAcPcaZh/+F/ZknqRfXj6CoOtde09mIESNYuXKl13W1jUg0V5fLJZF5roDk47kkn8gh+XguhTlyP1e1Vm5uC2/oT2RDf8Ib+mHwubyeMmWPye6yczr3NMeyj3Es55h8n32MpMIk9/Z6lZ4G/g1oGNCQxgGNaejfkEYBjajjUwdVFXZTlSSJzEJbmUQkJ6Ck4k4MybmWcrt1GzSq4ppQcTNdmea6SH89kX4G/AzqazoZif9H1UtyuZAcDhQqFQqVCslux1lQgMrHB4VGg8tiwZmZiSo0FGXxZSnXXNOZXq9n586ddOrUyf0ien3lmkZqSlFRES+++CIajYYuXbowfPjwmg7puqdUyqMShMb40raPPNJxfpZFHr2guMazZ91Z/i7+YQ0INxLR0M998WlgpKnC3m0V0Sg17tpLWQW2Ao7nHJcvPM05wYncE+xK3cXqk6vd22iVWncCauDXgHp+9ajnV4+6fnXx1V55s7BCoSDER0eIj442dfzL3cbpkvjj7/34hNXxOEeUkisnpz+OZ5CaZ+G8XIReoyTS30BEcVNdeHEtKcJP7kkX4a8n2HR554yE2kehVKIoc12jQqNBHVjae1Op16OMji7vqdXGa6J54YUXeOqppygoKECSJPz9/Xn11VerIzYPs2bNYtOmTQQHB7Nq1Sr3+i1btvDyyy/jcrkYO3YskyZNYt26dQwcOJC4uDimT58uEk0N8Q3S4xukp0knefwwu81J+pm84qa2PE7/k8nhP+VrYtRaJaF1fQmr70d4PT/C6vt6XEx6KXy0PrQPa0/7sPYe6wtsBZzKPcWJ3BOczJFHP9iXvo+1p9aWjv8GBOuD3Ymn7C3GNwa9+ur9kaVSKgg1qWlRt/wu3QAOp4v0Aqvca674XFFqnsWdkLadyiI1z4LjvGykUirk0bn99IT76ojw1xPuV3LTuZf99Nd27Ui4PnhNNC1atODHH3+koKAAAB8fHy/PqBrx8fHcfffdPPXUU+51TqeTOXPm8NlnnxEeHs6YMWOIi4sjNTWVZs2aAaBSiat4rxUarYqoJoFENZF/WEu6VaeeyiX1TD5pp/PYv+kcex3y8Dk6k7o46fgRVk9OQlfCR+tDm9A2tAlt47He6rSSkJfAmfwznMkrvf1+7nePTggAIYYQonyiiDZFE+0b7V6O8oki0icSnerqXjCpVimLm9AqHi/M5ZKb6UoSUUrxtBSpeVZS8yyczixk26msC3rTAejUSsL8dIT66Ajz1Zcu+8nlUF8dYb46gn1EDUm4fF4TTX5+PosWLarxXmedO3cmMTHRY92+ffuoV68eMTHyMBdDhgxhw4YNhIeHk5KSQosWLXC5XOXtTrgGKBQKAsKNBIQbadYtEiieNuFcIamn80g7k0fa6Xx2/XzaPSqA1qjkWH0rIdE+BNfxIaSODwHhxsu6tqeETqWjcWBjGgc2vuCxAlsBZ/PPcibvDGfzzpJUmMS5gnPsz9zPr2d+xSF5juMWagiVk44pknBjOOGmcI/7EEMIauXVvS5EqVQQ6qsj1LfiZjoAs81JWr6cgFLyLKTmWkgvsJKWZyEt38rx9AL+PJlZbkJSKCDIqCXUV1fcJKiV788rh/rqLqhdCYLXb/zTTz9NkyZNeOeddwC519msWbOuiV5nqampRESUTmoVHh7Ovn37GD9+PHPnzmXTpk306dOnwucfKhkqo5jFYrlgXW1Wm49HFQqRoRDZyRen3Yf8dDv5qXZyUixkp+eReCSL4mHWUCjBFKTGJ0SDT4gaU/G91qi8Ks1CChTUpz71tfVBi3vwApfkIsuWRbotnXRrOmnWNNKsaaRb0tmTt4dMWyZ2yX7BvgI0AQRrgwnSBuGv9Cc0KZQgbRCBmkACtYEEagIxqqpuzDNfwFcLTUKBUAB98U1mc7rINjvJKnKSZXaSbXaQZXaSY3GSY3aSkZvP8RQn2RYnVkf5ScVHewZ/vQp/vRJ/nYoAgwp/nQp/vYqAkvV6FX46FX56FVrVtVtbqs3/jypS3cfkNdGcPXuWhQsXustTp05lxIgRVRrUlTIajcybN8/rduf3urjWe5dcquvteKD0mJxOFzmpRWSeKyAzsYCMxEIyzxWQcjjfva1WryIg3Ih/mJHACCMBYUZ3DUqjq/omVUmSyLXmklqUWnor9Lz/J/cfzJkXDumkV+kJNYYSagglzBjmXg4xhHgs+2n9avQcS6HVQUaBlYwCK+n5NjIKrBw5fQ6lwY/MQhuZBTayCm0cy7aSVWi7oGNDCZNWRaBJS5BJS4BRS5BRI5eNWgJMWgKNGgKNWvwNGgKKl41aVbUc+/X8/+hy7Nq1y/tG56nVvc5KmshKpKamEh4efpFnCNcLlUpJcJQPwVE+UGboJnOBjcxzhWQlFZCTaiYntZCUE7kc25lKmfP9mAJ07qTjF6LHL9ggd14I1mPwvTrXsigUCgL0AQToA2gW1KzcbQ4dOkS9xvVIN6eTVpRGhjmDtKI00ovSSTPL94eyDrE5cTNmx4UJSavUEmosTkDFySfEEEKwIZhgfbB8X7x8NTsylDDp1Jh0auoFl14Ae8i/qNwfMZdLItdsJ7PQSmaBjcxCG9lFNrILbWQX2ckutJFVXD6VUUBOoZ18q+OC/biPXaXE36ghoDj5BBi1BBg0+Bk0+J938/NYVqNTi3O31anW9DorT5s2bTh9+jQJCQmEh4ezevVq3nzzzZoOS6hBBh8tdZppqdPMsyeXw+YkJ81MTmqRfEuT74/vTMVa5PljptYo8Q3WuxOP+xaoxxSgw+ivRa25ej9URo2Rehq5Z9vFFNoLSS9KJ92cToY5g/Si4nuzvO5U7im2p2wnz5ZX7vN9ND4eCShIH0SQPohAfSCBukAC9YEE6AII0gcRoAuo1EgLl0KpVBBo0hJo0tI4rHLPsTlcZBfZyCmyk1NkI8dcfF9kJ7vITq65ZNlGQlYR+812cs12is4bueF8eo0SP70GX70aX72ciHz1avxKysX3vno1uemF5Ggz8dWr8dGp8Sm+16mvTtPsjeCSe50ZDAZWr15N8+bNqzy4smbMmMH27dvJzs6mV69ePPLII4wdO5bZs2fzwAMP4HQ6GT16NE2aNPG+M+GGo9aqCCnuPHA+a5Gd/CwL+ZkW8jIt7uX8TAtpZ/KxFJbTW8ukxuSvw+SvxeSvwxhQumwK0GHw1WDw1aLRXb3mHZPGhMnfRH3/+hfdzua0kWXJkqf0NmeSacm84P54znEyzZkVJiUAX40vAfoAdyLy0/rhr/PHT+eHv7b03l8n3/y0flflGqSytGqluyv2pbA5XORZ5KSTV5x8zl/OtzjItzjc2yVmF8llsx3reaM6sDH1gtdQKxXupFNyM7nvVRi1petMOhUmbZllnRqjVl5nKL7Xa67fxFVhoikoKGDJkiWkpqbSt29funfvzpIlS/j0009p1qxZtV+b8tZbb5W7vnfv3vTu3bvcxwShMnRGDTqjhpA65f9I2iwO8rMsFGRbKcq1UphjozDXSmGOlaI8G9kp2RTl2nCVcwJCpVZi8NWg99Fg9NWi99Vg8NG6E1FGtgV/dQ46kxq9SYPeqEGlubIhc7QqrXv+IG8cLgc51hxyLDlkW7PJthTfrJ73qUWpHMs+Rp4tjwJ7wUX3aVAa8NsvJx0fjY98r/XBV1N8r/V1L5s0JkwaE0aNER+NXDaqjRjUl3cNlfs9UCvdF8xeDpvDRb5FTkZ7Dx0jNKoOBRYHhTYHBRYH+Vb5vsDqWc4uspGYXUSh1UmhzUGh1VHheanzKRRg1KgwaEsTlVGrwqhVodeoLlg2FG9r0JSuN5Ss16jQa5Qe6/QaVY11Ua8w0TzxxBP4+/vTvn17li5dygcffIAkSbz33nvX3YkxQbgYrV5dej6oApJLwlJoL05ANsz5Nsz5dswFxcsFdsz5drJTizAX2HFYS5t2/lmV7bEvtVaJzqhBb1IX32vQmdRoDWp0Bs/70mUVOoMGrUGF8hLGlVMr1e7zOpVld9nJt+WTa80lz5ZHrjXXvZxnzeN0ymm0vloKbAXk2/LJtGRyJu8MBfYC8mx57vHpLkapUGJSywmoJPkYNUY5CWkM7mTkXle8bFAbPG56lR6DpvhebUCv1ldq7DutWkmwj3z9kDlER4tGlX9/ypIkCYvd5U46JQmowOrAbHNSZHNSZHPI91YHhWXWFVrl+wKrg/R8K2a7/JjF5qTI7rxg+KLK0KqU+Bk0PH9LCNX5K15hoklMTOQ//5EnDho7diw9evRg06ZN6KpzBj9BqCUUSgUGXy0GXy0hdbxvb7c5MefbOPTPMaLC62AptGMtcsj3ZZeLHOSkFcnrzA4cNu/Xhak1SjR6FRq9Gq1ehUanQqtXo9Gp0OhVaHXq4sdVaHUq1DoVGm3pvUanQq1VotGp0eiUqHUqj0FRNUqN+/xOeS7Wo0mSJKxOKwV2OQkV2YsotBfKN0chhbbie3shRfYiCuwF8rKjCLPdTGpRqnu5yFFEkaMIl3Rp18rpVXr06uJb8bJOpfNcLvNYQU4BUbYo9Go9WpUWveq8+/PWa1VadCqdvKzUotNoMWgvv3ZV0ftod0pysrKXJi2rw4nZ5sJid2IuvlmKb2abC7PdKU97YfSe7K+mChONusxkQyqVioiICJFkBOEq0WhVaIIN+IVriGlR/g92eZxOF3azE6vZga34Zj3v3mZxYrcU31vl5aI8G3arE5vFgb14/aVQqhSotXICUmtVqDXyvaakrFWi1sj3efl55Bw+gVqrRKVRyttqVO7lknu9JggfTQhKtQK1QYlKrUKlUaBSy9solQqvzWclicvsKE489iIsDgsWpwWzw+y+WRwWj/siRxFWpxWrw4rZacbqsGJxWsgrysPitGBxWNz7tTgsSElXdhGqRqkpTT7FCUir0qJRakrXlVl//uMapQaNSoNWWbqsUWo8H1dq0Kg1aLQajCXlMtuVlPUqPQknEq7oeC5VhYnm8OHDdOjQASj+MK1WOnTo4B56+++//662IAVBkKlUSlQ+SvQ+V9YjTHJJ2G1ywnHYnNitLnnZ6jxvfdl7Fw67C4eteNkmb1uUZyuz3onN6uDcP2dxOa/sx1mhwJ10VGolSnVxEip7K05MSlWZskqNUu2HSuWPj1qJv0qBUq1EpVYUb1fmXq9EqVKgUsn3ypLHVPK9UqXg9JmT1G9cH4dkx44dB3bs2LBjk/+5rNgkKzaXDZvThtVpxea0YXOVLrvXnfd4yb3daSfXnuteZ3fZPR6zuWyVanKsDKVCyQvNX6BFNTaeVZhorrcrYQVBKKVQKtDq1Wj1V3+a5JKmM5dTTkxOhwuHzYXTXly2u3DYne5lp6P4VrJsl3A6nDgdksc2rpLtHFLpcxwu7FaHx+Mup+R575DK7ahxKbaT6XUbpVKFUmVEoTLJSUupQK1SolUq8FMp5HUqBQplcRJTli3L25e3rFAWlzWAAiSFq/gm4VI4kRQuXAoXLly4FE5cuIrXOXHilO8lp7us1EI9fcwVvR+XqmYn4xYE4bqlVCnRXsGEd1eT5JLkxOOUE4/T4XIvu9c75WVXSZIqXnf2TAJRkVGljztdOMssSy7JXZZK1rvkx1wueZ3TKckxuDyfV7Kd0172eZI7XpdTQpI8712u0n1JTomLzyimQP6Z9/ypN49SQtsqfMPPIxKNIAjXPYVSgUqpuKyu41ZdBk1beO8qXlMkqUzicVGaiMomKVfpskqt5Fz66WqNUSQaQRCEWkyhUKBQKbiUCWPPpVddPOW5Nuq1giAIwnVLJBpBEAShSolEIwiCIFQpkWgEQRCEKiUSjSAIglClRKIRBEEQqpRINIIgCEKVUkjSxa8rvV5dzrzXgiAIAnTs2PGStr9hE40gCIJQPUTTmSAIglClRKIRBEEQqpQY6wzYsmULL7/8Mi6Xi7FjxzJp0qSaDumKxcXFYTKZUCqVqFQqli1bVtMhXbJZs2axadMmgoODWbVqFQA5OTk89thjnDt3jujoaBYsWIC/v38NR1o55R3PwoULWbp0KUFB8uRnM2bMoHfv3jUZZqUlJyfz5JNPkpmZiUKh4LbbbmPixIm1+jOq6Jhq6+dktVq56667sNlsOJ1OBg4cyLRp00hISGDGjBnk5OTQqlUrXn/9dbRabdUFIt3gHA6H1LdvX+ns2bOS1WqVhg0bJh07dqymw7piffr0kTIzM2s6jCuyfft2af/+/dKQIUPc61577TXpww8/lCRJkj788EPp9ddfr6nwLll5x/Puu+9Kn3zySQ1GdflSU1Ol/fv3S5IkSfn5+dKAAQOkY8eO1erPqKJjqq2fk8vlkgoKCiRJkiSbzSaNGTNG2r17tzRt2jRp1apVkiRJ0nPPPSctWbKkSuO44ZvO9u3bR7169YiJiUGr1TJkyBA2bNhQ02EJQOfOnS/4S3jDhg2MHDkSgJEjR7J+/foaiOzylHc8tVlYWBitWrUCwMfHh4YNG5KamlqrP6OKjqm2UigUmEwmABwOBw6HA4VCwV9//cXAgQMBGDVqVJX/5t3wiSY1NZWIiNK5JsLDw2v1F6us+++/n/j4eL799tuaDuWqyczMJCwsDIDQ0FAyM73PfHitW7JkCcOGDWPWrFnk5ubWdDiXJTExkUOHDtGuXbvr5jMqe0xQez8np9PJiBEj6N69O927dycmJgY/Pz/UavnMSURERJX/5t3wieZ69fXXX7N8+XI+/vhjlixZwo4dO2o6pKtOoVCgUChqOowrcscdd/Drr7+ycuVKwsLCePXVV2s6pEtWWFjItGnTePrpp/Hx8fF4rLZ+RucfU23+nFQqFStXrmTz5s3s27ePkydPVnsMN3yiCQ8PJyUlxV1OTU0lPDy8BiO6OkqOITg4mP79+7Nv374ajujqCA4OJi0tDYC0tDT3ydnaKiQkBJVKhVKpZOzYsfzzzz81HdIlsdvtTJs2jWHDhjFgwACg9n9G5R1Tbf+cAPz8/OjatSt79uwhLy8Ph8MBQEpKSpX/5t3wiaZNmzacPn2ahIQEbDYbq1evJi4urqbDuiJFRUUUFBS4l//44w+aNGlSw1FdHXFxcaxYsQKAFStW0Ldv35oN6AqV/CADrF+/vlZ9TpIk8cwzz9CwYUPuvfde9/ra/BlVdEy19XPKysoiLy8PAIvFwtatW2nUqBFdu3bll19+AWD58uVV/psnRgYANm/ezCuvvILT6WT06NE8/PDDNR3SFUlISGDKlCmA3D47dOjQWnlMM2bMYPv27WRnZxMcHMwjjzxCv379mD59OsnJyURFRbFgwQICAgJqOtRKKe94tm/fzuHDhwGIjo5mzpw57vMb17qdO3dy11130bRpU5RK+W/WGTNm0LZt21r7GVV0TKtWraqVn9Phw4eZOXMmTqcTSZK49dZbmTp1KgkJCTz22GPk5ubSokUL5s+fX6Xdm0WiEQRBEKrUDd90JgiCIFQtkWgEQRCEKiUSjSAIglClRKIRBEEQqpRINIIgCEKVEqM3Cze87Oxs7rnnHgAyMjJQKpXuiwy/++67i3b7/Oeff1i5ciXPPvvsRV9j3LhxfPPNN1ct5qqycOFCjEYj999/f02HIlxHRPdmQSijvB9ah8PhHhfqeicSjVAVboz/PYJwiWbOnIlWq+XQoUN06NCBIUOG8PLLL2O1WtHr9bzyyis0bNiQbdu28emnn/Lhhx+ycOFCkpKSSExMJCkpiYkTJzJhwgQAYmNj2b17N9u2bWPRokUEBgZy9OhRWrVqxfz581EoFGzevJl58+ZhNBrp0KEDCQkJfPjhhx5xOZ1O5s+fz/bt27HZbNx1112MGzeObdu28e6772IymThz5gxdu3blhRdeQKlUsmrVKj788EMkSaJ379488cQTgDwP09tvv43T6SQwMJAvvvgCgOPHjzN+/PgLjkEQLpdINIJQgdTUVL755htUKhUFBQUsWbIEtVrN1q1befvtt1m4cOEFzzl16hRffvklBQUFDBo0iDvuuAONRuOxzcGDB1m9ejVhYWHccccd7Nq1izZt2jB79mz+7//+j5iYGGbMmFFuTN9//z2+vr788MMP2Gw2xo0bx8033wzIU16sWbOGqKgoHnjgAdatW0dsbCzz589n2bJl+Pn5cd9997F+/Xo6dOjAc8895369nJycSzoGQbgUItEIQgVuvfVWVCoVAPn5+Tz11FOcOXMGhUKB3W4v9zm9e/dGq9USFBREUFAQmZmZHtNQALRt29a9rnnz5pw7dw6TyURMTAwxMTEADBkyhKVLl16w/z/++IMjR464x6nKz8/nzJkzaDQa2rZt6/H8Xbt2oVar6dKli/uc07Bhw9ixYwdKpZJOnTq5ty87RExljkEQLoVINIJQAYPB4F5+55136Nq1K++99x6JiYkVNieV7TigUqncI+RebBun01npmCRJ4tlnn6Vnz54e67dt23bBcPyXOzx/ZY5BEC6F6N4sCJWQn5/vHkp9+fLlV33/DRo0ICEhgcTERADWrFlT7nY9evTg66+/dteoTp06RVFRESA3nSUkJOByufj555/p2LEjbdu2ZceOHWRlZeF0Olm9ejWdO3emffv27Ny5k4SEBACPpjNBuNpEjUYQKuGBBx5g5syZ/Oc//6F3795Xff96vZ7nn3+eBx54AKPRSOvWrcvdbuzYsZw7d474+HgkSSIwMJD3338fkKe8mDt3rrszQP/+/VEqlTz++ONMnDjR3RmgX79+AMyZM4dHHnkEl8tFcHAwn3322VU/LkEA0b1ZEK4ZhYWFmEwmJEnixRdfpH79+u7re7wp2/tNEK41okYjCNeI7777juXLl2O322nRogW33357TYckCFeFqNEIgiAIVUp0BhAEQRCqlEg0giAIQpUSiUYQBEGoUiLRCIIgCFVKJBpBEAShSolEIwiCIFSp/wdRdTEap2RqKwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for val in learning_rates_linear:\n",
    "    lr = str(val)\n",
    "    plt.plot(epochs_x, histories_tr_li[lr].history['root_mean_squared_error'], label=lr)\n",
    "    plt.plot(epochs_x, histories_tr_li[lr].history['val_root_mean_squared_error'], label=lr, linestyle='dotted')\n",
    "\n",
    "plt.title('Root mean squared error in user rating vs. training epoch')\n",
    "plt.xlabel('Training epoch')\n",
    "plt.ylabel('Root mean squared error in user rating')\n",
    "plt.yscale('log')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "jB1WWJdbK6AW"
   },
   "source": [
    "The best performances for the linear grid search look quite similar to each other, so let's stick with learning rate 0.1 and train the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false
    },
    "id": "AF5eXjeMGZ2b",
    "outputId": "2e2562d1-fbd2-4d16-81f2-29b8a68dc5fa",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 1s 30ms/step - root_mean_squared_error: 2.3640 - loss: 5.1172 - regularization_loss: 1.9729 - total_loss: 7.0902 - val_root_mean_squared_error: 1.1673 - val_loss: 1.3654 - val_regularization_loss: 1.8838 - val_total_loss: 3.2491\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.1214 - loss: 1.2550 - regularization_loss: 1.7940 - total_loss: 3.0491 - val_root_mean_squared_error: 1.1339 - val_loss: 1.2881 - val_regularization_loss: 1.7036 - val_total_loss: 2.9917\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1120 - loss: 1.2346 - regularization_loss: 1.6250 - total_loss: 2.8596 - val_root_mean_squared_error: 1.1319 - val_loss: 1.2833 - val_regularization_loss: 1.5437 - val_total_loss: 2.8270\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.1028 - loss: 1.2141 - regularization_loss: 1.4733 - total_loss: 2.6873 - val_root_mean_squared_error: 1.1299 - val_loss: 1.2788 - val_regularization_loss: 1.4004 - val_total_loss: 2.6792\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.0906 - loss: 1.1871 - regularization_loss: 1.3374 - total_loss: 2.5245 - val_root_mean_squared_error: 1.1274 - val_loss: 1.2730 - val_regularization_loss: 1.2721 - val_total_loss: 2.5451\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.0758 - loss: 1.1549 - regularization_loss: 1.2159 - total_loss: 2.3708 - val_root_mean_squared_error: 1.1238 - val_loss: 1.2650 - val_regularization_loss: 1.1574 - val_total_loss: 2.4224\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.0598 - loss: 1.1209 - regularization_loss: 1.1072 - total_loss: 2.2280 - val_root_mean_squared_error: 1.1191 - val_loss: 1.2541 - val_regularization_loss: 1.0547 - val_total_loss: 2.3088\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.0441 - loss: 1.0879 - regularization_loss: 1.0096 - total_loss: 2.0975 - val_root_mean_squared_error: 1.1130 - val_loss: 1.2404 - val_regularization_loss: 0.9623 - val_total_loss: 2.2027\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 1.0292 - loss: 1.0571 - regularization_loss: 0.9218 - total_loss: 1.9790 - val_root_mean_squared_error: 1.1060 - val_loss: 1.2244 - val_regularization_loss: 0.8791 - val_total_loss: 2.1035\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 17ms/step - root_mean_squared_error: 1.0156 - loss: 1.0295 - regularization_loss: 0.8427 - total_loss: 1.8722 - val_root_mean_squared_error: 1.0984 - val_loss: 1.2074 - val_regularization_loss: 0.8039 - val_total_loss: 2.0114\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 1.0037 - loss: 1.0056 - regularization_loss: 0.7711 - total_loss: 1.7768 - val_root_mean_squared_error: 1.0910 - val_loss: 1.1908 - val_regularization_loss: 0.7358 - val_total_loss: 1.9266\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 17ms/step - root_mean_squared_error: 0.9937 - loss: 0.9858 - regularization_loss: 0.7062 - total_loss: 1.6921 - val_root_mean_squared_error: 1.0842 - val_loss: 1.1755 - val_regularization_loss: 0.6740 - val_total_loss: 1.8495\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 0.9857 - loss: 0.9699 - regularization_loss: 0.6473 - total_loss: 1.6172 - val_root_mean_squared_error: 1.0782 - val_loss: 1.1623 - val_regularization_loss: 0.6177 - val_total_loss: 1.7799\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 0.9792 - loss: 0.9573 - regularization_loss: 0.5936 - total_loss: 1.5508 - val_root_mean_squared_error: 1.0732 - val_loss: 1.1511 - val_regularization_loss: 0.5664 - val_total_loss: 1.7176\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 0.9738 - loss: 0.9467 - regularization_loss: 0.5447 - total_loss: 1.4913 - val_root_mean_squared_error: 1.0690 - val_loss: 1.1418 - val_regularization_loss: 0.5198 - val_total_loss: 1.6616\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 0.9689 - loss: 0.9371 - regularization_loss: 0.5002 - total_loss: 1.4372 - val_root_mean_squared_error: 1.0654 - val_loss: 1.1339 - val_regularization_loss: 0.4774 - val_total_loss: 1.6112\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 17ms/step - root_mean_squared_error: 0.9642 - loss: 0.9280 - regularization_loss: 0.4597 - total_loss: 1.3877 - val_root_mean_squared_error: 1.0623 - val_loss: 1.1270 - val_regularization_loss: 0.4389 - val_total_loss: 1.5659\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 0.9599 - loss: 0.9197 - regularization_loss: 0.4230 - total_loss: 1.3426 - val_root_mean_squared_error: 1.0596 - val_loss: 1.1211 - val_regularization_loss: 0.4040 - val_total_loss: 1.5251\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 0.9559 - loss: 0.9122 - regularization_loss: 0.3896 - total_loss: 1.3018 - val_root_mean_squared_error: 1.0573 - val_loss: 1.1160 - val_regularization_loss: 0.3723 - val_total_loss: 1.4883\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 0.9525 - loss: 0.9057 - regularization_loss: 0.3593 - total_loss: 1.2650 - val_root_mean_squared_error: 1.0553 - val_loss: 1.1115 - val_regularization_loss: 0.3435 - val_total_loss: 1.4550\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 0.9495 - loss: 0.8999 - regularization_loss: 0.3318 - total_loss: 1.2317 - val_root_mean_squared_error: 1.0535 - val_loss: 1.1076 - val_regularization_loss: 0.3174 - val_total_loss: 1.4250\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 0.9468 - loss: 0.8949 - regularization_loss: 0.3068 - total_loss: 1.2017 - val_root_mean_squared_error: 1.0519 - val_loss: 1.1042 - val_regularization_loss: 0.2937 - val_total_loss: 1.3979\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 0.9445 - loss: 0.8904 - regularization_loss: 0.2842 - total_loss: 1.1746 - val_root_mean_squared_error: 1.0505 - val_loss: 1.1011 - val_regularization_loss: 0.2721 - val_total_loss: 1.3733\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 0.9423 - loss: 0.8865 - regularization_loss: 0.2636 - total_loss: 1.1501 - val_root_mean_squared_error: 1.0493 - val_loss: 1.0984 - val_regularization_loss: 0.2526 - val_total_loss: 1.3511\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 0.9405 - loss: 0.8829 - regularization_loss: 0.2450 - total_loss: 1.1279 - val_root_mean_squared_error: 1.0482 - val_loss: 1.0960 - val_regularization_loss: 0.2349 - val_total_loss: 1.3309\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 0.9387 - loss: 0.8797 - regularization_loss: 0.2280 - total_loss: 1.1077 - val_root_mean_squared_error: 1.0472 - val_loss: 1.0939 - val_regularization_loss: 0.2188 - val_total_loss: 1.3127\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 0.9372 - loss: 0.8768 - regularization_loss: 0.2126 - total_loss: 1.0894 - val_root_mean_squared_error: 1.0464 - val_loss: 1.0920 - val_regularization_loss: 0.2042 - val_total_loss: 1.2961\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 0.9358 - loss: 0.8741 - regularization_loss: 0.1987 - total_loss: 1.0728 - val_root_mean_squared_error: 1.0456 - val_loss: 1.0902 - val_regularization_loss: 0.1909 - val_total_loss: 1.2811\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 0.9345 - loss: 0.8717 - regularization_loss: 0.1860 - total_loss: 1.0577 - val_root_mean_squared_error: 1.0449 - val_loss: 1.0887 - val_regularization_loss: 0.1788 - val_total_loss: 1.2675\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 0.9333 - loss: 0.8695 - regularization_loss: 0.1744 - total_loss: 1.0439 - val_root_mean_squared_error: 1.0442 - val_loss: 1.0872 - val_regularization_loss: 0.1678 - val_total_loss: 1.2551\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 0.9322 - loss: 0.8675 - regularization_loss: 0.1639 - total_loss: 1.0314 - val_root_mean_squared_error: 1.0437 - val_loss: 1.0860 - val_regularization_loss: 0.1579 - val_total_loss: 1.2438\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 0.9312 - loss: 0.8656 - regularization_loss: 0.1544 - total_loss: 1.0200 - val_root_mean_squared_error: 1.0431 - val_loss: 1.0848 - val_regularization_loss: 0.1488 - val_total_loss: 1.2336\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 19ms/step - root_mean_squared_error: 0.9303 - loss: 0.8639 - regularization_loss: 0.1457 - total_loss: 1.0096 - val_root_mean_squared_error: 1.0427 - val_loss: 1.0837 - val_regularization_loss: 0.1406 - val_total_loss: 1.2243\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 18ms/step - root_mean_squared_error: 0.9294 - loss: 0.8623 - regularization_loss: 0.1378 - total_loss: 1.0001 - val_root_mean_squared_error: 1.0422 - val_loss: 1.0828 - val_regularization_loss: 0.1330 - val_total_loss: 1.2158\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 0.9286 - loss: 0.8608 - regularization_loss: 0.1307 - total_loss: 0.9915 - val_root_mean_squared_error: 1.0418 - val_loss: 1.0819 - val_regularization_loss: 0.1262 - val_total_loss: 1.2081\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 0.9279 - loss: 0.8594 - regularization_loss: 0.1241 - total_loss: 0.9836 - val_root_mean_squared_error: 1.0414 - val_loss: 1.0810 - val_regularization_loss: 0.1200 - val_total_loss: 1.2010\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 0.9272 - loss: 0.8582 - regularization_loss: 0.1181 - total_loss: 0.9763 - val_root_mean_squared_error: 1.0411 - val_loss: 1.0803 - val_regularization_loss: 0.1143 - val_total_loss: 1.1946\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 0.9266 - loss: 0.8570 - regularization_loss: 0.1127 - total_loss: 0.9697 - val_root_mean_squared_error: 1.0408 - val_loss: 1.0796 - val_regularization_loss: 0.1091 - val_total_loss: 1.1887\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 0.9260 - loss: 0.8559 - regularization_loss: 0.1078 - total_loss: 0.9636 - val_root_mean_squared_error: 1.0405 - val_loss: 1.0789 - val_regularization_loss: 0.1044 - val_total_loss: 1.1833\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 0.9254 - loss: 0.8549 - regularization_loss: 0.1032 - total_loss: 0.9581 - val_root_mean_squared_error: 1.0402 - val_loss: 1.0783 - val_regularization_loss: 0.1001 - val_total_loss: 1.1784\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 0.9249 - loss: 0.8539 - regularization_loss: 0.0991 - total_loss: 0.9530 - val_root_mean_squared_error: 1.0400 - val_loss: 1.0777 - val_regularization_loss: 0.0962 - val_total_loss: 1.1739\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 0.9244 - loss: 0.8530 - regularization_loss: 0.0953 - total_loss: 0.9483 - val_root_mean_squared_error: 1.0397 - val_loss: 1.0772 - val_regularization_loss: 0.0926 - val_total_loss: 1.1698\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 40ms/step - root_mean_squared_error: 0.9240 - loss: 0.8521 - regularization_loss: 0.0919 - total_loss: 0.9440 - val_root_mean_squared_error: 1.0395 - val_loss: 1.0767 - val_regularization_loss: 0.0893 - val_total_loss: 1.1660\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 17ms/step - root_mean_squared_error: 0.9235 - loss: 0.8513 - regularization_loss: 0.0887 - total_loss: 0.9400 - val_root_mean_squared_error: 1.0393 - val_loss: 1.0763 - val_regularization_loss: 0.0863 - val_total_loss: 1.1625\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 17ms/step - root_mean_squared_error: 0.9231 - loss: 0.8506 - regularization_loss: 0.0858 - total_loss: 0.9364 - val_root_mean_squared_error: 1.0391 - val_loss: 1.0759 - val_regularization_loss: 0.0835 - val_total_loss: 1.1594\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 15ms/step - root_mean_squared_error: 0.9227 - loss: 0.8499 - regularization_loss: 0.0832 - total_loss: 0.9330 - val_root_mean_squared_error: 1.0390 - val_loss: 1.0755 - val_regularization_loss: 0.0810 - val_total_loss: 1.1564\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 17ms/step - root_mean_squared_error: 0.9223 - loss: 0.8492 - regularization_loss: 0.0807 - total_loss: 0.9299 - val_root_mean_squared_error: 1.0388 - val_loss: 1.0751 - val_regularization_loss: 0.0786 - val_total_loss: 1.1537\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 0.9220 - loss: 0.8485 - regularization_loss: 0.0785 - total_loss: 0.9270 - val_root_mean_squared_error: 1.0386 - val_loss: 1.0747 - val_regularization_loss: 0.0765 - val_total_loss: 1.1512\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 16ms/step - root_mean_squared_error: 0.9217 - loss: 0.8479 - regularization_loss: 0.0764 - total_loss: 0.9243 - val_root_mean_squared_error: 1.0385 - val_loss: 1.0744 - val_regularization_loss: 0.0745 - val_total_loss: 1.1489\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 18ms/step - root_mean_squared_error: 0.9213 - loss: 0.8473 - regularization_loss: 0.0745 - total_loss: 0.9219 - val_root_mean_squared_error: 1.0383 - val_loss: 1.0741 - val_regularization_loss: 0.0727 - val_total_loss: 1.1468\n"
     ]
    }
   ],
   "source": [
    "model_tr = MovielensModelTunedRanking()\n",
    "model_tr.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))\n",
    "history_tr = model_tr.fit(cached_train, epochs=50, validation_data=cached_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false
    },
    "id": "3GrSMwIYNAl7",
    "outputId": "bdb1cc54-d0ba-4aad-d4f2-4bd8fdb433f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error in user rating from training: 0.92\n",
      "Root mean squared error in user rating from validation: 1.04\n"
     ]
    }
   ],
   "source": [
    "rmse_tr = history_tr.history['root_mean_squared_error'][-1]\n",
    "print(f'Root mean squared error in user rating from training: {rmse_tr:.2f}')\n",
    "\n",
    "val_rmse_tr = history_tr.history['val_root_mean_squared_error'][-1]\n",
    "print(f'Root mean squared error in user rating from validation: {val_rmse_tr:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "WG0EsFs3NRx1"
   },
   "outputs": [],
   "source": [
    "num_validation_runs = len(history_tr.history['root_mean_squared_error'])\n",
    "validation_freq = 1\n",
    "epochs_x = [(x + 1) * validation_freq for x in range(num_validation_runs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 308
    },
    "gradient": {
     "editing": false
    },
    "id": "Wmi3EAi3NYrM",
    "outputId": "0825f5e6-f49a-4513-abad-b493e5da70d5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f5a48714c50>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs_x, history_tr.history['root_mean_squared_error'], label='Training')\n",
    "plt.plot(epochs_x, history_tr.history['val_root_mean_squared_error'], label='Validation')\n",
    "plt.title('Root mean squared error in user rating vs. training epoch')\n",
    "plt.xlabel('Training epoch')\n",
    "plt.ylabel('Root mean squared error in user rating')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "QdiaiJ38IdwD"
   },
   "source": [
    "As mentioned, this is a very basic hyperparameter tuning. Some obvious improvements to this use of a grid for tuning include:\n",
    "\n",
    "- Use a larger grid of learning rates (log + linear fine-tuning)\n",
    "- More epochs in model.fit(): 100s, not 30 or 50\n",
    "- Use `keras.tuner` and/or TensorFlow callbacks to retain the best model, and retrain it with both the training and validation data once found\n",
    "- Use callbacks to stop training when the improvement rate drops below a threshold (early stopping), instead of training for a fixed number of epochs\n",
    "- Tune layer size or number of layers, as in [the TFRS multitask tutorial](https://www.tensorflow.org/recommenders/examples/multitask)\n",
    "- Tune the L2 regularization factor, currently set to the default 0.01\n",
    "- The [regularizer](https://www.tensorflow.org/tutorials/keras/overfit_and_underfit#strategies_to_prevent_overfitting) can be dropout as well as L2 (aka. weight decay), or it can be both\n",
    "- Tune embedding size (vary the number of dimensions from 32 and the number of  categories that can be fit: more is better unless it causes overfitting or too-slow training)\n",
    "- Optimizers other than Adagrad, e.g., SGD, RMSprop, Adam, Nadam\n",
    "- Activation functions other than ReLU, e.g., SELU with LecunNormal weight initialization\n",
    "- Keras tuner or [TensorBoard HParams](https://www.tensorflow.org/tensorboard/hyperparameter_tuning_with_hparams) for multi-parameter search, or smart search. The I/O would need to match the recommender model, but often smart search will find better hyperparameter sets then manual tuning, even by experts\n",
    "- Add [other metrics](https://www.tensorflow.org/guide/effective_tf2#tfmetrics_aggregates_data_and_tfsummary_logs_them) besides RMSE to the plotted tuning history\n",
    "\n",
    "One thing that is clear from the above code, however, is that managing and plotting much more extensive tuning from a single notebook can quickly become unwieldy, error-prone, and hard to reproduce due to the combinatorial explosion of parameters and their differing types and amounts. So the desirability of eking out further model performance needs to be balanced against this.\n",
    "\n",
    "There are various further improvements beyond tuning that should therefore also be considered - see the appendix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "Q6X66dBfK-5o"
   },
   "source": [
    "As in previous sections, we can see a summary of the final model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false
    },
    "id": "mfS8RD5aQK8M",
    "outputId": "756dc9ae-d628-445b-b222-57f7e96da255"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"movielens_model_tuned_ranking_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_24 (Sequential)   (None, 32)                53280     \n",
      "_________________________________________________________________\n",
      "sequential_25 (Sequential)   (None, 32)                30208     \n",
      "_________________________________________________________________\n",
      "sequential_26 (Sequential)   (None, 1)                 33153     \n",
      "_________________________________________________________________\n",
      "ranking_8 (Ranking)          multiple                  2         \n",
      "=================================================================\n",
      "Total params: 116,643\n",
      "Trainable params: 116,641\n",
      "Non-trainable params: 2\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_tr.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "0YzUHtmUWcKB"
   },
   "source": [
    "As with the basic model, the performance of the model on the unseen testing data is similar to the validation performance, at about RMSE ~ 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false
    },
    "id": "9hw7_atTIUul",
    "outputId": "f992c83a-ef5d-4215-a5dc-58210995158c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - root_mean_squared_error: 1.0260 - loss: 1.0544 - regularization_loss: 0.0727 - total_loss: 1.1271\n"
     ]
    }
   ],
   "source": [
    "eval_tr = model_tr.evaluate(cached_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false
    },
    "id": "8M151XaeN3PU",
    "outputId": "71b14698-3b31-4c8a-9778-0ec80dbed269"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error in user rating from evaluation: 1.03\n"
     ]
    }
   ],
   "source": [
    "rmse_eval_tr = eval_tr['root_mean_squared_error']\n",
    "print(f'Root mean squared error in user rating from evaluation: {rmse_eval_tr:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "5m5kalp0IdiT"
   },
   "source": [
    "And as above, new data can now be sent to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false
    },
    "id": "NFlR-80oPCwE",
    "outputId": "06095776-9182-40dc-f069-a45140fc8f1b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.02849846,  0.0176121 , -0.00894195, ..., -0.04526925,\n",
       "         -0.01119535,  0.00639677],\n",
       "        [-0.04739385,  0.03865167,  0.02980467, ...,  0.0179348 ,\n",
       "          0.03060083, -0.02724645],\n",
       "        [ 0.01094703, -0.01979085, -0.01319928, ..., -0.00660934,\n",
       "         -0.00511613,  0.00533506],\n",
       "        ...,\n",
       "        [-0.0411031 ,  0.00898093, -0.04372801, ..., -0.03874222,\n",
       "         -0.02124953, -0.02406938],\n",
       "        [-0.00822344, -0.02573305,  0.04053061, ...,  0.01533296,\n",
       "          0.04250797, -0.0078328 ],\n",
       "        [-0.0378443 ,  0.022497  ,  0.00351272, ..., -0.01329498,\n",
       "         -0.02220261, -0.01760115]], dtype=float32),\n",
       " array([[ 0.02721014,  0.02484442,  0.0145153 , ..., -0.04539186,\n",
       "          0.07511394,  0.06882158],\n",
       "        [ 0.06826174,  0.00559263, -0.01384696, ..., -0.04238057,\n",
       "         -0.00072053,  0.0022185 ],\n",
       "        [ 0.05204289,  0.04300666,  0.01135077, ..., -0.01102841,\n",
       "          0.04134514,  0.03032939],\n",
       "        ...,\n",
       "        [ 0.03491384,  0.00594732,  0.00053158, ..., -0.03236166,\n",
       "          0.0206691 , -0.01033043],\n",
       "        [ 0.0011001 ,  0.00900595, -0.03581786, ...,  0.01399285,\n",
       "         -0.02616364, -0.03695054],\n",
       "        [ 0.06225461, -0.01253602,  0.01089026, ...,  0.02603948,\n",
       "         -0.00786771,  0.07225379]], dtype=float32),\n",
       " array([[3.9811127],\n",
       "        [3.874377 ],\n",
       "        [3.8659406],\n",
       "        ...,\n",
       "        [3.5851712],\n",
       "        [2.9206936],\n",
       "        [3.7663796]], dtype=float32))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Again returns the embeddings and predicted ratings\n",
    "model_tr.predict(cached_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "### 4.3: Model as Gradient Workflow\n",
    "\n",
    "**This section requires the user to input their settings - see below.**  \n",
    "**Gradient Workflows is still a maturing product and it is expected that all of the setup steps currently given here will disappear in time.**\n",
    "\n",
    "Having completed creating and training the models in our notebook here, in principle we have a model that can be deployed into production.\n",
    "\n",
    "What can be seen from the above, however, is that even though we only trained 3 models - the wide grid, narrow grid, and final, already the notebook is quite long, and there are quite a few loops and things to keep track of. Adding further models, data preparation, feature engineering, etc., will quickly result in this getting out of hand, with too many things to keep track of. Considering that a typical real project might have 100s of models, when we get to that scale, a more rigorous way of working is indicated.\n",
    "\n",
    "There are good reasons to start with a notebook, which is why we have done so here, but when a project gets large, we can switch from Gradient's Notebook way of working to its Workflows. This does, however, require more setup and structure than a notebook.\n",
    "\n",
    "This section shows an example of a Workflow, where we put the code we need into a script, and instead of training the model from the notebook, we run that. Our script is `workflow_train_model.py`, and we show training the final model from section 4.2 above. The code is a subset of the notebook, with a few minor changes for lines that work in cells but not a .py (or vice versa), for example, `!pip install -q tensorflow-recommenders==0.4.0` becomes `subprocess.run('pip install -q tensorflow-recommenders==0.4.0', shell=True, check=True, stdout=subprocess.PIPE, universal_newlines=True)`. Another example would be `%` or `%%` line and cell magics.\n",
    "\n",
    "Since they run via script and parameter files (YAML), Workflows can be used without requiring a notebook at all. Here, to preserve continuity and keep the project within one end-to-end setting, we call the Workflow from the notebook. This involves setting up access to it and calling the YAML file with the settings, which in turn calls `workflow_train_model.py`.\n",
    "\n",
    "Aside from the advantages or organization, reproducibility, etc., Gradient also allows the setup to be straightforwardly extended to using GPU instead of CPU, by choosing a GPU instance, and using multiple machines instead of a single machine, by using multinode instead of single node. Since Gradient can use the Paperspace infrastructure, the user does not need to set up their own GPUs or be an expert in distributed computing to access this power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "#### Workflow setup\n",
    "\n",
    "To run the Workflow requires the user to supply the following settings:\n",
    "\n",
    " - `api_key` = API key to access Gradient. This is part of setting up one's user account\n",
    " - `workflow_train_id` = Currently Workflows need to be created in the GUI or CLI\n",
    " - `workflow_deploy_id` = Similarly for deployment Workflow in section 5\n",
    " \n",
    "To obtain these, follow the steps under *Additional requirements to run Gradient Workflows and model deployment (sections 4.3+)* near the start of the notebook.\n",
    "\n",
    "If you are using a Gradient private cluster, you should also specify `cluster_id`. If cluster ID is not specified, the Gradient public cluster will be used.\n",
    "\n",
    "When all is set up, add your settings to the next cell, then run it.\n",
    "\n",
    "They will look similar to this:\n",
    "\n",
    "`cluster_id = 'cdefghijk'` (optional)  \n",
    "`workflow_id_train = '6789abcd-01ef-23gh-45ij-678901klmnop'`  \n",
    "`workflow_id_deploy = '6789abcd-01ef-23gh-45ij-678901klmnoq'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [],
   "source": [
    "workflow_id_train = '6c325f57-9979-402e-8560-fe09951990cc' # Created workflows in GUI/CLI\n",
    "workflow_id_deploy = '1f116f34-388e-4e47-8f47-570cd2218795'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "The API key could also be given here as a string, but since it is a credential that allows access to the system for you as a user, it is better to not do so. Gradient will in future support accessing its Secrets from the Notebook via the SDK. For now, we can read the key, supplied by the user, from a file. Best is to create key.txt with the key in it, upload it here, then delete when done. The API key looks like `0123456789abcdef0123456789abcd`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [],
   "source": [
    "file = './key.txt'\n",
    "\n",
    "with open(file) as f:\n",
    "    out = f.readlines()\n",
    "\n",
    "api_key = ''.join(out).strip('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "#### Access Gradient\n",
    "Aside from its graphical interface (GUI), Gradient has command line and SDK interfaces that allow interaction to achieve most of the same things that can be done with the GUI. The lines here set up access to the SDK.\n",
    "\n",
    "Here, we install the Gradient SDK using pip. If you are running the notebook on your own machine rather than the Gradient Notebook, then this will also work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/secretstorage/dhcrypto.py:15: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/usr/lib/python3/dist-packages/secretstorage/util.py:19: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Requirement already satisfied: gradient in /usr/local/lib/python3.6/dist-packages (1.7.1)\n",
      "Requirement already satisfied: requests[security] in /usr/local/lib/python3.6/dist-packages (from gradient) (2.25.1)\n",
      "Requirement already satisfied: halo in /usr/local/lib/python3.6/dist-packages (from gradient) (0.0.31)\n",
      "Requirement already satisfied: progressbar2 in /usr/local/lib/python3.6/dist-packages (from gradient) (3.53.1)\n",
      "Requirement already satisfied: marshmallow<3.0 in /usr/local/lib/python3.6/dist-packages (from gradient) (2.21.0)\n",
      "Requirement already satisfied: click-help-colors in /usr/local/lib/python3.6/dist-packages (from gradient) (0.9.1)\n",
      "Requirement already satisfied: attrs<=19 in /usr/local/lib/python3.6/dist-packages (from gradient) (18.2.0)\n",
      "Requirement already satisfied: gradient-utils>=0.1.2 in /usr/local/lib/python3.6/dist-packages (from gradient) (0.3.2)\n",
      "Requirement already satisfied: click-completion in /usr/local/lib/python3.6/dist-packages (from gradient) (0.5.2)\n",
      "Requirement already satisfied: click==7.1.2 in /usr/local/lib/python3.6/dist-packages (from gradient) (7.1.2)\n",
      "Requirement already satisfied: python-dateutil==2.* in /usr/local/lib/python3.6/dist-packages (from gradient) (2.8.1)\n",
      "Requirement already satisfied: terminaltables in /usr/local/lib/python3.6/dist-packages (from gradient) (3.1.0)\n",
      "Requirement already satisfied: websocket-client==0.57.* in /usr/local/lib/python3.6/dist-packages (from gradient) (0.57.0)\n",
      "Requirement already satisfied: click-didyoumean in /usr/local/lib/python3.6/dist-packages (from gradient) (0.0.3)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gradient) (1.15.0)\n",
      "Requirement already satisfied: colorama==0.4.3 in /usr/local/lib/python3.6/dist-packages (from gradient) (0.4.3)\n",
      "Requirement already satisfied: PyYAML==5.* in /usr/local/lib/python3.6/dist-packages (from gradient) (5.4.1)\n",
      "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.6/dist-packages (from gradient) (0.9.1)\n",
      "Requirement already satisfied: hyperopt==0.1.2 in /usr/local/lib/python3.6/dist-packages (from gradient-utils>=0.1.2->gradient) (0.1.2)\n",
      "Collecting numpy==1.18.5\n",
      "  Using cached numpy-1.18.5-cp36-cp36m-manylinux1_x86_64.whl (20.1 MB)\n",
      "Requirement already satisfied: pymongo<4.0.0,>=3.11.0 in /usr/local/lib/python3.6/dist-packages (from gradient-utils>=0.1.2->gradient) (3.12.0)\n",
      "Requirement already satisfied: wheel<0.36.0,>=0.35.1 in /usr/local/lib/python3.6/dist-packages (from gradient-utils>=0.1.2->gradient) (0.35.1)\n",
      "Requirement already satisfied: prometheus-client<0.10,>=0.8 in /usr/local/lib/python3.6/dist-packages (from gradient-utils>=0.1.2->gradient) (0.9.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt==0.1.2->gradient-utils>=0.1.2->gradient) (2.5.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from hyperopt==0.1.2->gradient-utils>=0.1.2->gradient) (1.5.4)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from hyperopt==0.1.2->gradient-utils>=0.1.2->gradient) (4.62.0)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt==0.1.2->gradient-utils>=0.1.2->gradient) (0.18.2)\n",
      "Requirement already satisfied: shellingham in /usr/local/lib/python3.6/dist-packages (from click-completion->gradient) (1.4.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from click-completion->gradient) (2.11.2)\n",
      "Requirement already satisfied: log-symbols>=0.0.14 in /usr/local/lib/python3.6/dist-packages (from halo->gradient) (0.0.14)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from halo->gradient) (1.1.0)\n",
      "Requirement already satisfied: spinners>=0.0.24 in /usr/local/lib/python3.6/dist-packages (from halo->gradient) (0.0.24)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->click-completion->gradient) (1.1.1)\n",
      "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt==0.1.2->gradient-utils>=0.1.2->gradient) (4.4.2)\n",
      "Requirement already satisfied: python-utils>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from progressbar2->gradient) (2.5.6)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[security]->gradient) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[security]->gradient) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/lib/python3/dist-packages (from requests[security]->gradient) (2.6)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[security]->gradient) (1.26.2)\n",
      "Requirement already satisfied: cryptography>=1.3.4 in /usr/local/lib/python3.6/dist-packages (from requests[security]->gradient) (3.4.7)\n",
      "Requirement already satisfied: pyOpenSSL>=0.14 in /usr/local/lib/python3.6/dist-packages (from requests[security]->gradient) (20.0.1)\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.6/dist-packages (from cryptography>=1.3.4->requests[security]->gradient) (1.14.4)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.12->cryptography>=1.3.4->requests[security]->gradient) (2.20)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.5\n",
      "    Uninstalling numpy-1.19.5:\n",
      "      Successfully uninstalled numpy-1.19.5\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.4.0 requires numpy~=1.19.2, but you have numpy 1.18.5 which is incompatible.\n",
      "tensorflow-gpu 2.4.1 requires numpy~=1.19.2, but you have numpy 1.18.5 which is incompatible.\u001b[0m\n",
      "Successfully installed numpy-1.18.5\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U gradient # -U means upgrade any existing installed packages that this would have installed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "Functionality such as Workflows and deployments are under `SdkClient`. Aside from the ones shown, there are about [20 more](https://paperspace.github.io/gradient-cli/gradient.api_sdk.clients.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [],
   "source": [
    "# Access Gradient from the SDK, i.e., this notebook\n",
    "from gradient import sdk_client\n",
    "\n",
    "# Enable SDK to access YAML file\n",
    "import yaml\n",
    "\n",
    "# SDK clients\n",
    "# All can be accessed from client, or shorthanded for convenience as here\n",
    "client = sdk_client.SdkClient(api_key)\n",
    "deployments_client = sdk_client.DeploymentsClient(api_key)\n",
    "workflows_client  = sdk_client.WorkflowsClient(api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "When running workflows in Gradient, they can be associated with a user's project, which here we created above as part of the currently required manual setup steps.\n",
    "\n",
    "In other notebooks, you may want to create a project from the notebook, which can be done with\n",
    "\n",
    "`project_id = client.projects.create('My project')`\n",
    "\n",
    "With a project ID, you can also see information about project contents, such as the workflows\n",
    "\n",
    "`workflows = workflows_client.list(project_id=project_id)\n",
    "print(workflows)`\n",
    "\n",
    "After a project is created, it will also be visible under the Projects tab in the GUI, and to the command line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "#### Run the Workflow\n",
    "\n",
    "Now we are setup, we can run the Workflow by referring to its YAML file, `workflow-train-model.yaml`. Use of YAML is part of what makes this production-grade, as opposed to just for experimenting.\n",
    "\n",
    "The YAML file contains two jobs: `CloneRepo` and `RecommenderTrain`. The first one accesses the GitHub repository to obtain the training script, and the second runs the model training. For more details about YAML, see part 4 of the blog series, and the [Workflows documentation](https://docs.paperspace.com/gradient/explore-train-deploy/workflows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [],
   "source": [
    "# Train model\n",
    "spec_path = './workflow-train-model.yaml'\n",
    "\n",
    "yaml_spec = open(spec_path, 'r')\n",
    "train_spec = yaml.safe_load(yaml_spec)\n",
    "\n",
    "# If you are using a Gradient private cluster, add the cluster_id here as another argument\n",
    "workflow_param_train = {\n",
    "    'workflow_id' : workflow_id_train,\n",
    "    'spec': train_spec,\n",
    "    'inputs': None\n",
    "}\n",
    "\n",
    "workflow_run_train = workflows_client.run_workflow(**workflow_param_train) # \"**\" is used because parameters is a dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "If you have your team name, project ID, and Workflow ID, you can access the Workflow directly at its URL in the GUI:\n",
    "\n",
    "`https://console.paperspace.com/<team name>/projects/<project_id>/workflows/<workflow ID>`\n",
    "\n",
    "e.g., like\n",
    "\n",
    "`https://console.paperspace.com/my_team/projects/pqrstuvwx/workflows/6789abcd-01ef-23gh-45ij-678901klmnop`\n",
    "\n",
    "Or navigate there via the Workflows tab.\n",
    "\n",
    "Information about the Workflow can also be retrieved from the output of its invocation above (`workflow_run_train`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 10,\n",
       " 'cluster': {'id': 'clg07azjl'},\n",
       " 'spec': {'jobs': {'CloneRecRepo': {'uses': 'git-checkout@v1',\n",
       "    'with': {'url': 'https://github.com/gradient-ai/Deep-Learning-Recommender-TF'},\n",
       "    'outputs': {'repoRec': {'type': 'volume'}}},\n",
       "   'RecommenderTrain': {'env': {'HP_FINAL_LR': '0.1', 'HP_FINAL_EPOCHS': '50'},\n",
       "    'uses': 'script@v1',\n",
       "    'with': {'image': 'tensorflow/tensorflow:2.4.1-jupyter',\n",
       "     'script': 'cp -R /inputs/repoRec /Deep-Learning-Recommender-TF\\ncd /Deep-Learning-Recommender-TF\\npython workflow_train_model.py'},\n",
       "    'needs': ['CloneRecRepo'],\n",
       "    'inputs': {'repoRec': 'CloneRecRepo.outputs.repoRec'},\n",
       "    'outputs': {'trainedRecommender': {'type': 'dataset',\n",
       "      'with': {'ref': 'recommender'}}}}},\n",
       "  'defaults': {'env': {'PAPERSPACE_API_KEY': 'secret:api_key_recommender'},\n",
       "   'resources': {'instance-type': 'P4000'}}},\n",
       " 'status': {'phase': 'SUBMITTING',\n",
       "  'logId': 'wfr5574a82d07a24e11ac423cdfbefdd042',\n",
       "  'jobs': {'RecommenderTrain': {'phase': 'SUBMITTING',\n",
       "    'logId': 'wfrjaa920d9c0be743f592b8b11f91083c30',\n",
       "    'outputs': {'trainedRecommender': {'dataset': {'id': 'recommender:5vvsad5',\n",
       "       'isCommitted': False}}}},\n",
       "   'CloneRecRepo': {'phase': 'SUBMITTING',\n",
       "    'logId': 'wfrjd8d8078fe7af47529d389ac51296e43f'}}}}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow_run_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "Like most Gradient functionality, invoking the Workflow from the GUI or SDK has an equivalent in the command line. Here we don't run it, since it would just rerun the same computation, but for reference, it is:\n",
    "\n",
    "`gradient workflows run \\`  \n",
    "`  --id <workflow_id_train> \\`  \n",
    "`  --clusterId <cluster_id> \\`  \n",
    "`  --path <path_to_yaml_file>`\n",
    "\n",
    "i.e., like\n",
    "\n",
    "`gradient workflows run \\`  \n",
    "` --id 6789abcd-01ef-23gh-45ij-678901klmnop \\`  \n",
    "` --clusterId cdefghijk \\`  \n",
    "` --path ./workflow-train-model.yaml`\n",
    "  \n",
    "There are other parameters available which we did not use here. See the [API documentation on Workflows](https://paperspace.github.io/gradient-cli/gradient.api_sdk.clients.html#module-gradient.api_sdk.clients.workflow_client) for information on those, and the [command line](https://paperspace.github.io/gradient-cli/gradient.cli.html) section under Workflows for more on CLI equivalents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "# NOT YET SUPPORTED HERE TO END\n",
    "\n",
    "Section 5 is pending support of model deployment from Workflows, and availability of deployments on public clusters. These will both be available circa Q4 2021, so we show the rest of the Notebook for completeness, but it will not yet run correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "Wf7US2o2LYDL"
   },
   "source": [
    "## 5: Deploy the final model\n",
    "\n",
    "A major part of any production data science end-to-end dataflow is that the trained model must be deployed so that it can generate output on new data being fed to it (inference). Many enterprise projects fail at the production stage, even if a model was successfully trained and showed good performance.\n",
    "\n",
    "In this project, the necessity of using a lower level model representation, i.e., the subclassing API, for recommender systems also adds to the potential complexity of deployment. Solving many real business problems will also require the subclassing API because of some custom requirement or business logic, and face similar issues.\n",
    "\n",
    "While it is possible to take one or more of the models generated from the notebook in sections 4.1 and 4.2 above, and then setup TensorFlow Serving to deploy, the process is so much easier on Gradient that we do not attempt this, and instead go directly to deploying the final model from section 4.3.\n",
    "\n",
    "In an enterprise production system, after model deployment comes dealing with model output to make it actionable to the business, model monitoring (especially for concept / data / model drift), retraining or updating the model when it does drift, and periodic updates with stakeholders to be sure the model is still being used and providing value. Some of these are mentioned again in the appendices below regarding improvements to the analysis and extensions to the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "### 5.1: Create and start model deployment using Workflows\n",
    "\n",
    "Running `workflow_train_model.py` from section 4.3 above produces a saved model, which we will deploy here.\n",
    "\n",
    "For reference, the lines in the Workflow's `workflow_train_model.py` to save the model are the standard `model.save` form from TensorFlow. The output directory is the location specified in the `workflow-train-model.yaml` file\n",
    "\n",
    "`export_path = '/outputs/trainedRecommender'`  \n",
    "`print('export_path = {}\\n'.format(export_path))`  \n",
    "`model_tr.save(export_path)`\n",
    "\n",
    "Viewing this in the GUI, one can see that the model is on disk and has the usual TensorFlow SavedModel structure:\n",
    "\n",
    " - `saved_model.pb` = code for the model, including its architecture\n",
    " - `variables/` = trained model weights\n",
    " - `assets/` = internal information for restoring the model if needed, here empty so not shown. An example would be a text file for initializing a vocabulary.\n",
    " \n",
    "The model is present and ready to be deployed. The process is similar to running the training, and shows the advantage of using this setup: the machine, cluster configuration, and container are all already available, and the deployments will be organized and versioned similar to how the models are.\n",
    "\n",
    "As with the training, there is a corresponding YAML file, `workflow-deploy-model.yaml` that here contains 3 jobs: `UploadModel`, `CreateDeployment`, and `StartDeployment`. `UploadModel` accesses the desired model version and makes it accessible to the Workflow, then create and start are separate steps since in general not all created deployments will want to be started immediately, and a deployment may want to be stopped without being deleted.\n",
    "\n",
    "Unlike the training, in the deployment here, a further `.py` Python script is not needed.\n",
    "\n",
    "As with training, there are more parameters available, as described in the [API documentation for deployment creation](https://paperspace.github.io/gradient-cli/gradient.api_sdk.clients.html#module-gradient.api_sdk.clients.deployment_client)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [],
   "source": [
    "spec_path = './workflow-deploy-model.yaml'\n",
    "\n",
    "yaml_spec = open(spec_path, 'r')\n",
    "deploy_spec = yaml.safe_load(yaml_spec)\n",
    "\n",
    "workflow_param_deploy = {\n",
    "    'workflow_id' : workflow_id_deploy,\n",
    "    'spec': deploy_spec,\n",
    "    'inputs': None\n",
    "}\n",
    "\n",
    "workflow_run_deploy = workflows_client.run_workflow(**workflow_param_deploy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "As with training, we can view the deployment details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [],
   "source": [
    "workflow_run_deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "### 5.2: Send predictions to the model\n",
    "\n",
    "When a model is deployed with Gradient Deployments (or TensorFlow Serving), there is a choice between using the Google gRPC API and the http [REST API](https://www.tensorflow.org/tfx/serving/api_rest#predict_api).\n",
    "\n",
    "Here, we use the REST API.\n",
    "\n",
    "With this API, to send new data (requests) to the deployed model, and have it return predicted movie ratings for that data (predictions), the requests must be formatted as JSON rather than TensorFlow tensors. So we can't just use the same format as the loaded TFDS dataset, or the `cached_train` that we passed in during training above.\n",
    "\n",
    "As a reminder, the raw data loaded in looked like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false
    },
    "id": "pFn7DEMhLGHj",
    "outputId": "6c0bef38-87d7-4f8d-a390-7ec83d8116dd"
   },
   "outputs": [],
   "source": [
    "for x in ratings_raw.take(2).as_numpy_iterator():\n",
    "    pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "WM0-SD87Leza"
   },
   "source": [
    "and the data passed to the model during training looked like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false
    },
    "id": "2mKEL5fYLiPO",
    "outputId": "f8260544-0980-45a2-c2d6-79e1056e2f2b"
   },
   "outputs": [],
   "source": [
    "for x in cached_train.take(2).as_numpy_iterator():\n",
    "    pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "dki19It0KzXR"
   },
   "source": [
    "But for JSON, the data needs to look more like this:\n",
    "\n",
    "```\n",
    "{\n",
    " \"instances\": [\n",
    "   {\n",
    "     \"tag\": \"foo\",\n",
    "     \"signal\": [1, 2, 3, 4, 5],\n",
    "     \"sensor\": [[1, 2], [3, 4]]\n",
    "   },\n",
    "   {\n",
    "     \"tag\": \"bar\",\n",
    "     \"signal\": [3, 4, 1, 2, 5]],\n",
    "     \"sensor\": [[4, 5], [6, 8]]\n",
    "   }\n",
    " ]\n",
    "}\n",
    "```\n",
    "\n",
    "From [the TFX API page](https://www.tensorflow.org/tfx/serving/api_rest#specifying_input_tensors_in_row_format): \"For multiple named inputs, each item is expected to be an object containing input name/tensor value pair, one for each named input. ... a request with two instances, each with a set of three named input tensors\".\n",
    "\n",
    "To create JSON-formatted data, the easiest way at the scale of data in this notebook is to use Python's json module. Then to send it, the requests module is used to enable it to be sent to the REST API via POST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": true
    },
    "id": "tjvE00XnPtRP"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "wRUt3IqsND5k"
   },
   "source": [
    "The correct format of a some data rows (instances) then looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "s0MOEitGXtaM"
   },
   "outputs": [],
   "source": [
    "test_rows_1 = {'movie_title': 'Devils Advocate, The (1997)',\n",
    " 'timestamp': 892870992,\n",
    " 'user_id': '587'}\n",
    "\n",
    "test_rows_2 = {'movie_title': 'Donnie Brasco (1997)',\n",
    " 'timestamp': 891499278,\n",
    " 'user_id': '782'}\n",
    "\n",
    "test_rows_3 = {'movie_title': 'Craft, The (1996)',\n",
    " 'timestamp': 891700850,\n",
    " 'user_id': '280'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "GcIMvYUlNNIa"
   },
   "source": [
    "And it can be converted to JSON with .dumps (dump string), with the instances as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "gradient": {
     "editing": false
    },
    "id": "OYHYMjEPM56U",
    "outputId": "b5b1d6b6-a8ea-45a2-8585-837924748186"
   },
   "outputs": [],
   "source": [
    "data = json.dumps({'signature_name': 'serving_default', 'instances': [test_rows_1, test_rows_2, test_rows_3]})\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "uW5bnvRTNU_j"
   },
   "source": [
    "Then the data can be sent to the deployed model via POST, and the returned output extracted from the full response by `.json()`. We can get the model's endpoint from the deployment properties, as shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false
    },
    "id": "ry8Qk0roM59h",
    "outputId": "ad54ad32-2381-475c-c4a3-5cc49128748f"
   },
   "outputs": [],
   "source": [
    "endpoint = deployment[0].endpoint\n",
    "headers = {'content-type': 'application/json'}\n",
    "json_response = requests.post(endpoint, data=data, headers=headers)\n",
    "pprint.pprint(json_response.json(), compact=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "Cys2R1B0Nwz4"
   },
   "source": [
    "As with `.predict()` in training above, this has returned both the embeddings and the predictions. We can also extract just the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false
    },
    "id": "-VV6ZKFuZHNt",
    "outputId": "79cd51bb-2624-4985-a00e-3572cbebaaa5"
   },
   "outputs": [],
   "source": [
    "predictions = json.loads(json_response.text)['predictions']\n",
    "\n",
    "print(predictions[0]['output_3'])\n",
    "print(predictions[1]['output_3'])\n",
    "print(predictions[2]['output_3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "0SFYXBQ9NzUj"
   },
   "source": [
    "One thing to note about the above of course is that we wrote the example lines of new data here to send to the model, instead of loading them. This could be improved by, say loading more data from TFDS. In this particular case, more steps would be required in converting the byte-encoded fields into the above format before passing to JSON, because byte-encoded fields are not JSON serializable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "### 5.3: Stop deployment\n",
    "\n",
    "Once we are done with the deployment, we can stop it again to avoid leaving it consuming compute resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [],
   "source": [
    "deployments_client.stop(deployment_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "tAE5YcD_IW0u"
   },
   "source": [
    "## 6: Conclusions\n",
    "\n",
    "We have shown an end-to-end example of deep learning recommender models in TensorFlow, using the TensorFlow Recommenders (TFRS) library, and the implementation of this using Paperspace Gradient.\n",
    "\n",
    "The main takeaways are:\n",
    "\n",
    " - We showed a real-world-style example of machine learning on Gradient\n",
    " - This is within an end-to-end dataflow incorporating both Gradient Notebooks and Workflows\n",
    " - Modern data science methodology based on Gradient's integrations with Git was used\n",
    " - We used TensorFlow 2 and TensorFlow Recommenders (TFRS) to train a recommender model that includes deep learning\n",
    " - We used training data that reflects what real-world projects deal with (not just demo data)\n",
    " - We constructed a custom model using the full TensorFlow subclassing API\n",
    " - Feature engineering and hyperparameter tuning improved model performance versus a basic model (RMSE between predicted and user ratings from ~ 1.1 to ~ 1)\n",
    " - The model was deployed using Gradient Deployments and its TensorFlow Serving integrations\n",
    " - Accompanying material is available: the 6 part blog series, and Git repository\n",
    " - We have aimed at a broad technical audience: data scientists who are not engineers, engineers who are not data scientists, those who span the two disciplines, and others\n",
    "\n",
    "The project is not a complete enterprise-grade recommender system: they would typically take teams of several people months to construct, but it aims to be more than just a simple demonstration or toy model, by showcasing real data science techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "efApI0Ii6srB"
   },
   "source": [
    "# Next steps\n",
    "\n",
    "Now that you have seen recommender systems, deep learning, and Paperspace Gradient, if you are interested in taking some next steps, some options are:\n",
    "\n",
    " - Sign up for [Paperspace](https://paperspace.com), if not done already\n",
    " - Run this notebook on [Gradient](https://gradient.paperspace.com), if not done already\n",
    " - Read the accompanying [blog series](https://blog.paperspace.com) to this notebook\n",
    " - See more projects on our [ML Showcase](https://ml-showcase.paperspace.com)\n",
    " - View the Gradient [documentation](https://docs.paperspace.com) or [API reference](https://paperspace.github.io/gradient-cli)\n",
    " - Learn more about recommenders at [TFRS](https://www.tensorflow.org/recommenders)\n",
    " - Check out more links and references in the [final part]() of the blog\n",
    " - [Contact sales](https://info.paperspace.com/contact-sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "Flxm19Sos2Xz"
   },
   "source": [
    "# Appendices\n",
    "\n",
    "These show ways the project can be extended, either generically, or in ways specifically aided by Paperspace Gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "z2-iK1-LHo-1"
   },
   "source": [
    "## Appendix 1: Improvements to the analysis\n",
    "\n",
    "These are some ways that the analysis could be improved while telling the same story. These are given in the order in which they would appear in the dataflow.\n",
    "\n",
    "They are relatively briefly described here. For more details, see the final part of the blog.\n",
    "\n",
    "A few minor detail improvements were also included in various code comments throughout the notebook.\n",
    "\n",
    " - Add more to the business story: here it is showing the generic concept of a deep learning recommender improving upon a basic model, but it is not translated into specific quantified business value for a given use case.\n",
    " - Use a bigger dataset: Aside from movielens-100k, the available datasets include 1M, 20M, and 25M. 20M and 25M contain less demographic information but still include user ratings.\n",
    " - Data larger than 25M can be produced via simulation if we wish to show scaling to bigger sizes, e.g., the [original MovieLens site](https://grouplens.org/datasets/movielens) contains a synthetic dataset called MovieLens-1B, which can go to numbers of interactions in the billions.\n",
    " - Add data exploration for information and sanity checking.\n",
    " - Use more [features](https://www.tensorflow.org/recommenders/examples/featurization) and [context](https://www.tensorflow.org/recommenders/examples/context_features) from the dataset to improve model performance, including preprocessing with word embedding, text tokenization, normalizaton of numerical values, and timestamps.\n",
    " - Feature selection / engineering, e.g., day of week or time of day.\n",
    " - Hyperparameter tuning improvements noted in section 4.2 above.\n",
    " - Turning metric calculation off in training for [retrieval models](https://www.tensorflow.org/recommenders/examples/basic_retrieval) (compute_metrics in task as False) can make training faster.\n",
    " - Examine the model output predicted ratings in more detail - most are currently around 3-4, and since most reviews are 3-5 out of 5, just saying 3.5ish every time might give the best RMSE.\n",
    " - Remove all randomness in execution of the ML models, making their results exactly reproducible. This may not be possible in some environments such as a distributed system.\n",
    " - Use Paperspace's GPU instances for faster training of large models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "q3ltn-uGIGkU"
   },
   "source": [
    "## Appendix 2: Extensions to the project\n",
    "\n",
    "These are possible extensions to the analysis that would add to the story, again in approximate dataflow order.\n",
    "\n",
    "### Generic\n",
    "\n",
    " - Address [fairness, bias, etc.](https://www.tensorflow.org/tfx/guide/fairness_indicators), in feature selection and model training.\n",
    " - Show dealing with missing data and out-of-vocabulary categoricals.\n",
    " - Show improving performance via [feature crosses](https://www.tensorflow.org/recommenders/examples/dcn).\n",
    " - Add the retrieval model and hence a [combined model](https://www.tensorflow.org/recommenders/examples/multitask) for both retrieval and ranking.\n",
    " - Show dealing with the \"cold start\" problem of what to recommend to a new user who hasn't watched any movies but whose information we possess.\n",
    " - Use data from common tasks to help model rarer tasks via transfer learning.\n",
    " - Add an option to exclude already-watched shows or movies from a user's recommendations, or add extra variety versus the baseline choices.\n",
    " - Visualize the trained model with TensorBoard or [TFMA](https://www.tensorflow.org/tfx/model_analysis/metrics).\n",
    " - Provide [explanations](https://www.tensorflow.org/recommenders/examples/dcn) for the models' choices of recommendations.\n",
    " - For retrieval, deploy with [ScaNN approximate nearest neighbors](https://www.tensorflow.org/recommenders/examples/efficient_serving) to speed up model inference. Tune the layer for better performance/accuracy tradeoff.\n",
    " - Monitor the deployed model for drift and/or anomalies using a monitoring tool.\n",
    "\n",
    "### Paperspace Gradient-specific\n",
    "\n",
    " - Show the relation between working in Notebooks, Workflows, and Gradient's GradientCI GitHub integration capabilities, e.g., versioning of notebooks, when they are supported by Workflows.\n",
    " - Show getting the data from somewhere that is not TensorFlow's prepackaged datasets (TFDS), that Gradient easily connects to, e.g., Amazon S3.\n",
    " - Show distributed training with Gradient's multinode capability.\n",
    " - Combine multinode, GPU, and GradientCI to show distributed GPU training that follows good versioning practices and GitHub integration.\n",
    " - Show full specification of the end-to-end data flow (software, versions, licenses, security) in a way that makes it easy for an enterprise IT department to approve it.\n",
    " - Show production of an audit trail from the end-to-end process, making it auditable and hence FAccT (fair, accountable, and transparent).\n",
    " - Show how other users can query the deployed model.\n",
    " - Show retraining being triggered with Gradient's jobs function, e.g., if deployed model has drifted.\n",
    " - Show rollback to an earlier deployed model.\n",
    " - Show a GUI application (e.g., Streamlit) that accesses the deployed model's API endpoint, making its functionality accessible to non-technical as well as technical users."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "tnDTzpDQ_hUS",
    "tAE5YcD_IW0u",
    "efApI0Ii6srB"
   ],
   "name": "deep_learning_recommender_tf.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
